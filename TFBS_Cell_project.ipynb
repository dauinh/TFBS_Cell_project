{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-psvXpKG_x8"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D9OdA0JYgif",
        "outputId": "80dee469-c9d1-48a0-bfbf-b8500f84a075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(gpus)\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e: print(e)\n",
        "\n",
        "import re\n",
        "import json\n",
        "import gzip\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "from keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NFwoVcfHYx7",
        "outputId": "a114b78a-abb0-4b63-becd-5187b6388cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from os import path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT_DIR=\"/content/drive/MyDrive/Shared/TFBS_Cell_project/\"\n",
        "in_path=ROOT_DIR+\"cellvar.db.tfbs_seq.tsv.gz\"\n",
        "out_dir=ROOT_DIR+\"out\"\n",
        "\n",
        "if path.exists(out_dir) == False:\n",
        "    os.mkdir(out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EiRPOh24YoMS"
      },
      "outputs": [],
      "source": [
        "# des = \"\"\"\n",
        "# TFBS sequence training/learning tool\n",
        "# (C) Timothy James Becker, 05/03/24-07/08/24, version=0.0.1\"\"\"\n",
        "# parser = argparse.ArgumentParser(description=des, formatter_class=argparse.RawTextHelpFormatter)\n",
        "# # need the split, max vocab, maxlen, balance, cmap,tsv.gz input file\n",
        "# parser.add_argument('--in_path', type=str, help='cellvar.db.tfbs_seq.tsv.gz traing input file')\n",
        "# parser.add_argument('--out_dir', type=str, help='output directory')\n",
        "# parser.add_argument('--features', type=str, help='comma-seperated list fo features to model: AEC,PEC,PC,IC')\n",
        "# parser.add_argument('--split', type=float, help='split factor [0.0 to 1.0]')\n",
        "# parser.add_argument('--vocab', type=int, help='maximum vocabulary size')\n",
        "# parser.add_argument('--len', type=int, help='sequence length')\n",
        "# parser.add_argument('--balance', type=float, help='balance factor [0.0 is downsample to 1.0 is upsample]')\n",
        "# parser.add_argument('--gpu', type=int, help='gpu number [0 to x]')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "# in_path = args.in_path\n",
        "# features = args.features.split(',')\n",
        "# features = set([feature.upper() for feature in features]).intersection(set(['AEC', 'PEC', 'PC', 'IC']))\n",
        "# split = args.split\n",
        "# max_vocab = args.vocab\n",
        "# maxlen = args.len\n",
        "# balance_w = args.balance\n",
        "# gpu_num = args.gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YRp0xKLHDAI"
      },
      "source": [
        "## Network layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHNmYBMAYy48"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.embed_dim,self.num_heads,self.ff_dim,self.rate = embed_dim, num_heads, ff_dim, rate\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim), ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.maxlen,self.vocab_size,self.embed_dim = maxlen, vocab_size, embed_dim\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = ops.shape(x)[-1]\n",
        "        positions = ops.arange(start=0, stop=maxlen, step=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_yeyVpJY5Qa"
      },
      "outputs": [],
      "source": [
        "class F1(keras.metrics.Metric):\n",
        "    def __init__(self, name='f1'):\n",
        "        super().__init__(name=name)\n",
        "        self.sum_t0   = self.add_variable(shape=(),initializer='zeros',name='sum_t0')\n",
        "        self.sum_p0   = self.add_variable(shape=(),initializer='zeros',name='sum_p0')\n",
        "        self.sum_t0p0 = self.add_variable(shape=(),initializer='zeros',name='sum_t0p0')\n",
        "        self.sum_t1   = self.add_variable(shape=(),initializer='zeros',name='sum_t1')\n",
        "        self.sum_p1   = self.add_variable(shape=(),initializer='zeros',name='sum_p1')\n",
        "        self.sum_t1p1 = self.add_variable(shape=(),initializer='zeros',name='sum_t1p1')\n",
        "        self.f1       = self.add_variable(shape=(),initializer='zeros',name='f1')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        t0 = -1 * (y_true - 1) + 0.0\n",
        "        t1 = y_true\n",
        "        p0 = ops.round(y_pred[:, 0],0)\n",
        "        p1 = ops.round(y_pred[:, 1],0)\n",
        "        self.sum_t0.assign(self.sum_t0+ops.sum(t0))\n",
        "        self.sum_p0.assign(self.sum_p0+ops.sum(p0))\n",
        "        self.sum_t0p0.assign(self.sum_t0p0+ops.sum(t0*p0))\n",
        "        self.sum_t1.assign( self.sum_t1+ops.sum(t1))\n",
        "        self.sum_p1.assign(self.sum_p1+ops.sum(p1))\n",
        "        self.sum_t1p1.assign(self.sum_t1p1+ops.sum(t1*p1))\n",
        "\n",
        "    def result(self):\n",
        "        prec0 = ops.divide_no_nan(self.sum_t0p0,self.sum_t0)\n",
        "        rec0  = ops.divide_no_nan(self.sum_t0p0,self.sum_p0)\n",
        "        prec1 = ops.divide_no_nan(self.sum_t1p1,self.sum_t1)\n",
        "        rec1  = ops.divide_no_nan(self.sum_t1p1,self.sum_p1)\n",
        "        f1_0  = 2.0*ops.divide_no_nan(prec0*rec0,prec0+rec0)\n",
        "        f1_1  = 2.0*ops.divide_no_nan(prec1*rec1,prec1+rec1)\n",
        "        self.f1.assign((f1_0+f1_1)/2.0)\n",
        "        return self.f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSak6Pz3HIbA"
      },
      "source": [
        "## Helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcCFvAiTY-qK"
      },
      "outputs": [],
      "source": [
        "def c2_f1_loss(y_true, y_pred):\n",
        "    t0 = -1 * (y_true - 1) + 0.0\n",
        "    t1 = y_true\n",
        "    p0 = y_pred[:, 0]\n",
        "    p1 = y_pred[:, 1]\n",
        "    e10 = t1*p0\n",
        "    e01 = t0*p1\n",
        "    e = ops.sum(e10) + ops.sum(e01)\n",
        "    x1 = ops.sum(t1 * p0) / e\n",
        "    x2 = ops.sum(t0 * p1) / e\n",
        "    f1 = 1.0 - 2.0 * (x1 * x2) / (x1 + x2)\n",
        "    return ops.sum(f1 * e10) + ops.sum(f1 * e01)\n",
        "\n",
        "def data2dict(raw):\n",
        "    F = {}\n",
        "    for row in raw:\n",
        "        feature, cell = row[:2]\n",
        "        if feature not in F:       F[feature] = {}\n",
        "        if cell not in F[feature]: F[feature][cell] = []\n",
        "        F[feature][cell] += [row[2:]]\n",
        "    return F\n",
        "\n",
        "def split_num(s):\n",
        "    match = re.match(r\"([a-z]*)([0-9]+)([a-z]*)\", s, re.I)\n",
        "    if match:\n",
        "        items = list(match.groups())\n",
        "    else:\n",
        "        items = [s]\n",
        "    while items[-1] == '': items = items[:-1]\n",
        "    return items\n",
        "\n",
        "def conv(s):\n",
        "    ss = split_num(s)\n",
        "    t = ''\n",
        "    for x in ss:\n",
        "        if x.isdigit():\n",
        "            t += chr(int(x) + ord('z') + 1)\n",
        "        else:\n",
        "            t += x\n",
        "    return t\n",
        "\n",
        "def edit_sim(s1, s2, w=[0, 1, 1, 1]):\n",
        "    s1 = conv(s1.replace('+', '').replace('-', ''))\n",
        "    s2 = conv(s2.replace('+', '').replace('-', ''))\n",
        "    if len(s1) < len(s2): s1, s2 = s2, s1\n",
        "    u, v = len(s1), len(s2)\n",
        "    d = [[0 for col in range(v + 1)] for row in range(u + 1)]\n",
        "    for i in range(0, u + 1): d[i][0] = i\n",
        "    for j in range(0, v + 1): d[0][j] = j\n",
        "    for j in range(1, v + 1):\n",
        "        for i in range(1, u + 1):\n",
        "            if s1[i - 1] == s2[j - 1]:\n",
        "                d[i][j] = d[i - 1][j - 1] + w[0]\n",
        "            else:\n",
        "                d[i][j] = min(d[i - 1][j] + w[1], d[i][j - 1] + w[2], d[i - 1][j - 1] + w[3])\n",
        "    return 1.0 - d[u][v] / max(len(s1), len(s2))\n",
        "\n",
        "def kmer_tree_sample(T,kmer):\n",
        "    s,i = [],0\n",
        "    while 'links' in T and i<kmer:\n",
        "        x  = 1/T['sum']\n",
        "        xs = [[T['links'][k]['sum']*x,k] for k in sorted(T['links'])]\n",
        "        ks,ps = [k[1] for k in xs],[k[0] for k in xs]\n",
        "        y = np.random.choice(ks,1,p=ps)[0]\n",
        "        s += [y]\n",
        "        i += 1\n",
        "        T = T['links'][y]\n",
        "    return s\n",
        "\n",
        "def reverse_complement(seqs,strings=False):\n",
        "    teqs = []\n",
        "    for i in range(len(seqs)):\n",
        "        if strings:\n",
        "            teqs += [' '.join([t.replace('+','-') if t.find('+')>=0 else t.replace('-','+') for t in seqs[i]][::-1])]\n",
        "        else:\n",
        "            teqs += [[t.replace('+', '-') if t.find('+') >= 0 else t.replace('-', '+') for t in seqs[i]][::-1]]\n",
        "    return teqs\n",
        "\n",
        "# given sequences F[feature][cell] = [['RUNX2+',...],[],[],...] with len n, up-sample to target value m>n\n",
        "# up sampling should use a generative model, something like a kmer=3 distribution...\n",
        "def upsample_seqs(teqs,m,strings=True):\n",
        "    if strings: seqs = [seq.split(' ') for seq in teqs]\n",
        "    else:       seqs = teqs\n",
        "    #maybe convert the seqs to int sequences to save some RAM...\n",
        "    S = set([])\n",
        "    for seq in seqs+reverse_complement(seqs,strings=False):\n",
        "        for e in seq: S.add(e)\n",
        "    S = sorted(S)\n",
        "    s_idx = {S[i]:i for i in range(len(S))}\n",
        "    idx_s = {i:S[i] for i in range(len(S))}\n",
        "    T = []\n",
        "    for seq in seqs+reverse_complement(seqs,strings=False):\n",
        "        T += [[s_idx[e] for e in seq]]\n",
        "    seqs = T\n",
        "\n",
        "    print('starting kmer counting...')\n",
        "    t_start = time.time()\n",
        "    #--------------------------------------------------------------------------------\n",
        "    k = int(np.mean([len(seq) for seq in seqs])+3*np.std([len(seq) for seq in seqs]))\n",
        "    H = {'sum':0,'links':{}}\n",
        "    for seq in seqs:\n",
        "        if len(seq)>=k:\n",
        "            for i in range(0,len(seq)-(k-1),1):\n",
        "                H['sum'] += 1\n",
        "                h = H['links']\n",
        "                if seq[i] not in h: h[seq[i]] = {'sum':1,'links':{}}\n",
        "                else:               h[seq[i]]['sum'] += 1\n",
        "                h = h[seq[i]]['links']\n",
        "                for a in range(i+1,i+(k-1),1):\n",
        "                    if seq[a] not in h: h[seq[a]]  = {'sum':1,'links':{}}\n",
        "                    else:               h[seq[a]]['sum'] += 1\n",
        "                    h = h[seq[a]]['links']\n",
        "                b = i+(k-1)\n",
        "                if seq[b] not in h: h[seq[b]]  = {'sum':1}\n",
        "                else:               h[seq[b]]['sum'] += 1\n",
        "        else:\n",
        "            t = len(seq) #maximal\n",
        "            if seq[0] not in H: H[seq[0]] = {'sum':1,'links':{}}\n",
        "            h = H[seq[0]]['links']\n",
        "            for a in range(1,k-1,1):\n",
        "                if a<t:\n",
        "                    if seq[a] not in h: h[seq[a]]  = {'sum':1,'links':{}}\n",
        "                    h = h[seq[a]]['links']\n",
        "                else:\n",
        "                    if '' not in h: h[''] = {'sum':1,'links':{}}\n",
        "                    h = h['']['links']\n",
        "            b = k-1\n",
        "            if b<t:\n",
        "                if seq[b] not in h: h[seq[b]]  = {'sum':1}\n",
        "                else:               h[seq[b]]['sum'] += 1\n",
        "            else:\n",
        "                if '' not in h: h['']  = {'sum':1}\n",
        "                else:           h['']['sum'] += 1\n",
        "            #now do we keep going and pad the ends?\n",
        "        #now traverse the tree and pull out every path as a tuple/key\n",
        "        # -----------------------------------------------------\n",
        "    t_stop = time.time()\n",
        "    print('kmer counting tree completed in %s sec'%int(t_stop-t_start))\n",
        "\n",
        "    print('starting generative modeling...')\n",
        "    g_start = time.time()\n",
        "    G = []\n",
        "    ss = list(np.random.choice([len(seq) for seq in seqs],m,replace=True))\n",
        "    for sx in ss:\n",
        "        G += [[idx_s[i] for i in kmer_tree_sample(H,kmer=sx)]]\n",
        "    if strings: G = [' '.join(seq) for seq in G]\n",
        "    g_stop = time.time()\n",
        "    print('generative modeling %s sequences in %s sec'%(m,int(g_stop-g_start)))\n",
        "\n",
        "    return G\n",
        "\n",
        "def get_cell_idx(D):\n",
        "    cells = sorted(list(set([tuple(sorted(D[feature])) for feature in D]))[0])\n",
        "    cell_idx = {cells[i]: i for i in range(len(cells))}\n",
        "    return cell_idx\n",
        "\n",
        "def data_partition(D, split=0.3, shuffle=True,\n",
        "                    balance_w=None):  # will take 70% for training, 20% for test and 10% for validation of each stratification, using spilt=0.3\n",
        "    train_x, train_y, test_x, test_y, valid_x, valid_y = {}, {}, {}, {}, {}, {}\n",
        "    cells = sorted(list(set([tuple(sorted(D[feature])) for feature in D]))[0])\n",
        "    cell_idx = {cells[i]: i for i in range(len(cells))}\n",
        "    print('using data labeling scheme: %s'%cell_idx)\n",
        "    for feature in D:\n",
        "        train_x[feature], train_y[feature] = {}, {}\n",
        "        test_x[feature], test_y[feature] = {}, {}\n",
        "        valid_x[feature], valid_y[feature] = {}, {}\n",
        "        for cell in sorted(D[feature]):\n",
        "            if cell in cell_idx:\n",
        "                n = len(D[feature][cell])\n",
        "                u = int(round(n * (1.0 - split)))\n",
        "                v = int(round(2 * n * split / 3.0))\n",
        "                u_idx = np.random.choice(range(n), u, replace=False)\n",
        "                v_idx = np.random.choice(list(set(range(n)).difference(set(u_idx))), v, replace=False)\n",
        "                w_idx = set(range(n)).difference(set(u_idx).union(set(v_idx)))\n",
        "                train_x[feature][cell] = [' '.join(D[feature][cell][i]) for i in u_idx]\n",
        "                test_x[feature][cell] = [' '.join(D[feature][cell][i]) for i in v_idx]\n",
        "                valid_x[feature][cell] = [' '.join(D[feature][cell][i]) for i in w_idx]\n",
        "\n",
        "    if balance_w is not None:  # balance the data using a variable 0.0-1.0 up/down sampling point\n",
        "        print('balancing data...')\n",
        "        for feature in train_x:\n",
        "            min_class = min([len(train_x[feature][cell]) for cell in train_x[feature]])\n",
        "            max_class = max([len(train_x[feature][cell]) for cell in train_x[feature]])\n",
        "            mid_class = int(round(min_class + balance_w * (max_class - min_class)))\n",
        "            for cell in sorted(train_x[feature]):\n",
        "                print('balancing training feature=%s, cell=%s' % (feature, cell))\n",
        "                fc_len = len(train_x[feature][cell])\n",
        "                if fc_len >= mid_class:\n",
        "                    train_x[feature][cell] = [train_x[feature][cell][i] for i in\n",
        "                                                np.random.choice(range(fc_len), mid_class, replace=False)]\n",
        "                else:\n",
        "                    train_x[feature][cell] += upsample_seqs(train_x[feature][cell], mid_class - fc_len,\n",
        "                                                            strings=True)\n",
        "        for feature in test_x:\n",
        "            min_class = min([len(test_x[feature][cell]) for cell in test_x[feature]])\n",
        "            max_class = max([len(test_x[feature][cell]) for cell in test_x[feature]])\n",
        "            mid_class = int(round(min_class + balance_w * (max_class - min_class)))\n",
        "            for cell in sorted(test_x[feature]):\n",
        "                print('balancing test feature=%s, cell=%s' % (feature, cell))\n",
        "                fc_len = len(test_x[feature][cell])\n",
        "                if fc_len >= mid_class:\n",
        "                    test_x[feature][cell] = [test_x[feature][cell][i] for i in\n",
        "                                                np.random.choice(range(fc_len), mid_class, replace=False)]\n",
        "                else:\n",
        "                    test_x[feature][cell] += upsample_seqs(test_x[feature][cell], mid_class - fc_len, strings=True)\n",
        "\n",
        "    for feature in train_x:\n",
        "        X, Y = [], []\n",
        "        for cell in sorted(train_x[feature]):\n",
        "            X += train_x[feature][cell]\n",
        "            Y += [cell_idx[cell] for i in range(len(train_x[feature][cell]))]\n",
        "        train_x[feature], train_y[feature] = X, Y\n",
        "    for feature in test_x:\n",
        "        X, Y = [], []\n",
        "        for cell in sorted(test_x[feature]):\n",
        "            X += test_x[feature][cell]\n",
        "            Y += [cell_idx[cell] for i in range(len(test_x[feature][cell]))]\n",
        "        test_x[feature], test_y[feature] = X, Y\n",
        "        X, Y = [], []\n",
        "    for feature in valid_x:\n",
        "        for cell in sorted(valid_x[feature]):\n",
        "            X += valid_x[feature][cell]\n",
        "            Y += [cell_idx[cell] for i in range(len(valid_x[feature][cell]))]\n",
        "        valid_x[feature], valid_y[feature] = X, Y\n",
        "\n",
        "    if shuffle:  # have the correct number of examples but the labels are not shuffled\n",
        "        for feature in D:\n",
        "            n = len(train_x[feature])\n",
        "            idx = np.random.choice(range(n), n, replace=False)\n",
        "            train_x[feature] = [train_x[feature][i] for i in idx]\n",
        "            train_y[feature] = [train_y[feature][i] for i in idx]\n",
        "\n",
        "            u = len(test_x[feature])\n",
        "            idx = np.random.choice(range(u), u, replace=False)\n",
        "            test_x[feature] = [test_x[feature][i] for i in idx]\n",
        "            test_y[feature] = [test_y[feature][i] for i in idx]\n",
        "\n",
        "            v = len(valid_x[feature])\n",
        "            idx = np.random.choice(range(v), v, replace=False)\n",
        "            valid_x[feature] = [valid_x[feature][i] for i in idx]\n",
        "            valid_y[feature] = [valid_y[feature][i] for i in idx]\n",
        "\n",
        "    return train_x, train_y, test_x, test_y, valid_x, valid_y\n",
        "\n",
        "def preprocess_data(D, max_vocab=None, maxlen=2000, split=0.4, balance_w=0.5, dt=np.float32):\n",
        "    train_x, train_y, test_x, test_y, valid_x, valid_y = data_partition(D, split=split, balance_w=balance_w)\n",
        "    vocab = sorted(get_vocab(D))\n",
        "    vocab_size = len(vocab)\n",
        "    vectorize_layer = TextVectorization(\n",
        "        standardize=\"lower\",\n",
        "        max_tokens=min(vocab_size, max_vocab),\n",
        "        output_mode=\"int\",\n",
        "        output_sequence_length=maxlen\n",
        "    )\n",
        "    vectorize_layer.adapt(vocab)\n",
        "    train, test, valid = {}, {}, {}\n",
        "    for feature in D:\n",
        "        train[feature] = (\n",
        "        np.array(vectorize_layer(train_x[feature]), dtype=dt), np.array(train_y[feature], dtype=dt))\n",
        "        test[feature] = (np.array(vectorize_layer(test_x[feature]), dtype=dt), np.array(test_y[feature], dtype=dt))\n",
        "        valid[feature] = (\n",
        "        np.array(vectorize_layer(valid_x[feature]), dtype=dt), np.array(valid_y[feature], dtype=dt))\n",
        "    return train, test, valid, vectorize_layer\n",
        "\n",
        "def get_vocab(D):\n",
        "    V = set([])\n",
        "    for feature in D:\n",
        "        for cell in D[feature]:\n",
        "            for row in D[feature][cell]:\n",
        "                for i in row:\n",
        "                    V.add(i)\n",
        "    return V\n",
        "\n",
        "def get_trans(C, ks=16):\n",
        "    S = {}\n",
        "    V = sorted(set([re.split('[+|-]', v)[0] for v in get_vocab(C)]))\n",
        "    idx = {V[i]: i for i in range(len(V))}\n",
        "    for feature in C:\n",
        "        S[feature] = {}\n",
        "        for cell in C[feature]:\n",
        "            S[feature][cell] = []\n",
        "            for i in range(len(C[feature][cell])):\n",
        "                X = np.zeros((len(idx), len(idx), 3), dtype=float)\n",
        "                for k in range(min(ks, len(C[feature][cell][i]))):\n",
        "                    for a in range(len(C[feature][cell][i]) - k):\n",
        "                        tf1 = re.split('[+|-]', C[feature][cell][i][a])[0]\n",
        "                        tf2 = re.split('[+|-]', C[feature][cell][i][a + k])[0]\n",
        "                        if C[feature][cell][i][a].find('+') > -1:\n",
        "                            if C[feature][cell][i][a + k].find('+') > -1:\n",
        "                                X[idx[tf1], idx[tf2], 0] += 1\n",
        "                            else:\n",
        "                                X[idx[tf1], idx[tf2], 1] += 1\n",
        "                        else:\n",
        "                            if C[feature][cell][i][a + k].find('+') > -1:\n",
        "                                X[idx[tf1], idx[tf2], 1] += 1\n",
        "                            else:\n",
        "                                X[idx[tf1], idx[tf2], 0] += 1\n",
        "                X /= np.sum(X)\n",
        "                S[feature][cell] += [X]\n",
        "    return S\n",
        "\n",
        "def get_classes(D):\n",
        "    C = set([])\n",
        "    for feature in D:\n",
        "        for cell in D[feature]:\n",
        "            C.add(cell)\n",
        "    return C\n",
        "\n",
        "def cell_map(F, cmap):\n",
        "    C = {}\n",
        "    for feature in F:\n",
        "        C[feature] = {}\n",
        "        for cell in F[feature]:\n",
        "            if cmap[cell] in C[feature]:\n",
        "                C[feature][cmap[cell]] += [row for row in F[feature][cell]]\n",
        "            else:\n",
        "                C[feature][cmap[cell]] = [row for row in F[feature][cell]]\n",
        "    return C\n",
        "\n",
        "def confusion_matrix(T, Y, c=10):\n",
        "    M = np.array([[0.0 for j in range(c)] for i in range(c)], dtype=float)\n",
        "    for i in range(len(T)):\n",
        "        M[int(T[i])][int(Y[i])] += 1.0\n",
        "    return M\n",
        "\n",
        "def f1_score(cm):\n",
        "    f1s = []\n",
        "    for i in range(len(cm)):\n",
        "        prec = (0.0 if np.sum(cm[:, i]) == 0.0 else cm[i, i] / np.sum(cm[:, i]))\n",
        "        rec = (0.0 if np.sum(cm[i, :]) == 0.0 else cm[i, i] / np.sum(cm[i, :]))\n",
        "        f1s += [(0.0 if (prec + rec) == 0.0 else 2 * (prec * rec) / (prec + rec))]\n",
        "    return (0.0 if () == 0.0 else len(cm) * (np.prod(f1s)) / (np.sum(f1s)))\n",
        "\n",
        "def remove_seq_suffix(seq):\n",
        "    return [x[:-1] for x in seq]\n",
        "\n",
        "def reverse_seq(seq):\n",
        "    return [x.replace('+','-') if x[-1] == '+' else x.replace('-','+') for x in seq[::-1]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvPDUKD8HM2v"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RLZWEFAoJvJ"
      },
      "source": [
        "Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58aFffPZIVLA"
      },
      "outputs": [],
      "source": [
        "# comma-seperated list fo features to model: AEC,PEC,PC,IC\n",
        "features=[\"AEC\"]\n",
        "\n",
        "# split factor [0.0 to 1.0]\n",
        "split=0.3\n",
        "\n",
        "# maximum vocabulary size\n",
        "max_vocab=1200\n",
        "\n",
        "# sequence length\n",
        "maxlen=200\n",
        "\n",
        "# balance factor [0.0 is downsample to 1.0 is upsample]\n",
        "balance_w=1\n",
        "\n",
        "# top k frequent TFs to remove\n",
        "k=2\n",
        "\n",
        "# gpu number [0 to x]\n",
        "gpu_num=0\n",
        "\n",
        "# number of epochs for training\n",
        "epochs=25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh-Zyc_JKDEs"
      },
      "outputs": [],
      "source": [
        "# read in the raw data sequences as: feature,cell,x1,x2,...xm\n",
        "with gzip.GzipFile(in_path, 'rb') as f:\n",
        "    raw = [row.decode('utf-8').replace('\\n', '').split('\\t') for row in f.readlines()]\n",
        "F = data2dict(raw)\n",
        "\n",
        "# with gzip.GzipFile(in_path, 'rb') as f:\n",
        "#     raw = []\n",
        "#     for row in f.readlines():\n",
        "#         row = row.decode('utf-8').replace('\\n', '').split('\\t')\n",
        "#         raw.append(row[:2] + reverse_seq(row[2:]))\n",
        "# F = data2dict(raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "87VWeOud0jDT"
      },
      "outputs": [],
      "source": [
        "worddict = {}\n",
        "worddict_dir = {}\n",
        "for seq in raw:\n",
        "    for tf in seq[2:]:\n",
        "        worddict[tf[:-1]] = worddict.get(tf[:-1], 0) + 1\n",
        "        worddict_dir[tf] = worddict_dir.get(tf, 0) + 1\n",
        "\n",
        "sorted_worddict = sorted(worddict.items(), key=lambda x:x[1], reverse=True)\n",
        "sorted_worddict_dir = sorted(worddict_dir.items(), key=lambda x:x[1], reverse=True)\n",
        "worddict = {i[0]:i[1] for i in sorted_worddict[:k]}\n",
        "worddict_dir = {i[0]:i[1] for i in sorted_worddict_dir[:k]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnenqP5imRkD",
        "outputId": "7922f811-ecfd-418b-a0ec-7152462d7e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'ZNF384-': 755770, 'ZNF384+': 695515}\n",
            "['AEC', 'IC', 'PEC', 'PC']\n",
            "['RHOXF1+', 'SRY-', 'VAX1-', 'ZNF354A-', 'LBX2+', 'ISL2+', 'ZNF667-', 'CLOCK-', 'HEY2-', 'MYC-', 'NFIX-']\n"
          ]
        }
      ],
      "source": [
        "print(worddict_dir)\n",
        "print(list(F))\n",
        "print(list(F['AEC']['NEURALCREST'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWpIm73406gU"
      },
      "outputs": [],
      "source": [
        "# remove top k frequent TF\n",
        "count = 0\n",
        "for feature in F:\n",
        "    for cell in F[feature]:\n",
        "        for i, row in enumerate(F[feature][cell]):\n",
        "            F[feature][cell][i] = [x for x in row if x not in worddict_dir]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCYfIt4D3206",
        "outputId": "31f1d0b1-6f53-42c9-9f5c-4da5975a2b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['RHOXF1+', 'SRY-', 'VAX1-', 'ZNF354A-', 'LBX2+', 'ISL2+', 'ZNF667-', 'CLOCK-', 'HEY2-', 'MYC-', 'NFIX-']\n"
          ]
        }
      ],
      "source": [
        "print(list(F['AEC']['NEURALCREST'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2HUB7PWoGDC"
      },
      "outputs": [],
      "source": [
        "# apply cell map to F\n",
        "cmap = {'MESENCHYMAL': 'OFC', 'NEURALCREST': 'OFC', 'OSTEOCYTE': 'BACKGROUND',\n",
        "        'HEPATOCYTE': 'BACKGROUND', 'MESOTHELIALEPICARDIUM': 'BACKGROUND', 'NEPHRONPROGENITOR': 'BACKGROUND',\n",
        "        'PANCREAS': 'BACKGROUND', 'PERIPHERALBLOOD': 'BACKGROUND', 'SPLEEN': 'BACKGROUND', 'STOMACH': 'BACKGROUND'}\n",
        "# cmap = {k:k for k in set([c for f in F for c in F[f]])}\n",
        "C = cell_map(F, cmap)\n",
        "C = {feature: C[feature] for feature in features}  # apply only features that are selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWwfnmlSoDGy",
        "outputId": "ab200f52-00c5-4558-efcf-094cfcc68b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80207\n"
          ]
        }
      ],
      "source": [
        "print(len(C['AEC']['OFC']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6XiH_hwoMpd"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u0vGiSuoQMn"
      },
      "outputs": [],
      "source": [
        "#embed_dims,num_heads,ff_dims,batches,drops = [4],[2],[16],[128],[0.3]\n",
        "# embed_dims,num_heads,ff_dims,batches,drops = [2,4,8],[2,4,8],[16,32,64],[32,64,128],[0.4,0.5]\n",
        "embed_dims,num_heads,ff_dims,batches,drops = [2,4,8],[8],[32],[128],[0.4,0.5]\n",
        "hyper_params = []\n",
        "for embed_dim in embed_dims:\n",
        "    for num_head in num_heads:\n",
        "        for ff_dim in ff_dims:\n",
        "            for batch in batches:\n",
        "                for drop in drops:\n",
        "                    hyper_params += [[embed_dim, num_head, ff_dim, batch, drop, balance_w]]\n",
        "\n",
        "class_num = len(get_classes(C))\n",
        "vocab_size = len(sorted(get_vocab(C)))\n",
        "max_vocab = min(max_vocab, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8DuB9-xoSMR",
        "outputId": "476e514d-b4f5-4465-9db9-e77b2e8d2352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "preprocessing data now...\n",
            "using data labeling scheme: {'BACKGROUND': 0, 'OFC': 1}\n",
            "balancing data...\n",
            "balancing training feature=AEC, cell=BACKGROUND\n",
            "balancing training feature=AEC, cell=OFC\n",
            "starting kmer counting...\n",
            "kmer counting tree completed in 31 sec\n",
            "starting generative modeling...\n",
            "generative modeling 161990 sequences in 277 sec\n",
            "balancing test feature=AEC, cell=BACKGROUND\n",
            "balancing test feature=AEC, cell=OFC\n",
            "starting kmer counting...\n",
            "kmer counting tree completed in 7 sec\n",
            "starting generative modeling...\n",
            "generative modeling 46283 sequences in 72 sec\n"
          ]
        }
      ],
      "source": [
        "print('preprocessing data now...')\n",
        "train, test, valid, vec = preprocess_data(C, max_vocab=max_vocab, maxlen=maxlen, split=split, balance_w=balance_w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nslYv2koTjK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JPpkA0Y4BEv"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "cell_idx = get_cell_idx(C)\n",
        "cell_label_str = '_'.join([k+'-%s'%cell_idx[k] for k in sorted(cell_idx)])\n",
        "json_score = out_dir+'/%s.%s.%s.score.json'%('_'.join(sorted(features)),cell_label_str,balance_w)\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%y%m%d%H%M\")\n",
        "jsonl_timestamp = out_dir+'/timestamp.%s.%s.%s.score.jsonl'%('_'.join(sorted(features)),cell_label_str,balance_w)\n",
        "\n",
        "if os.path.exists(json_score):\n",
        "    with open(json_score,'r') as f: score = json.load(f)\n",
        "else: score = {feature: [hyper_params[0],[], 0.0] for feature in C}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ad9wHZ06ZF9e",
        "outputId": "eedacc32-3601-4bd4-beb6-89d51d34a95a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 8ms/step - f1: 0.5083 - loss: 8.2300 - val_f1: 0.4572 - val_loss: 8.1815\n",
            "Epoch 2/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7ms/step - f1: 0.5362 - loss: 8.1025 - val_f1: 0.3340 - val_loss: 8.3388\n",
            "Epoch 3/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 8ms/step - f1: 0.5348 - loss: 8.0174 - val_f1: 0.3333 - val_loss: 9.2637\n",
            "Epoch 4/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8ms/step - f1: 0.5301 - loss: 8.0029 - val_f1: 0.3333 - val_loss: 9.0392\n",
            "Epoch 5/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8ms/step - f1: 0.5246 - loss: 8.0673 - val_f1: 0.5575 - val_loss: 8.0608\n",
            "Epoch 6/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.5198 - loss: 8.1034 - val_f1: 0.3333 - val_loss: 8.5260\n",
            "Epoch 7/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 7ms/step - f1: 0.5195 - loss: 8.1215 - val_f1: 0.3333 - val_loss: 9.1597\n",
            "Epoch 8/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.5256 - loss: 8.0505 - val_f1: 0.3333 - val_loss: 11.6806\n",
            "Epoch 9/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8ms/step - f1: 0.5294 - loss: 8.0119 - val_f1: 0.3333 - val_loss: 8.7969\n",
            "Epoch 10/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.5096 - loss: 8.1981 - val_f1: 0.3679 - val_loss: 8.3674\n",
            "Epoch 11/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.5054 - loss: 8.2626 - val_f1: 0.3657 - val_loss: 8.9430\n",
            "Epoch 12/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.5069 - loss: 8.2361 - val_f1: 0.3332 - val_loss: 8.2300\n",
            "Epoch 13/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 7ms/step - f1: 0.4948 - loss: 8.4214 - val_f1: 0.3427 - val_loss: 8.2602\n",
            "Epoch 14/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.4984 - loss: 8.2646 - val_f1: 0.3333 - val_loss: 10.7136\n",
            "Epoch 15/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.4987 - loss: 8.2644 - val_f1: 0.3333 - val_loss: 8.2990\n",
            "Epoch 16/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.4983 - loss: 8.2765 - val_f1: 0.3333 - val_loss: 8.2995\n",
            "Epoch 17/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.4999 - loss: 8.2717 - val_f1: 0.3333 - val_loss: 8.3414\n",
            "Epoch 18/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.4986 - loss: 8.2747 - val_f1: 0.3333 - val_loss: 8.2746\n",
            "Epoch 19/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 7ms/step - f1: 0.4990 - loss: 8.2619 - val_f1: 0.3333 - val_loss: 8.2612\n",
            "Epoch 20/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.4984 - loss: 8.2665 - val_f1: 0.3333 - val_loss: 8.2587\n",
            "Epoch 21/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.5003 - loss: 8.2655 - val_f1: 0.3333 - val_loss: 8.2870\n",
            "Epoch 22/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.4987 - loss: 8.2673 - val_f1: 0.3333 - val_loss: 8.3075\n",
            "Epoch 23/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 8ms/step - f1: 0.4983 - loss: 8.2657 - val_f1: 0.3333 - val_loss: 8.2987\n",
            "Epoch 24/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 8ms/step - f1: 0.4998 - loss: 8.2688 - val_f1: 0.3333 - val_loss: 8.2968\n",
            "Epoch 25/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.4999 - loss: 8.2547 - val_f1: 0.3333 - val_loss: 8.3207\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
            "\n",
            "Validation score\n",
            "[[    0. 31162.]\n",
            " [    0.  8021.]]\n",
            "[[0.         0.79529388]\n",
            " [0.         0.20470612]]\n",
            "f1 score: feature=AEC, balance=1, f1=0.0\n",
            "Hyperparameters: [2, 8, 32, 128, 0.4, 1]\n",
            "\n",
            "Baseline\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "-------------------------------new session-------------------------------\n",
            "Epoch 1/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 8ms/step - f1: 0.5276 - loss: 8.1545 - val_f1: 0.3333 - val_loss: 10.1085\n",
            "Epoch 2/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 7ms/step - f1: 0.5534 - loss: 7.7737 - val_f1: 0.4997 - val_loss: 9.5072\n",
            "Epoch 3/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.5522 - loss: 7.7191 - val_f1: 0.4321 - val_loss: 10.6072\n",
            "Epoch 4/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.5594 - loss: 7.6160 - val_f1: 0.3375 - val_loss: 13.2965\n",
            "Epoch 5/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.5601 - loss: 7.5778 - val_f1: 0.4074 - val_loss: 12.3385\n",
            "Epoch 6/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.5088 - loss: 11.0870 - val_f1: 0.4870 - val_loss: 12.3083\n",
            "Epoch 7/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.5288 - loss: 8.1066 - val_f1: 0.5795 - val_loss: 7.3013\n",
            "Epoch 8/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8ms/step - f1: 0.5292 - loss: 8.0188 - val_f1: 0.5414 - val_loss: 8.3310\n",
            "Epoch 9/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.5311 - loss: 7.9557 - val_f1: 0.4518 - val_loss: 9.4219\n",
            "Epoch 10/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.5397 - loss: 7.9244 - val_f1: 0.5767 - val_loss: 7.7140\n",
            "Epoch 11/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.5519 - loss: 7.7672 - val_f1: 0.5380 - val_loss: 7.7658\n",
            "Epoch 12/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 8ms/step - f1: 0.5534 - loss: 7.6874 - val_f1: 0.5208 - val_loss: 9.0424\n",
            "Epoch 13/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 7ms/step - f1: 0.5553 - loss: 7.6920 - val_f1: 0.5407 - val_loss: 8.5832\n",
            "Epoch 14/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 7ms/step - f1: 0.5578 - loss: 7.6622 - val_f1: 0.5775 - val_loss: 7.4572\n",
            "Epoch 15/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.5641 - loss: 7.5418 - val_f1: 0.3377 - val_loss: 13.1710\n",
            "Epoch 16/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.5671 - loss: 7.5520 - val_f1: 0.5524 - val_loss: 8.6303\n",
            "Epoch 17/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.5659 - loss: 7.4933 - val_f1: 0.4697 - val_loss: 8.1208\n",
            "Epoch 18/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.5263 - loss: 7.9222 - val_f1: 0.4864 - val_loss: 7.9818\n",
            "Epoch 19/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 7ms/step - f1: 0.5506 - loss: 7.6747 - val_f1: 0.5517 - val_loss: 7.9417\n",
            "Epoch 20/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 7ms/step - f1: 0.5624 - loss: 7.5600 - val_f1: 0.5845 - val_loss: 7.1983\n",
            "Epoch 21/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.5688 - loss: 7.4708 - val_f1: 0.5736 - val_loss: 7.2968\n",
            "Epoch 22/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.5690 - loss: 7.5130 - val_f1: 0.5783 - val_loss: 7.2198\n",
            "Epoch 23/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.5784 - loss: 7.4688 - val_f1: 0.5147 - val_loss: 7.9287\n",
            "Epoch 24/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.5644 - loss: 7.4888 - val_f1: 0.5770 - val_loss: 7.3487\n",
            "Epoch 25/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.5753 - loss: 7.4985 - val_f1: 0.5522 - val_loss: 8.1287\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
            "\n",
            "Validation score\n",
            "[[21400.  9762.]\n",
            " [ 4921.  3100.]]\n",
            "[[0.54615522 0.24913866]\n",
            " [0.12559018 0.07911594]]\n",
            "f1 score: feature=AEC, balance=1, f1=0.4245124929310575\n",
            "Hyperparameters: [2, 8, 32, 128, 0.5, 1]\n",
            "\n",
            "Baseline\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "-------------------------------new session-------------------------------\n",
            "Epoch 1/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 8ms/step - f1: 0.5319 - loss: 8.0796 - val_f1: 0.5770 - val_loss: 7.8066\n",
            "Epoch 2/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 7ms/step - f1: 0.5967 - loss: 7.1845 - val_f1: 0.6072 - val_loss: 6.8440\n",
            "Epoch 3/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 8ms/step - f1: 0.6132 - loss: 6.8666 - val_f1: 0.6211 - val_loss: 6.5704\n",
            "Epoch 4/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8ms/step - f1: 0.6263 - loss: 6.6328 - val_f1: 0.6260 - val_loss: 6.5833\n",
            "Epoch 5/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 7ms/step - f1: 0.6337 - loss: 6.4510 - val_f1: 0.6283 - val_loss: 6.5984\n",
            "Epoch 6/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.6393 - loss: 6.3474 - val_f1: 0.6274 - val_loss: 6.5090\n",
            "Epoch 7/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 8ms/step - f1: 0.6427 - loss: 6.2918 - val_f1: 0.6262 - val_loss: 6.5791\n",
            "Epoch 8/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.6472 - loss: 6.2146 - val_f1: 0.6318 - val_loss: 6.4651\n",
            "Epoch 9/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 7ms/step - f1: 0.6485 - loss: 6.1841 - val_f1: 0.6287 - val_loss: 6.4734\n",
            "Epoch 10/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.6508 - loss: 6.1624 - val_f1: 0.6298 - val_loss: 6.3996\n",
            "Epoch 11/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 8ms/step - f1: 0.6545 - loss: 6.1090 - val_f1: 0.6299 - val_loss: 6.4091\n",
            "Epoch 12/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8ms/step - f1: 0.6569 - loss: 6.0804 - val_f1: 0.6153 - val_loss: 7.1411\n",
            "Epoch 13/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 7ms/step - f1: 0.6595 - loss: 6.0098 - val_f1: 0.6272 - val_loss: 6.5043\n",
            "Epoch 14/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.6610 - loss: 5.9944 - val_f1: 0.6294 - val_loss: 6.4184\n",
            "Epoch 15/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.6610 - loss: 6.0042 - val_f1: 0.6294 - val_loss: 6.4147\n",
            "Epoch 16/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.6619 - loss: 5.9717 - val_f1: 0.6288 - val_loss: 6.4463\n",
            "Epoch 17/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.6626 - loss: 5.9538 - val_f1: 0.6256 - val_loss: 6.5779\n",
            "Epoch 18/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 7ms/step - f1: 0.6625 - loss: 5.9480 - val_f1: 0.6289 - val_loss: 6.4316\n",
            "Epoch 19/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.6624 - loss: 5.9536 - val_f1: 0.6266 - val_loss: 6.5007\n",
            "Epoch 20/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8ms/step - f1: 0.6659 - loss: 5.8819 - val_f1: 0.6282 - val_loss: 6.4338\n",
            "Epoch 21/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.6653 - loss: 5.9007 - val_f1: 0.6276 - val_loss: 6.4480\n",
            "Epoch 22/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.6664 - loss: 5.8768 - val_f1: 0.6269 - val_loss: 6.4779\n",
            "Epoch 23/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.6657 - loss: 5.9028 - val_f1: 0.6279 - val_loss: 6.4491\n",
            "Epoch 24/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.6669 - loss: 5.8673 - val_f1: 0.6218 - val_loss: 6.6766\n",
            "Epoch 25/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.6669 - loss: 5.8873 - val_f1: 0.6248 - val_loss: 6.5601\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
            "\n",
            "Validation score\n",
            "[[20580. 10582.]\n",
            " [ 4695.  3326.]]\n",
            "[[0.52522778 0.2700661 ]\n",
            " [0.11982237 0.08488375]]\n",
            "f1 score: feature=AEC, balance=1, f1=0.42847069077580435\n",
            "Hyperparameters: [4, 8, 32, 128, 0.4, 1]\n",
            "\n",
            "Baseline\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "-------------------------------new session-------------------------------\n",
            "Epoch 1/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 8ms/step - f1: 0.5506 - loss: 7.9684 - val_f1: 0.5827 - val_loss: 7.2809\n",
            "Epoch 2/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 7ms/step - f1: 0.5860 - loss: 7.3191 - val_f1: 0.5903 - val_loss: 7.1704\n",
            "Epoch 3/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 8ms/step - f1: 0.6013 - loss: 7.0887 - val_f1: 0.6097 - val_loss: 6.8183\n",
            "Epoch 4/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.6155 - loss: 6.8607 - val_f1: 0.6155 - val_loss: 6.8121\n",
            "Epoch 5/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 8ms/step - f1: 0.6292 - loss: 6.6304 - val_f1: 0.6198 - val_loss: 6.8651\n",
            "Epoch 6/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 7ms/step - f1: 0.6357 - loss: 6.5300 - val_f1: 0.6268 - val_loss: 6.5349\n",
            "Epoch 7/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 7ms/step - f1: 0.6410 - loss: 6.4079 - val_f1: 0.6284 - val_loss: 6.5314\n",
            "Epoch 8/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 7ms/step - f1: 0.6430 - loss: 6.3470 - val_f1: 0.6306 - val_loss: 6.4721\n",
            "Epoch 9/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.6458 - loss: 6.3290 - val_f1: 0.6302 - val_loss: 6.4361\n",
            "Epoch 10/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 7ms/step - f1: 0.6478 - loss: 6.2582 - val_f1: 0.6312 - val_loss: 6.3756\n",
            "Epoch 11/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 7ms/step - f1: 0.6496 - loss: 6.1930 - val_f1: 0.6282 - val_loss: 6.5526\n",
            "Epoch 12/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 8ms/step - f1: 0.6511 - loss: 6.1777 - val_f1: 0.6324 - val_loss: 6.3718\n",
            "Epoch 13/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 8ms/step - f1: 0.6525 - loss: 6.1544 - val_f1: 0.6324 - val_loss: 6.3602\n",
            "Epoch 14/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 7ms/step - f1: 0.6551 - loss: 6.0880 - val_f1: 0.6173 - val_loss: 7.1487\n",
            "Epoch 15/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 7ms/step - f1: 0.6543 - loss: 6.0987 - val_f1: 0.6213 - val_loss: 6.9201\n",
            "Epoch 16/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 7ms/step - f1: 0.6556 - loss: 6.0638 - val_f1: 0.6319 - val_loss: 6.3848\n",
            "Epoch 17/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.6570 - loss: 6.0403 - val_f1: 0.6198 - val_loss: 7.0066\n",
            "Epoch 18/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.6580 - loss: 6.0113 - val_f1: 0.6313 - val_loss: 6.3784\n",
            "Epoch 19/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 7ms/step - f1: 0.6599 - loss: 5.9791 - val_f1: 0.6296 - val_loss: 6.4571\n",
            "Epoch 20/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 7ms/step - f1: 0.6611 - loss: 5.9521 - val_f1: 0.6240 - val_loss: 6.7374\n",
            "Epoch 21/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.6595 - loss: 5.9824 - val_f1: 0.6181 - val_loss: 7.0938\n",
            "Epoch 22/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 7ms/step - f1: 0.6628 - loss: 5.9334 - val_f1: 0.6295 - val_loss: 6.4212\n",
            "Epoch 23/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.6627 - loss: 5.9182 - val_f1: 0.6259 - val_loss: 6.6214\n",
            "Epoch 24/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 7ms/step - f1: 0.6633 - loss: 5.9274 - val_f1: 0.6289 - val_loss: 6.4422\n",
            "Epoch 25/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 7ms/step - f1: 0.6646 - loss: 5.8961 - val_f1: 0.6145 - val_loss: 7.2500\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\n",
            "Validation score\n",
            "[[23334.  7828.]\n",
            " [ 5504.  2517.]]\n",
            "[[0.59551336 0.19978052]\n",
            " [0.14046908 0.06423704]]\n",
            "f1 score: feature=AEC, balance=1, f1=0.40534500130409973\n",
            "Hyperparameters: [4, 8, 32, 128, 0.5, 1]\n",
            "\n",
            "Baseline\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "-------------------------------new session-------------------------------\n",
            "Epoch 1/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 9ms/step - f1: 0.5245 - loss: 8.1068 - val_f1: 0.5888 - val_loss: 7.1777\n",
            "Epoch 2/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 7ms/step - f1: 0.5950 - loss: 7.1922 - val_f1: 0.5856 - val_loss: 7.8992\n",
            "Epoch 3/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.6179 - loss: 6.8144 - val_f1: 0.6239 - val_loss: 6.5358\n",
            "Epoch 4/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8ms/step - f1: 0.6354 - loss: 6.4459 - val_f1: 0.6309 - val_loss: 6.3907\n",
            "Epoch 5/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 7ms/step - f1: 0.6427 - loss: 6.2840 - val_f1: 0.6284 - val_loss: 6.5119\n",
            "Epoch 6/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 8ms/step - f1: 0.6481 - loss: 6.1822 - val_f1: 0.6314 - val_loss: 6.4049\n",
            "Epoch 7/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 7ms/step - f1: 0.6510 - loss: 6.1146 - val_f1: 0.6323 - val_loss: 6.3740\n",
            "Epoch 8/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 8ms/step - f1: 0.6540 - loss: 6.0699 - val_f1: 0.6308 - val_loss: 6.4357\n",
            "Epoch 9/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 7ms/step - f1: 0.6576 - loss: 6.0202 - val_f1: 0.6313 - val_loss: 6.3941\n",
            "Epoch 10/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 8ms/step - f1: 0.6595 - loss: 5.9794 - val_f1: 0.6280 - val_loss: 6.5216\n",
            "Epoch 11/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 7ms/step - f1: 0.6596 - loss: 5.9764 - val_f1: 0.6278 - val_loss: 6.5044\n",
            "Epoch 12/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 8ms/step - f1: 0.6614 - loss: 5.9476 - val_f1: 0.6276 - val_loss: 6.4794\n",
            "Epoch 13/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 8ms/step - f1: 0.6620 - loss: 5.9244 - val_f1: 0.6284 - val_loss: 6.4570\n",
            "Epoch 14/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 8ms/step - f1: 0.6641 - loss: 5.9145 - val_f1: 0.6281 - val_loss: 6.4469\n",
            "Epoch 15/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 8ms/step - f1: 0.6639 - loss: 5.9148 - val_f1: 0.6274 - val_loss: 6.4607\n",
            "Epoch 16/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 8ms/step - f1: 0.6663 - loss: 5.8645 - val_f1: 0.6276 - val_loss: 6.4509\n",
            "Epoch 17/25\n",
            "\u001b[1m13634/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 8ms/step - f1: 0.6664 - loss: 5.8593 - val_f1: 0.6229 - val_loss: 6.6210\n",
            "Epoch 18/25\n",
            "\u001b[1m 8920/13634\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - f1: 0.6664 - loss: 5.8809"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-e39a85e0f0f1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                 restore_best_weights=True)\n\u001b[1;32m     28\u001b[0m             ]\n\u001b[0;32m---> 29\u001b[0;31m             history = models[feature].fit(\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "models = {}\n",
        "for feature in C:\n",
        "    for hyper in hyper_params:\n",
        "        embed_dim, num_head, ff_dim, batch, drop, bl = hyper\n",
        "        with tf.device('/device:GPU:%s'%gpu_num):\n",
        "            # -----------------------------------------------------------------------\n",
        "            inputs = layers.Input(shape=(maxlen,))\n",
        "            embedding_layer = TokenAndPositionEmbedding(maxlen, max_vocab, embed_dim)\n",
        "            x = embedding_layer(inputs)\n",
        "            transformer_block = TransformerBlock(embed_dim, num_head, ff_dim)\n",
        "            x = transformer_block(x)\n",
        "            x = layers.GlobalAveragePooling1D()(x)\n",
        "            x = layers.Dropout(0.2)(x)\n",
        "            x = layers.Dense(class_num * 64, activation=\"relu\")(x)\n",
        "            x = layers.Dropout(drop)(x)\n",
        "            outputs = layers.Dense(class_num, activation=\"softmax\")(x)\n",
        "            models[feature] = keras.Model(inputs=inputs, outputs=outputs)\n",
        "            models[feature].compile(optimizer=keras.optimizers.Adam(5e-5),\n",
        "                                    loss=c2_f1_loss,\n",
        "                                    metrics=[F1()])\n",
        "            models[feature].name = feature\n",
        "\n",
        "            # training-----------------------------------------------------------------------\n",
        "            callbacks = [\n",
        "                keras.callbacks.EarlyStopping(monitor=\"val_f1\",\n",
        "                                                min_delta=1e-2,patience=5,mode='max',verbose=1,\n",
        "                                                restore_best_weights=True)\n",
        "            ]\n",
        "            history = models[feature].fit(\n",
        "                x=train[feature][0], y=train[feature][1], epochs=epochs,\n",
        "                validation_data=(test[feature][0],test[feature][1])\n",
        "            )\n",
        "\n",
        "            # validation score-----------------------------------------------------------------------\n",
        "            true = valid[feature][1]\n",
        "            pred = np.argmax(models[feature].predict(valid[feature][0]), axis=1)\n",
        "            cm = confusion_matrix(true, pred, c=class_num)\n",
        "            cm0 = (cm if np.sum(cm) == 0.0 else cm / np.sum(cm))\n",
        "            print(\"\\nValidation score\")\n",
        "            print(cm)\n",
        "            print(cm0)\n",
        "            f1 = f1_score(cm)\n",
        "            if f1 >= score[feature][-1]:\n",
        "                print(\n",
        "                    '-------------------------------new high f1 score: feature=%s, balance=%s, f1=%s -------------------------------\\n%s'\\\n",
        "                    %(feature,balance_w,f1,hyper))\n",
        "                score[feature] = [hyper, [list(l) for l in list(cm)], f1]\n",
        "                score[\"timestamp\"] = timestamp\n",
        "                weight_path    = out_dir+'/%s.%s.%s.weights.h5'%(feature,cell_label_str,balance_w)\n",
        "                # weight_path    = '/'.join(in_path.split('/')[:-1])+'/%s.%s.%s.weights.h5'%(feature,cell_label_str,balance_w)\n",
        "                if os.path.exists(json_score):\n",
        "                    with open(json_score,'r') as f:  old_score          = json.load(f)\n",
        "                    if feature in old_score:         old_score[feature] = score[feature]\n",
        "                    with open(json_score,'w') as f:\n",
        "                        json.dump(score,f)\n",
        "                        models[feature].save_weights(weight_path)\n",
        "                else:\n",
        "                    with open(json_score,'w') as f:\n",
        "                        json.dump(score,f)\n",
        "                        models[feature].save_weights(weight_path)\n",
        "                # JSONL format with timestamp\n",
        "                if os.path.exists(jsonl_timestamp):\n",
        "                    with open(jsonl_timestamp, 'a') as f:\n",
        "                        f.write(json.dumps(score) + '\\n')\n",
        "                else:\n",
        "                    with open(jsonl_timestamp,'w') as f:\n",
        "                        f.write(json.dumps(score) + '\\n')\n",
        "            else:\n",
        "                print('f1 score: feature=%s, balance=%s, f1=%s'%(feature,balance_w, f1))\n",
        "                print(\"Hyperparameters:\", hyper)\n",
        "\n",
        "            print(\"\\nBaseline\")\n",
        "            print({cell: len(F[feature][cell]) for cell in F[feature]})\n",
        "            min_score = max([len(F[feature][cell]) for cell in F[feature]]) / sum(\n",
        "                [len(F[feature][cell]) for cell in F[feature]])\n",
        "            print(min_score)\n",
        "            print({cell: len(C[feature][cell]) for cell in C[feature]})\n",
        "            min_score = max([len(C[feature][cell]) for cell in C[feature]]) / sum(\n",
        "                [len(C[feature][cell]) for cell in C[feature]])\n",
        "            print(min_score)\n",
        "            print(\"-------------------------------new session-------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "u-psvXpKG_x8",
        "9YRp0xKLHDAI"
      ],
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "130r0o1OABt7BqiCKFKPVwKS9cfZf0aKZ",
      "authorship_tag": "ABX9TyOhspn+jXvDUrCl9sCFcItk"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}