{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-psvXpKG_x8"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D9OdA0JYgif",
        "outputId": "879b7af1-dac5-4209-c2cc-23193d0fc45d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "print(gpus)\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e: print(e)\n",
        "\n",
        "import re\n",
        "import json\n",
        "import gzip\n",
        "import numpy as np\n",
        "import argparse\n",
        "\n",
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers\n",
        "from keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NFwoVcfHYx7",
        "outputId": "57aa7805-1b97-483c-9390-b843ba4d76fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from os import path\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "ROOT_DIR=\"/content/drive/MyDrive/Shared/TFBS_Cell_project/\"\n",
        "in_path=ROOT_DIR+\"cellvar.db.tfbs_seq.tsv.gz\"\n",
        "out_dir=ROOT_DIR+\"out\"\n",
        "\n",
        "if path.exists(out_dir) == False:\n",
        "    os.mkdir(out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EiRPOh24YoMS"
      },
      "outputs": [],
      "source": [
        "# des = \"\"\"\n",
        "# TFBS sequence training/learning tool\n",
        "# (C) Timothy James Becker, 05/03/24-07/08/24, version=0.0.1\"\"\"\n",
        "# parser = argparse.ArgumentParser(description=des, formatter_class=argparse.RawTextHelpFormatter)\n",
        "# # need the split, max vocab, maxlen, balance, cmap,tsv.gz input file\n",
        "# parser.add_argument('--in_path', type=str, help='cellvar.db.tfbs_seq.tsv.gz traing input file')\n",
        "# parser.add_argument('--out_dir', type=str, help='output directory')\n",
        "# parser.add_argument('--features', type=str, help='comma-seperated list fo features to model: AEC,PEC,PC,IC')\n",
        "# parser.add_argument('--split', type=float, help='split factor [0.0 to 1.0]')\n",
        "# parser.add_argument('--vocab', type=int, help='maximum vocabulary size')\n",
        "# parser.add_argument('--len', type=int, help='sequence length')\n",
        "# parser.add_argument('--balance', type=float, help='balance factor [0.0 is downsample to 1.0 is upsample]')\n",
        "# parser.add_argument('--gpu', type=int, help='gpu number [0 to x]')\n",
        "# args = parser.parse_args()\n",
        "\n",
        "# in_path = args.in_path\n",
        "# features = args.features.split(',')\n",
        "# features = set([feature.upper() for feature in features]).intersection(set(['AEC', 'PEC', 'PC', 'IC']))\n",
        "# split = args.split\n",
        "# max_vocab = args.vocab\n",
        "# maxlen = args.len\n",
        "# balance_w = args.balance\n",
        "# gpu_num = args.gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YRp0xKLHDAI"
      },
      "source": [
        "## Network layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHNmYBMAYy48"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.embed_dim,self.num_heads,self.ff_dim,self.rate = embed_dim, num_heads, ff_dim, rate\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim), ]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.maxlen,self.vocab_size,self.embed_dim = maxlen, vocab_size, embed_dim\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = ops.shape(x)[-1]\n",
        "        positions = ops.arange(start=0, stop=maxlen, step=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_yeyVpJY5Qa"
      },
      "outputs": [],
      "source": [
        "class F1(keras.metrics.Metric):\n",
        "    def __init__(self, name='f1'):\n",
        "        super().__init__(name=name)\n",
        "        self.sum_t0   = self.add_variable(shape=(),initializer='zeros',name='sum_t0')\n",
        "        self.sum_p0   = self.add_variable(shape=(),initializer='zeros',name='sum_p0')\n",
        "        self.sum_t0p0 = self.add_variable(shape=(),initializer='zeros',name='sum_t0p0')\n",
        "        self.sum_t1   = self.add_variable(shape=(),initializer='zeros',name='sum_t1')\n",
        "        self.sum_p1   = self.add_variable(shape=(),initializer='zeros',name='sum_p1')\n",
        "        self.sum_t1p1 = self.add_variable(shape=(),initializer='zeros',name='sum_t1p1')\n",
        "        self.f1       = self.add_variable(shape=(),initializer='zeros',name='f1')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        t0 = -1 * (y_true - 1) + 0.0\n",
        "        t1 = y_true\n",
        "        p0 = ops.round(y_pred[:, 0],0)\n",
        "        p1 = ops.round(y_pred[:, 1],0)\n",
        "        self.sum_t0.assign(self.sum_t0+ops.sum(t0))\n",
        "        self.sum_p0.assign(self.sum_p0+ops.sum(p0))\n",
        "        self.sum_t0p0.assign(self.sum_t0p0+ops.sum(t0*p0))\n",
        "        self.sum_t1.assign( self.sum_t1+ops.sum(t1))\n",
        "        self.sum_p1.assign(self.sum_p1+ops.sum(p1))\n",
        "        self.sum_t1p1.assign(self.sum_t1p1+ops.sum(t1*p1))\n",
        "\n",
        "    def result(self):\n",
        "        prec0 = ops.divide_no_nan(self.sum_t0p0,self.sum_t0)\n",
        "        rec0  = ops.divide_no_nan(self.sum_t0p0,self.sum_p0)\n",
        "        prec1 = ops.divide_no_nan(self.sum_t1p1,self.sum_t1)\n",
        "        rec1  = ops.divide_no_nan(self.sum_t1p1,self.sum_p1)\n",
        "        f1_0  = 2.0*ops.divide_no_nan(prec0*rec0,prec0+rec0)\n",
        "        f1_1  = 2.0*ops.divide_no_nan(prec1*rec1,prec1+rec1)\n",
        "        self.f1.assign((f1_0+f1_1)/2.0)\n",
        "        return self.f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSak6Pz3HIbA"
      },
      "source": [
        "## Helper function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcCFvAiTY-qK"
      },
      "outputs": [],
      "source": [
        "def c2_f1_loss(y_true, y_pred):\n",
        "    t0 = -1 * (y_true - 1) + 0.0\n",
        "    t1 = y_true\n",
        "    p0 = y_pred[:, 0]\n",
        "    p1 = y_pred[:, 1]\n",
        "    e10 = t1*p0\n",
        "    e01 = t0*p1\n",
        "    e = ops.sum(e10) + ops.sum(e01)\n",
        "    x1 = ops.sum(t1 * p0) / e\n",
        "    x2 = ops.sum(t0 * p1) / e\n",
        "    f1 = 1.0 - 2.0 * (x1 * x2) / (x1 + x2)\n",
        "    return ops.sum(f1 * e10) + ops.sum(f1 * e01)\n",
        "\n",
        "def data2dict(raw):\n",
        "    F = {}\n",
        "    for row in raw:\n",
        "        feature, cell = row[:2]\n",
        "        if feature not in F:       F[feature] = {}\n",
        "        if cell not in F[feature]: F[feature][cell] = []\n",
        "        F[feature][cell] += [row[2:]]\n",
        "    return F\n",
        "\n",
        "def split_num(s):\n",
        "    match = re.match(r\"([a-z]*)([0-9]+)([a-z]*)\", s, re.I)\n",
        "    if match:\n",
        "        items = list(match.groups())\n",
        "    else:\n",
        "        items = [s]\n",
        "    while items[-1] == '': items = items[:-1]\n",
        "    return items\n",
        "\n",
        "def conv(s):\n",
        "    ss = split_num(s)\n",
        "    t = ''\n",
        "    for x in ss:\n",
        "        if x.isdigit():\n",
        "            t += chr(int(x) + ord('z') + 1)\n",
        "        else:\n",
        "            t += x\n",
        "    return t\n",
        "\n",
        "def edit_sim(s1, s2, w=[0, 1, 1, 1]):\n",
        "    s1 = conv(s1.replace('+', '').replace('-', ''))\n",
        "    s2 = conv(s2.replace('+', '').replace('-', ''))\n",
        "    if len(s1) < len(s2): s1, s2 = s2, s1\n",
        "    u, v = len(s1), len(s2)\n",
        "    d = [[0 for col in range(v + 1)] for row in range(u + 1)]\n",
        "    for i in range(0, u + 1): d[i][0] = i\n",
        "    for j in range(0, v + 1): d[0][j] = j\n",
        "    for j in range(1, v + 1):\n",
        "        for i in range(1, u + 1):\n",
        "            if s1[i - 1] == s2[j - 1]:\n",
        "                d[i][j] = d[i - 1][j - 1] + w[0]\n",
        "            else:\n",
        "                d[i][j] = min(d[i - 1][j] + w[1], d[i][j - 1] + w[2], d[i - 1][j - 1] + w[3])\n",
        "    return 1.0 - d[u][v] / max(len(s1), len(s2))\n",
        "\n",
        "# given sequences F[feature][cell] = [['RUNX2+',...],[],[],...] with len n, up-sample to target value m>n\n",
        "# up sampling should use a generative model, something like a kmer=3 distribution...\n",
        "def upsample_seqs(teqs, m, strings=True):\n",
        "    if strings:\n",
        "        seqs = [seq.split(' ') for seq in teqs]\n",
        "    else:\n",
        "        seqs = teqs\n",
        "    H = {}\n",
        "    for seq in seqs:\n",
        "        if len(seqs) >= 2:\n",
        "            for i in range(0, len(seq) - 1, 1):\n",
        "                a, b = seq[i], seq[i + 1]\n",
        "                if a not in H:    H[a] = {}\n",
        "                if b not in H[a]:\n",
        "                    H[a][b] = 1\n",
        "                else:\n",
        "                    H[a][b] += 1\n",
        "            for i in range(len(seq) - 1, 0, -1):\n",
        "                a, b = seq[i].replace('+', '-'), seq[i - 1].replace('-', '+')\n",
        "                if a not in H:    H[a] = {}\n",
        "                if b not in H[a]:\n",
        "                    H[a][b] = 1\n",
        "                else:\n",
        "                    H[a][b] += 1\n",
        "    G, H = [], {h: {c: H[h][c] for c in sorted(H[h])} for h in sorted(H)}\n",
        "    ss = list(np.random.choice(list(H), m, replace=True))\n",
        "    for i in range(len(ss)):\n",
        "        s, g, n = ss[i], [], np.random.choice([len(seq) for seq in seqs])\n",
        "        for i in range(n):\n",
        "            g += [s]\n",
        "            if s in H:\n",
        "                s = np.random.choice(list(H[s]))\n",
        "            else:\n",
        "                s = np.random.choice(ss)\n",
        "        G += [g]\n",
        "    if strings: G = [' '.join(seq) for seq in G]\n",
        "    return G\n",
        "\n",
        "def get_cell_idx(D):\n",
        "    cells = sorted(list(set([tuple(sorted(D[feature])) for feature in D]))[0])\n",
        "    cell_idx = {cells[i]: i for i in range(len(cells))}\n",
        "    return cell_idx\n",
        "\n",
        "def data_partition(D, split=0.3, shuffle=True,\n",
        "                    balance_w=None):  # will take 70% for training, 20% for test and 10% for validation of each stratification, using spilt=0.3\n",
        "    train_x, train_y, test_x, test_y, valid_x, valid_y = {}, {}, {}, {}, {}, {}\n",
        "    cells = sorted(list(set([tuple(sorted(D[feature])) for feature in D]))[0])\n",
        "    cell_idx = {cells[i]: i for i in range(len(cells))}\n",
        "    print('using data labeling scheme: %s'%cell_idx)\n",
        "    for feature in D:\n",
        "        train_x[feature], train_y[feature] = {}, {}\n",
        "        test_x[feature], test_y[feature] = {}, {}\n",
        "        valid_x[feature], valid_y[feature] = {}, {}\n",
        "        for cell in sorted(D[feature]):\n",
        "            if cell in cell_idx:\n",
        "                n = len(D[feature][cell])\n",
        "                u = int(round(n * (1.0 - split)))\n",
        "                v = int(round(2 * n * split / 3.0))\n",
        "                u_idx = np.random.choice(range(n), u, replace=False)\n",
        "                v_idx = np.random.choice(list(set(range(n)).difference(set(u_idx))), v, replace=False)\n",
        "                w_idx = set(range(n)).difference(set(u_idx).union(set(v_idx)))\n",
        "                train_x[feature][cell] = [' '.join(D[feature][cell][i]) for i in u_idx]\n",
        "                test_x[feature][cell] = [' '.join(D[feature][cell][i]) for i in v_idx]\n",
        "                valid_x[feature][cell] = [' '.join(D[feature][cell][i]) for i in w_idx]\n",
        "\n",
        "    if balance_w is not None:  # balance the data using a variable 0.0-1.0 up/down sampling point\n",
        "        print('balancing data...')\n",
        "        for feature in train_x:\n",
        "            min_class = min([len(train_x[feature][cell]) for cell in train_x[feature]])\n",
        "            max_class = max([len(train_x[feature][cell]) for cell in train_x[feature]])\n",
        "            mid_class = int(round(min_class + balance_w * (max_class - min_class)))\n",
        "            for cell in sorted(train_x[feature]):\n",
        "                print('balancing training feature=%s, cell=%s' % (feature, cell))\n",
        "                fc_len = len(train_x[feature][cell])\n",
        "                if fc_len >= mid_class:\n",
        "                    train_x[feature][cell] = [train_x[feature][cell][i] for i in\n",
        "                                                np.random.choice(range(fc_len), mid_class, replace=False)]\n",
        "                else:\n",
        "                    train_x[feature][cell] += upsample_seqs(train_x[feature][cell], mid_class - fc_len,\n",
        "                                                            strings=True)\n",
        "        for feature in test_x:\n",
        "            min_class = min([len(test_x[feature][cell]) for cell in test_x[feature]])\n",
        "            max_class = max([len(test_x[feature][cell]) for cell in test_x[feature]])\n",
        "            mid_class = int(round(min_class + balance_w * (max_class - min_class)))\n",
        "            for cell in sorted(test_x[feature]):\n",
        "                print('balancing test feature=%s, cell=%s' % (feature, cell))\n",
        "                fc_len = len(test_x[feature][cell])\n",
        "                if fc_len >= mid_class:\n",
        "                    test_x[feature][cell] = [test_x[feature][cell][i] for i in\n",
        "                                                np.random.choice(range(fc_len), mid_class, replace=False)]\n",
        "                else:\n",
        "                    test_x[feature][cell] += upsample_seqs(test_x[feature][cell], mid_class - fc_len, strings=True)\n",
        "        # for feature in valid_x:\n",
        "        #     min_class = min([len(valid_x[feature][cell]) for cell in valid_x[feature]])\n",
        "        #     max_class = max([len(valid_x[feature][cell]) for cell in valid_x[feature]])\n",
        "        #     mid_class = int(round(min_class + balance_w * (max_class - min_class)))\n",
        "        #     for cell in valid_x[feature]:\n",
        "        #         print('balancing valid feature=%s, cell=%s' % (feature, cell))\n",
        "        #         fc_len = len(valid_x[feature][cell])\n",
        "        #         if fc_len >= mid_class:\n",
        "        #             valid_x[feature][cell] = [valid_x[feature][cell][i] for i in\n",
        "        #                                       np.random.choice(range(fc_len), mid_class, replace=False)]\n",
        "        #         else:\n",
        "        #             valid_x[feature][cell] += upsample_seqs(valid_x[feature][cell], mid_class - fc_len,\n",
        "        #                                                     strings=True)\n",
        "\n",
        "    for feature in train_x:\n",
        "        X, Y = [], []\n",
        "        for cell in sorted(train_x[feature]):\n",
        "            X += train_x[feature][cell]\n",
        "            Y += [cell_idx[cell] for i in range(len(train_x[feature][cell]))]\n",
        "        train_x[feature], train_y[feature] = X, Y\n",
        "    for feature in test_x:\n",
        "        X, Y = [], []\n",
        "        for cell in sorted(test_x[feature]):\n",
        "            X += test_x[feature][cell]\n",
        "            Y += [cell_idx[cell] for i in range(len(test_x[feature][cell]))]\n",
        "        test_x[feature], test_y[feature] = X, Y\n",
        "        X, Y = [], []\n",
        "    for feature in valid_x:\n",
        "        for cell in sorted(valid_x[feature]):\n",
        "            X += valid_x[feature][cell]\n",
        "            Y += [cell_idx[cell] for i in range(len(valid_x[feature][cell]))]\n",
        "        valid_x[feature], valid_y[feature] = X, Y\n",
        "\n",
        "    if shuffle:  # have the correct number of examples but the labels are not shuffled\n",
        "        for feature in D:\n",
        "            n = len(train_x[feature])\n",
        "            idx = np.random.choice(range(n), n, replace=False)\n",
        "            train_x[feature] = [train_x[feature][i] for i in idx]\n",
        "            train_y[feature] = [train_y[feature][i] for i in idx]\n",
        "\n",
        "            u = len(test_x[feature])\n",
        "            idx = np.random.choice(range(u), u, replace=False)\n",
        "            test_x[feature] = [test_x[feature][i] for i in idx]\n",
        "            test_y[feature] = [test_y[feature][i] for i in idx]\n",
        "\n",
        "            v = len(valid_x[feature])\n",
        "            idx = np.random.choice(range(v), v, replace=False)\n",
        "            valid_x[feature] = [valid_x[feature][i] for i in idx]\n",
        "            valid_y[feature] = [valid_y[feature][i] for i in idx]\n",
        "\n",
        "    return train_x, train_y, test_x, test_y, valid_x, valid_y\n",
        "\n",
        "def preprocess_data(D, max_vocab=None, maxlen=2000, split=0.4, balance_w=0.5, dt=np.float32):\n",
        "    train_x, train_y, test_x, test_y, valid_x, valid_y = data_partition(D, split=split, balance_w=balance_w)\n",
        "    vocab = sorted(get_vocab(D))\n",
        "    vocab_size = len(vocab)\n",
        "    vectorize_layer = TextVectorization(\n",
        "        standardize=\"lower\",\n",
        "        max_tokens=min(vocab_size, max_vocab),\n",
        "        output_mode=\"int\",\n",
        "        output_sequence_length=maxlen\n",
        "    )\n",
        "    vectorize_layer.adapt(vocab)\n",
        "    train, test, valid = {}, {}, {}\n",
        "    for feature in D:\n",
        "        train[feature] = (\n",
        "        np.array(vectorize_layer(train_x[feature]), dtype=dt), np.array(train_y[feature], dtype=dt))\n",
        "        test[feature] = (np.array(vectorize_layer(test_x[feature]), dtype=dt), np.array(test_y[feature], dtype=dt))\n",
        "        valid[feature] = (\n",
        "        np.array(vectorize_layer(valid_x[feature]), dtype=dt), np.array(valid_y[feature], dtype=dt))\n",
        "    return train, test, valid, vectorize_layer\n",
        "\n",
        "def get_vocab(D):\n",
        "    V = set([])\n",
        "    for feature in D:\n",
        "        for cell in D[feature]:\n",
        "            for row in D[feature][cell]:\n",
        "                for i in row:\n",
        "                    V.add(i)\n",
        "    return V\n",
        "\n",
        "def get_trans(C, ks=16):\n",
        "    S = {}\n",
        "    V = sorted(set([re.split('[+|-]', v)[0] for v in get_vocab(C)]))\n",
        "    idx = {V[i]: i for i in range(len(V))}\n",
        "    for feature in C:\n",
        "        S[feature] = {}\n",
        "        for cell in C[feature]:\n",
        "            S[feature][cell] = []\n",
        "            for i in range(len(C[feature][cell])):\n",
        "                X = np.zeros((len(idx), len(idx), 3), dtype=float)\n",
        "                for k in range(min(ks, len(C[feature][cell][i]))):\n",
        "                    for a in range(len(C[feature][cell][i]) - k):\n",
        "                        tf1 = re.split('[+|-]', C[feature][cell][i][a])[0]\n",
        "                        tf2 = re.split('[+|-]', C[feature][cell][i][a + k])[0]\n",
        "                        if C[feature][cell][i][a].find('+') > -1:\n",
        "                            if C[feature][cell][i][a + k].find('+') > -1:\n",
        "                                X[idx[tf1], idx[tf2], 0] += 1\n",
        "                            else:\n",
        "                                X[idx[tf1], idx[tf2], 1] += 1\n",
        "                        else:\n",
        "                            if C[feature][cell][i][a + k].find('+') > -1:\n",
        "                                X[idx[tf1], idx[tf2], 1] += 1\n",
        "                            else:\n",
        "                                X[idx[tf1], idx[tf2], 0] += 1\n",
        "                X /= np.sum(X)\n",
        "                S[feature][cell] += [X]\n",
        "    return S\n",
        "\n",
        "def get_classes(D):\n",
        "    C = set([])\n",
        "    for feature in D:\n",
        "        for cell in D[feature]:\n",
        "            C.add(cell)\n",
        "    return C\n",
        "\n",
        "def cell_map(F, cmap):\n",
        "    C = {}\n",
        "    for feature in F:\n",
        "        C[feature] = {}\n",
        "        for cell in F[feature]:\n",
        "            if cmap[cell] in C[feature]:\n",
        "                C[feature][cmap[cell]] += [row for row in F[feature][cell]]\n",
        "            else:\n",
        "                C[feature][cmap[cell]] = [row for row in F[feature][cell]]\n",
        "    return C\n",
        "\n",
        "def confusion_matrix(T, Y, c=10):\n",
        "    M = np.array([[0.0 for j in range(c)] for i in range(c)], dtype=float)\n",
        "    for i in range(len(T)):\n",
        "        M[int(T[i])][int(Y[i])] += 1.0\n",
        "    return M\n",
        "\n",
        "def f1_score(cm):\n",
        "    f1s = []\n",
        "    for i in range(len(cm)):\n",
        "        prec = (0.0 if np.sum(cm[:, i]) == 0.0 else cm[i, i] / np.sum(cm[:, i]))\n",
        "        rec = (0.0 if np.sum(cm[i, :]) == 0.0 else cm[i, i] / np.sum(cm[i, :]))\n",
        "        f1s += [(0.0 if (prec + rec) == 0.0 else 2 * (prec * rec) / (prec + rec))]\n",
        "    return (0.0 if () == 0.0 else len(cm) * (np.prod(f1s)) / (np.sum(f1s)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvPDUKD8HM2v"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RLZWEFAoJvJ"
      },
      "source": [
        "Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58aFffPZIVLA"
      },
      "outputs": [],
      "source": [
        "# comma-seperated list fo features to model: AEC,PEC,PC,IC\n",
        "features=[\"AEC\"]\n",
        "\n",
        "# split factor [0.0 to 1.0]\n",
        "split=0.3\n",
        "\n",
        "# maximum vocabulary size\n",
        "max_vocab=5\n",
        "\n",
        "# sequence length\n",
        "maxlen=50\n",
        "\n",
        "# balance factor [0.0 is downsample to 1.0 is upsample]\n",
        "balance_w=None\n",
        "\n",
        "# gpu number [0 to x]\n",
        "gpu_num=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh-Zyc_JKDEs"
      },
      "outputs": [],
      "source": [
        "# read in the raw data sequences as: feature,cell,x1,x2,...xm\n",
        "with gzip.GzipFile(in_path, 'rb') as f:\n",
        "    raw = [row.decode('utf-8').replace('\\n', '').split('\\t') for row in f.readlines()]\n",
        "F = data2dict(raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFWIbNQUK_SY",
        "outputId": "5d04c714-f650-476d-90b0-87fb766fd942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AEC', 'IC', 'PEC', 'PC']\n",
            "['MESOTHELIALEPICARDIUM', 'SPLEEN', 'STOMACH', 'HEPATOCYTE', 'NEURALCREST', 'NEPHRONPROGENITOR', 'OSTEOCYTE', 'PANCREAS', 'MESENCHYMAL', 'PERIPHERALBLOOD']\n"
          ]
        }
      ],
      "source": [
        "print(list(F))\n",
        "print(list(F['AEC']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2HUB7PWoGDC"
      },
      "outputs": [],
      "source": [
        "# apply cell map to F\n",
        "cmap = {'MESENCHYMAL': 'OFC', 'NEURALCREST': 'OFC', 'OSTEOCYTE': 'BACKGROUND',\n",
        "        'HEPATOCYTE': 'BACKGROUND', 'MESOTHELIALEPICARDIUM': 'BACKGROUND', 'NEPHRONPROGENITOR': 'BACKGROUND',\n",
        "        'PANCREAS': 'BACKGROUND', 'PERIPHERALBLOOD': 'BACKGROUND', 'SPLEEN': 'BACKGROUND', 'STOMACH': 'BACKGROUND'}\n",
        "# cmap = {k:k for k in set([c for f in F for c in F[f]])}\n",
        "C = cell_map(F, cmap)\n",
        "C = {feature: C[feature] for feature in features}  # apply only features that are selected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWwfnmlSoDGy",
        "outputId": "48f48545-2dbb-4cc5-f981-23e335037c07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['BACKGROUND', 'OFC']\n"
          ]
        }
      ],
      "source": [
        "print(list(C['AEC']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6XiH_hwoMpd"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u0vGiSuoQMn"
      },
      "outputs": [],
      "source": [
        "#embed_dims,num_heads,ff_dims,batches,drops = [4],[2],[16],[128],[0.3]\n",
        "embed_dims,num_heads,ff_dims,batches,drops = [2,4,8],[2,4,8],[16,32,64],[32,64,128],[0.4,0.5]\n",
        "hyper_params = []\n",
        "for embed_dim in embed_dims:\n",
        "    for num_head in num_heads:\n",
        "        for ff_dim in ff_dims:\n",
        "            for batch in batches:\n",
        "                for drop in drops:\n",
        "                    hyper_params += [[embed_dim, num_head, ff_dim, batch, drop, balance_w]]\n",
        "\n",
        "class_num = len(get_classes(C))\n",
        "vocab_size = len(sorted(get_vocab(C)))\n",
        "max_vocab = min(max_vocab, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8DuB9-xoSMR",
        "outputId": "6e879025-7ac3-4405-c8ba-f320e292cd86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessing data now...\n",
            "using data labeling scheme: {'BACKGROUND': 0, 'OFC': 1}\n"
          ]
        }
      ],
      "source": [
        "print('preprocessing data now...')\n",
        "train, test, valid, vec = preprocess_data(C, max_vocab=max_vocab, maxlen=maxlen, split=split, balance_w=balance_w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nslYv2koTjK"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad9wHZ06ZF9e",
        "outputId": "02b27eb3-d9f9-4ec5-8c71-e10f608ff7d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - f1: 0.4564 - loss: 5.8919 - val_f1: 0.4430 - val_loss: 5.0239\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0112 - val_f1: 0.4430 - val_loss: 5.0145\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9955 - val_f1: 0.4430 - val_loss: 5.0124\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0317 - val_f1: 0.4430 - val_loss: 5.0147\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9973 - val_f1: 0.4430 - val_loss: 5.0140\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0218 - val_f1: 0.4430 - val_loss: 5.0150\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0469 - val_f1: 0.4430 - val_loss: 5.0243\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0342 - val_f1: 0.4430 - val_loss: 5.0188\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0501 - val_f1: 0.4430 - val_loss: 5.0191\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0203 - val_f1: 0.4430 - val_loss: 5.0195\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0044 - val_f1: 0.4430 - val_loss: 5.0226\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0209 - val_f1: 0.4430 - val_loss: 5.0280\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0052 - val_f1: 0.4430 - val_loss: 5.0249\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0146 - val_f1: 0.4430 - val_loss: 5.0255\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0282 - val_f1: 0.4430 - val_loss: 5.0254\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0313 - val_f1: 0.4430 - val_loss: 5.0171\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0055 - val_f1: 0.4430 - val_loss: 5.0207\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0051 - val_f1: 0.4430 - val_loss: 5.0347\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0296 - val_f1: 0.4430 - val_loss: 5.0168\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9988 - val_f1: 0.4430 - val_loss: 5.0359\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9995 - val_f1: 0.4430 - val_loss: 5.0286\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0143 - val_f1: 0.4430 - val_loss: 5.0276\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0226 - val_f1: 0.4430 - val_loss: 5.0195\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0150 - val_f1: 0.4430 - val_loss: 5.0366\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0074 - val_f1: 0.4430 - val_loss: 5.0437\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0371 - val_f1: 0.4430 - val_loss: 5.0506\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0250 - val_f1: 0.4430 - val_loss: 5.0351\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0297 - val_f1: 0.4430 - val_loss: 5.0299\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0063 - val_f1: 0.4430 - val_loss: 5.0253\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0264 - val_f1: 0.4430 - val_loss: 5.0279\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0219 - val_f1: 0.4430 - val_loss: 5.0321\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0243 - val_f1: 0.4430 - val_loss: 5.0389\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9926 - val_f1: 0.4430 - val_loss: 5.0259\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0036 - val_f1: 0.4430 - val_loss: 5.0281\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0399 - val_f1: 0.4430 - val_loss: 5.0282\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0052 - val_f1: 0.4430 - val_loss: 5.0391\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0295 - val_f1: 0.4430 - val_loss: 5.0307\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9895 - val_f1: 0.4430 - val_loss: 5.0281\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0007 - val_f1: 0.4430 - val_loss: 5.0296\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0195 - val_f1: 0.4430 - val_loss: 5.0236\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0275 - val_f1: 0.4430 - val_loss: 5.0299\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0101 - val_f1: 0.4430 - val_loss: 5.0216\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0291 - val_f1: 0.4430 - val_loss: 5.0167\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0144 - val_f1: 0.4430 - val_loss: 5.0310\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0221 - val_f1: 0.4430 - val_loss: 5.0406\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0217 - val_f1: 0.4430 - val_loss: 5.0631\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0200 - val_f1: 0.4430 - val_loss: 5.0264\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0030 - val_f1: 0.4430 - val_loss: 5.0391\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9960 - val_f1: 0.4430 - val_loss: 5.0439\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9932 - val_f1: 0.4430 - val_loss: 5.0306\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0402 - val_f1: 0.4430 - val_loss: 5.0311\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9919 - val_f1: 0.4430 - val_loss: 5.0342\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0030 - val_f1: 0.4430 - val_loss: 5.0371\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0320 - val_f1: 0.4430 - val_loss: 5.0383\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0195 - val_f1: 0.4430 - val_loss: 5.0368\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0178 - val_f1: 0.4430 - val_loss: 5.0446\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9914 - val_f1: 0.4430 - val_loss: 5.0085\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9775 - val_f1: 0.4430 - val_loss: 4.9433\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9360 - val_f1: 0.4430 - val_loss: 4.9198\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8850 - val_f1: 0.4430 - val_loss: 4.8712\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9045 - val_f1: 0.4430 - val_loss: 4.8783\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8935 - val_f1: 0.4430 - val_loss: 4.8759\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8776 - val_f1: 0.4430 - val_loss: 5.0246\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9069 - val_f1: 0.4430 - val_loss: 4.8692\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9186 - val_f1: 0.4430 - val_loss: 4.8734\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8829 - val_f1: 0.4430 - val_loss: 4.8792\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8724 - val_f1: 0.4430 - val_loss: 4.9310\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9316 - val_f1: 0.4430 - val_loss: 4.8624\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8508 - val_f1: 0.4430 - val_loss: 4.8628\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8858 - val_f1: 0.4430 - val_loss: 4.9175\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8742 - val_f1: 0.4430 - val_loss: 4.8860\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8889 - val_f1: 0.4430 - val_loss: 4.8709\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8815 - val_f1: 0.4430 - val_loss: 4.9225\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8989 - val_f1: 0.4430 - val_loss: 4.8956\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8951 - val_f1: 0.4430 - val_loss: 4.9125\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8671 - val_f1: 0.4430 - val_loss: 4.9134\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8963 - val_f1: 0.4430 - val_loss: 4.8756\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8851 - val_f1: 0.4430 - val_loss: 4.8788\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8723 - val_f1: 0.4430 - val_loss: 4.8643\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8587 - val_f1: 0.4430 - val_loss: 4.8653\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8622 - val_f1: 0.4430 - val_loss: 4.8773\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9023 - val_f1: 0.4430 - val_loss: 4.8960\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8842 - val_f1: 0.4430 - val_loss: 4.8693\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8830 - val_f1: 0.4430 - val_loss: 4.8750\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8610 - val_f1: 0.4430 - val_loss: 4.8750\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8920 - val_f1: 0.4430 - val_loss: 4.8707\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8676 - val_f1: 0.4430 - val_loss: 4.8639\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8584 - val_f1: 0.4430 - val_loss: 4.8715\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8813 - val_f1: 0.4430 - val_loss: 4.8892\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8655 - val_f1: 0.4430 - val_loss: 4.8732\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8740 - val_f1: 0.4430 - val_loss: 4.9342\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9253 - val_f1: 0.4430 - val_loss: 4.9453\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8755 - val_f1: 0.4430 - val_loss: 4.8787\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8769 - val_f1: 0.4430 - val_loss: 4.9088\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8777 - val_f1: 0.4430 - val_loss: 4.8846\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8609 - val_f1: 0.4430 - val_loss: 4.8876\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9100 - val_f1: 0.4430 - val_loss: 4.8767\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8683 - val_f1: 0.4430 - val_loss: 4.8624\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8499 - val_f1: 0.4430 - val_loss: 4.8748\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8623 - val_f1: 0.4430 - val_loss: 4.9475\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 16, 32, 0.4, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - f1: 0.4554 - loss: 5.8900 - val_f1: 0.4430 - val_loss: 5.0211\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0065 - val_f1: 0.4430 - val_loss: 5.0136\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0031 - val_f1: 0.4430 - val_loss: 5.0226\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0279 - val_f1: 0.4430 - val_loss: 5.0141\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0180 - val_f1: 0.4430 - val_loss: 5.0318\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0217 - val_f1: 0.4430 - val_loss: 5.0223\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0019 - val_f1: 0.4430 - val_loss: 5.0303\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0050 - val_f1: 0.4430 - val_loss: 5.0369\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0203 - val_f1: 0.4430 - val_loss: 5.0223\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0265 - val_f1: 0.4430 - val_loss: 5.0262\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0450 - val_f1: 0.4430 - val_loss: 5.0378\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9854 - val_f1: 0.4430 - val_loss: 5.0631\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0496 - val_f1: 0.4430 - val_loss: 5.0324\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0140 - val_f1: 0.4430 - val_loss: 5.0276\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0201 - val_f1: 0.4430 - val_loss: 5.0437\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9935 - val_f1: 0.4430 - val_loss: 5.0582\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0065 - val_f1: 0.4430 - val_loss: 5.0465\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0101 - val_f1: 0.4430 - val_loss: 5.0442\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0079 - val_f1: 0.4430 - val_loss: 5.0428\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0258 - val_f1: 0.4430 - val_loss: 5.0432\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 5.0020 - val_f1: 0.4430 - val_loss: 5.0829\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0037 - val_f1: 0.4430 - val_loss: 5.0520\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9836 - val_f1: 0.4430 - val_loss: 5.0712\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0165 - val_f1: 0.4430 - val_loss: 5.0519\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9894 - val_f1: 0.4430 - val_loss: 5.0579\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0011 - val_f1: 0.4430 - val_loss: 5.0785\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9909 - val_f1: 0.4430 - val_loss: 5.0524\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9981 - val_f1: 0.4430 - val_loss: 5.0607\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9961 - val_f1: 0.4430 - val_loss: 5.0749\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0066 - val_f1: 0.4430 - val_loss: 5.0497\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9923 - val_f1: 0.4430 - val_loss: 5.0455\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0302 - val_f1: 0.4430 - val_loss: 5.0504\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9979 - val_f1: 0.4430 - val_loss: 5.0615\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0323 - val_f1: 0.4430 - val_loss: 5.0488\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9837 - val_f1: 0.4430 - val_loss: 5.0533\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9908 - val_f1: 0.4430 - val_loss: 5.0747\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9934 - val_f1: 0.4430 - val_loss: 5.0529\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0325 - val_f1: 0.4430 - val_loss: 5.0572\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0296 - val_f1: 0.4430 - val_loss: 5.0465\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0050 - val_f1: 0.4430 - val_loss: 5.0612\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9819 - val_f1: 0.4430 - val_loss: 5.0771\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0170 - val_f1: 0.4430 - val_loss: 5.0557\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0236 - val_f1: 0.4430 - val_loss: 5.0507\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0163 - val_f1: 0.4430 - val_loss: 5.0492\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0370 - val_f1: 0.4430 - val_loss: 5.0562\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0002 - val_f1: 0.4430 - val_loss: 5.0700\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0001 - val_f1: 0.4430 - val_loss: 5.0375\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0119 - val_f1: 0.4430 - val_loss: 5.0440\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9866 - val_f1: 0.4430 - val_loss: 5.0506\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0099 - val_f1: 0.4430 - val_loss: 5.0396\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0186 - val_f1: 0.4430 - val_loss: 5.0485\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9815 - val_f1: 0.4430 - val_loss: 5.0569\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0107 - val_f1: 0.4430 - val_loss: 5.0579\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9914 - val_f1: 0.4430 - val_loss: 5.0524\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0075 - val_f1: 0.4430 - val_loss: 5.0579\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0030 - val_f1: 0.4430 - val_loss: 5.0464\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0313 - val_f1: 0.4430 - val_loss: 5.0423\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0238 - val_f1: 0.4430 - val_loss: 5.0614\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0364 - val_f1: 0.4430 - val_loss: 5.0688\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9989 - val_f1: 0.4430 - val_loss: 5.0562\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9962 - val_f1: 0.4430 - val_loss: 5.0662\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0401 - val_f1: 0.4430 - val_loss: 5.0375\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0293 - val_f1: 0.4430 - val_loss: 5.0565\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0233 - val_f1: 0.4430 - val_loss: 5.0595\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9972 - val_f1: 0.4430 - val_loss: 5.0501\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9896 - val_f1: 0.4430 - val_loss: 5.0720\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0133 - val_f1: 0.4430 - val_loss: 5.0442\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9951 - val_f1: 0.4430 - val_loss: 5.0841\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9782 - val_f1: 0.4430 - val_loss: 5.0745\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0207 - val_f1: 0.4430 - val_loss: 5.0441\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9878 - val_f1: 0.4430 - val_loss: 5.0670\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0141 - val_f1: 0.4430 - val_loss: 5.0704\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9927 - val_f1: 0.4430 - val_loss: 5.0824\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0131 - val_f1: 0.4430 - val_loss: 5.0809\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9983 - val_f1: 0.4430 - val_loss: 5.0628\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0140 - val_f1: 0.4430 - val_loss: 5.0613\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0391 - val_f1: 0.4430 - val_loss: 5.0553\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0077 - val_f1: 0.4430 - val_loss: 5.0516\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0234 - val_f1: 0.4430 - val_loss: 5.0753\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9747 - val_f1: 0.4430 - val_loss: 5.0871\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0070 - val_f1: 0.4430 - val_loss: 5.1132\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0128 - val_f1: 0.4430 - val_loss: 5.0771\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0034 - val_f1: 0.4430 - val_loss: 5.0828\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0141 - val_f1: 0.4430 - val_loss: 5.0842\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0140 - val_f1: 0.4430 - val_loss: 5.0687\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0008 - val_f1: 0.4430 - val_loss: 5.0840\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0311 - val_f1: 0.4430 - val_loss: 5.0843\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0296 - val_f1: 0.4430 - val_loss: 5.0905\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0117 - val_f1: 0.4430 - val_loss: 5.0665\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0055 - val_f1: 0.4430 - val_loss: 5.0922\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9883 - val_f1: 0.4430 - val_loss: 5.1175\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0278 - val_f1: 0.4430 - val_loss: 5.0697\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0156 - val_f1: 0.4430 - val_loss: 5.0816\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9954 - val_f1: 0.4430 - val_loss: 5.0555\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0387 - val_f1: 0.4430 - val_loss: 5.0617\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0103 - val_f1: 0.4430 - val_loss: 5.0996\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0402 - val_f1: 0.4430 - val_loss: 5.0863\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0374 - val_f1: 0.4430 - val_loss: 5.0699\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0013 - val_f1: 0.4430 - val_loss: 5.0749\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0217 - val_f1: 0.4430 - val_loss: 5.0634\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 16, 32, 0.5, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4452 - loss: 6.0249 - val_f1: 0.4430 - val_loss: 4.9895\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0121 - val_f1: 0.4430 - val_loss: 5.0063\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9858 - val_f1: 0.4430 - val_loss: 4.9880\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9746 - val_f1: 0.4430 - val_loss: 4.9797\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9912 - val_f1: 0.4430 - val_loss: 4.9665\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9501 - val_f1: 0.4430 - val_loss: 4.9684\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9731 - val_f1: 0.4430 - val_loss: 4.9791\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9648 - val_f1: 0.4430 - val_loss: 4.9869\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0158 - val_f1: 0.4430 - val_loss: 5.0116\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0036 - val_f1: 0.4430 - val_loss: 5.0390\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0165 - val_f1: 0.4430 - val_loss: 5.0292\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9766 - val_f1: 0.4430 - val_loss: 5.0436\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0270 - val_f1: 0.4430 - val_loss: 5.0330\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0206 - val_f1: 0.4430 - val_loss: 5.0472\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9958 - val_f1: 0.4430 - val_loss: 5.0652\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0317 - val_f1: 0.4430 - val_loss: 5.0724\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9863 - val_f1: 0.4430 - val_loss: 5.0981\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0039 - val_f1: 0.4430 - val_loss: 5.0654\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0110 - val_f1: 0.4430 - val_loss: 5.0623\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9852 - val_f1: 0.4430 - val_loss: 5.0513\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0421 - val_f1: 0.4430 - val_loss: 5.0698\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9964 - val_f1: 0.4430 - val_loss: 5.0879\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0140 - val_f1: 0.4430 - val_loss: 5.0806\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0223 - val_f1: 0.4430 - val_loss: 5.1197\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9734 - val_f1: 0.4430 - val_loss: 5.0754\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0022 - val_f1: 0.4430 - val_loss: 5.0959\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9980 - val_f1: 0.4430 - val_loss: 5.0790\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0126 - val_f1: 0.4430 - val_loss: 5.0700\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9842 - val_f1: 0.4430 - val_loss: 5.0888\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0110 - val_f1: 0.4430 - val_loss: 5.0574\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9998 - val_f1: 0.4430 - val_loss: 5.1056\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9779 - val_f1: 0.4430 - val_loss: 5.0438\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0080 - val_f1: 0.4430 - val_loss: 5.0461\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9748 - val_f1: 0.4430 - val_loss: 5.0543\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9717 - val_f1: 0.4430 - val_loss: 5.0847\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0065 - val_f1: 0.4430 - val_loss: 5.0538\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9810 - val_f1: 0.4430 - val_loss: 5.0819\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0092 - val_f1: 0.4430 - val_loss: 5.1114\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9950 - val_f1: 0.4430 - val_loss: 5.1059\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9954 - val_f1: 0.4430 - val_loss: 5.1083\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9735 - val_f1: 0.4430 - val_loss: 5.1041\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0127 - val_f1: 0.4430 - val_loss: 5.1097\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9988 - val_f1: 0.4430 - val_loss: 5.1654\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0188 - val_f1: 0.4430 - val_loss: 5.1843\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0036 - val_f1: 0.4430 - val_loss: 5.1365\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9807 - val_f1: 0.4430 - val_loss: 5.1580\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0096 - val_f1: 0.4430 - val_loss: 5.1272\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0076 - val_f1: 0.4430 - val_loss: 5.1942\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9636 - val_f1: 0.4430 - val_loss: 5.1796\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9762 - val_f1: 0.4430 - val_loss: 5.1279\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9761 - val_f1: 0.4430 - val_loss: 5.1801\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9917 - val_f1: 0.4430 - val_loss: 5.1077\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9541 - val_f1: 0.4430 - val_loss: 5.1703\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9805 - val_f1: 0.4430 - val_loss: 5.1212\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9856 - val_f1: 0.4430 - val_loss: 5.1516\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9703 - val_f1: 0.4430 - val_loss: 5.2614\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9824 - val_f1: 0.4430 - val_loss: 5.4194\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9756 - val_f1: 0.4430 - val_loss: 5.2186\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9934 - val_f1: 0.4430 - val_loss: 5.2604\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9724 - val_f1: 0.4430 - val_loss: 5.2902\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9789 - val_f1: 0.4430 - val_loss: 5.3398\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9927 - val_f1: 0.4430 - val_loss: 5.2178\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9903 - val_f1: 0.4430 - val_loss: 5.3790\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9839 - val_f1: 0.4430 - val_loss: 5.3796\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9673 - val_f1: 0.4430 - val_loss: 5.3064\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9782 - val_f1: 0.4430 - val_loss: 5.5768\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9970 - val_f1: 0.4430 - val_loss: 5.5800\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9819 - val_f1: 0.4430 - val_loss: 5.5625\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0031 - val_f1: 0.4430 - val_loss: 5.7074\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9810 - val_f1: 0.4430 - val_loss: 5.7541\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9898 - val_f1: 0.4430 - val_loss: 5.6797\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9927 - val_f1: 0.4430 - val_loss: 5.5263\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0223 - val_f1: 0.4430 - val_loss: 5.7441\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0056 - val_f1: 0.4430 - val_loss: 5.6292\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0088 - val_f1: 0.4430 - val_loss: 5.7683\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0277 - val_f1: 0.4430 - val_loss: 5.8877\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9863 - val_f1: 0.4430 - val_loss: 5.7691\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0076 - val_f1: 0.4430 - val_loss: 5.7639\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0319 - val_f1: 0.4430 - val_loss: 5.7464\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0099 - val_f1: 0.4430 - val_loss: 5.8102\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0261 - val_f1: 0.4430 - val_loss: 5.7697\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0159 - val_f1: 0.4430 - val_loss: 5.7920\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0037 - val_f1: 0.4430 - val_loss: 5.7131\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0195 - val_f1: 0.4430 - val_loss: 5.6991\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9689 - val_f1: 0.4430 - val_loss: 5.4597\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9517 - val_f1: 0.4430 - val_loss: 5.5768\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9559 - val_f1: 0.4430 - val_loss: 5.5052\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9504 - val_f1: 0.4430 - val_loss: 5.4170\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9837 - val_f1: 0.4430 - val_loss: 5.4510\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9603 - val_f1: 0.4430 - val_loss: 5.4673\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9906 - val_f1: 0.4430 - val_loss: 5.4420\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9713 - val_f1: 0.4430 - val_loss: 5.5767\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9761 - val_f1: 0.4430 - val_loss: 5.6913\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9555 - val_f1: 0.4430 - val_loss: 5.6224\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9624 - val_f1: 0.4430 - val_loss: 5.7350\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9669 - val_f1: 0.4430 - val_loss: 6.2957\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9603 - val_f1: 0.4430 - val_loss: 6.2039\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9773 - val_f1: 0.4430 - val_loss: 6.1880\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9365 - val_f1: 0.4430 - val_loss: 6.3002\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9377 - val_f1: 0.4430 - val_loss: 6.4672\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 16, 64, 0.4, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4580 - loss: 6.0267 - val_f1: 0.4430 - val_loss: 4.9920\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0211 - val_f1: 0.4430 - val_loss: 4.9910\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9940 - val_f1: 0.4430 - val_loss: 4.9912\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0013 - val_f1: 0.4430 - val_loss: 4.9925\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0086 - val_f1: 0.4430 - val_loss: 4.9912\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9850 - val_f1: 0.4430 - val_loss: 4.9906\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0087 - val_f1: 0.4430 - val_loss: 4.9915\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4436 - loss: 4.9594 - val_f1: 0.4430 - val_loss: 5.0096\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0222 - val_f1: 0.4430 - val_loss: 5.0194\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0482 - val_f1: 0.4430 - val_loss: 5.0236\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0456 - val_f1: 0.4430 - val_loss: 5.0441\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 5.0015 - val_f1: 0.4430 - val_loss: 5.0457\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0122 - val_f1: 0.4430 - val_loss: 5.0526\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0225 - val_f1: 0.4430 - val_loss: 5.0571\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0240 - val_f1: 0.4430 - val_loss: 5.0429\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0437 - val_f1: 0.4430 - val_loss: 5.0386\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0233 - val_f1: 0.4430 - val_loss: 5.0443\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0104 - val_f1: 0.4430 - val_loss: 5.0494\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0020 - val_f1: 0.4430 - val_loss: 5.0529\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0293 - val_f1: 0.4430 - val_loss: 5.0395\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0021 - val_f1: 0.4430 - val_loss: 5.0483\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9890 - val_f1: 0.4430 - val_loss: 5.0445\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0182 - val_f1: 0.4430 - val_loss: 5.0468\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0105 - val_f1: 0.4430 - val_loss: 5.0109\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9853 - val_f1: 0.4430 - val_loss: 5.0008\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9874 - val_f1: 0.4430 - val_loss: 5.0203\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9662 - val_f1: 0.4430 - val_loss: 5.0064\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9858 - val_f1: 0.4430 - val_loss: 5.0372\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0019 - val_f1: 0.4430 - val_loss: 5.0105\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9977 - val_f1: 0.4430 - val_loss: 5.0341\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9752 - val_f1: 0.4430 - val_loss: 5.0216\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9904 - val_f1: 0.4430 - val_loss: 5.0253\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9795 - val_f1: 0.4430 - val_loss: 5.0291\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9706 - val_f1: 0.4430 - val_loss: 5.0155\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9719 - val_f1: 0.4430 - val_loss: 5.0260\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9653 - val_f1: 0.4430 - val_loss: 4.9982\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0184 - val_f1: 0.4430 - val_loss: 5.0887\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0118 - val_f1: 0.4430 - val_loss: 5.2030\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0020 - val_f1: 0.4430 - val_loss: 5.1256\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9969 - val_f1: 0.4430 - val_loss: 5.2411\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0207 - val_f1: 0.4430 - val_loss: 5.1520\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4436 - loss: 4.9543 - val_f1: 0.4430 - val_loss: 5.2215\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0045 - val_f1: 0.4430 - val_loss: 5.2161\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9693 - val_f1: 0.4430 - val_loss: 5.2326\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0099 - val_f1: 0.4430 - val_loss: 5.2836\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9931 - val_f1: 0.4430 - val_loss: 5.2725\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0083 - val_f1: 0.4430 - val_loss: 5.2200\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0061 - val_f1: 0.4430 - val_loss: 5.2457\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0095 - val_f1: 0.4430 - val_loss: 5.2674\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0016 - val_f1: 0.4430 - val_loss: 5.2817\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0109 - val_f1: 0.4430 - val_loss: 5.2731\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0117 - val_f1: 0.4430 - val_loss: 5.2356\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0025 - val_f1: 0.4430 - val_loss: 5.2544\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9986 - val_f1: 0.4430 - val_loss: 5.3002\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0046 - val_f1: 0.4430 - val_loss: 5.3069\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9984 - val_f1: 0.4430 - val_loss: 5.2812\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0115 - val_f1: 0.4430 - val_loss: 5.2195\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0041 - val_f1: 0.4430 - val_loss: 5.3269\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0071 - val_f1: 0.4430 - val_loss: 5.2923\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0165 - val_f1: 0.4430 - val_loss: 5.2731\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0176 - val_f1: 0.4430 - val_loss: 5.3836\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0010 - val_f1: 0.4430 - val_loss: 5.3708\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9976 - val_f1: 0.4430 - val_loss: 5.3041\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0216 - val_f1: 0.4430 - val_loss: 5.3288\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0126 - val_f1: 0.4430 - val_loss: 5.3032\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0203 - val_f1: 0.4430 - val_loss: 5.3278\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0011 - val_f1: 0.4430 - val_loss: 5.3315\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0066 - val_f1: 0.4430 - val_loss: 5.3857\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0135 - val_f1: 0.4430 - val_loss: 5.2974\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9984 - val_f1: 0.4430 - val_loss: 5.3304\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0185 - val_f1: 0.4430 - val_loss: 5.3447\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9673 - val_f1: 0.4430 - val_loss: 5.3475\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0276 - val_f1: 0.4430 - val_loss: 5.3730\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9975 - val_f1: 0.4430 - val_loss: 5.4729\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9993 - val_f1: 0.4430 - val_loss: 5.4300\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0018 - val_f1: 0.4430 - val_loss: 5.4466\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9985 - val_f1: 0.4430 - val_loss: 5.4381\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0008 - val_f1: 0.4430 - val_loss: 5.4771\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0121 - val_f1: 0.4430 - val_loss: 5.3704\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9759 - val_f1: 0.4430 - val_loss: 5.4853\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9870 - val_f1: 0.4430 - val_loss: 5.4632\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0194 - val_f1: 0.4430 - val_loss: 5.4888\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9873 - val_f1: 0.4430 - val_loss: 5.5060\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0532 - val_f1: 0.4430 - val_loss: 5.5420\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0328 - val_f1: 0.4430 - val_loss: 5.3713\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0161 - val_f1: 0.4430 - val_loss: 5.4602\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0167 - val_f1: 0.4430 - val_loss: 5.3368\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0084 - val_f1: 0.4430 - val_loss: 5.3989\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0284 - val_f1: 0.4430 - val_loss: 5.4227\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9969 - val_f1: 0.4430 - val_loss: 5.4151\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9966 - val_f1: 0.4430 - val_loss: 5.4667\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0075 - val_f1: 0.4430 - val_loss: 5.5223\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0052 - val_f1: 0.4430 - val_loss: 5.4233\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0185 - val_f1: 0.4430 - val_loss: 5.5034\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9910 - val_f1: 0.4430 - val_loss: 5.4413\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0217 - val_f1: 0.4430 - val_loss: 5.5126\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9954 - val_f1: 0.4430 - val_loss: 5.4684\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0315 - val_f1: 0.4430 - val_loss: 5.4849\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0311 - val_f1: 0.4430 - val_loss: 5.4493\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0237 - val_f1: 0.4430 - val_loss: 5.5511\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 16, 64, 0.5, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4497 - loss: 5.8689 - val_f1: 0.4430 - val_loss: 5.0325\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0428 - val_f1: 0.4430 - val_loss: 5.0017\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0074 - val_f1: 0.4430 - val_loss: 4.9676\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9748 - val_f1: 0.4430 - val_loss: 4.9844\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9681 - val_f1: 0.4430 - val_loss: 4.9832\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0182 - val_f1: 0.4430 - val_loss: 5.0134\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0234 - val_f1: 0.4430 - val_loss: 5.0136\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9931 - val_f1: 0.4430 - val_loss: 5.0154\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0126 - val_f1: 0.4430 - val_loss: 5.0150\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0032 - val_f1: 0.4430 - val_loss: 5.0189\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9945 - val_f1: 0.4430 - val_loss: 5.0115\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9954 - val_f1: 0.4430 - val_loss: 5.0272\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4438 - loss: 4.9671 - val_f1: 0.4430 - val_loss: 5.0208\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0555 - val_f1: 0.4430 - val_loss: 5.0078\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0284 - val_f1: 0.4430 - val_loss: 5.0200\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0200 - val_f1: 0.4430 - val_loss: 5.0199\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9814 - val_f1: 0.4430 - val_loss: 5.0019\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9783 - val_f1: 0.4430 - val_loss: 5.0241\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9942 - val_f1: 0.4430 - val_loss: 4.9970\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9814 - val_f1: 0.4430 - val_loss: 4.9772\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9747 - val_f1: 0.4430 - val_loss: 4.9990\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9861 - val_f1: 0.4430 - val_loss: 5.0466\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9520 - val_f1: 0.4430 - val_loss: 5.0435\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9673 - val_f1: 0.4430 - val_loss: 5.1038\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9855 - val_f1: 0.4430 - val_loss: 5.1104\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9836 - val_f1: 0.4430 - val_loss: 5.0241\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9795 - val_f1: 0.4430 - val_loss: 4.9969\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9706 - val_f1: 0.4430 - val_loss: 5.1234\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9729 - val_f1: 0.4430 - val_loss: 5.1853\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9996 - val_f1: 0.4430 - val_loss: 5.2177\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0180 - val_f1: 0.4430 - val_loss: 5.2341\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0249 - val_f1: 0.4430 - val_loss: 5.2554\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9869 - val_f1: 0.4430 - val_loss: 5.1820\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0435 - val_f1: 0.4430 - val_loss: 5.2030\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 5.0011 - val_f1: 0.4430 - val_loss: 5.2019\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0252 - val_f1: 0.4430 - val_loss: 5.1867\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9815 - val_f1: 0.4430 - val_loss: 5.2440\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0410 - val_f1: 0.4430 - val_loss: 5.1891\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0078 - val_f1: 0.4430 - val_loss: 5.2240\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9944 - val_f1: 0.4430 - val_loss: 5.2467\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0017 - val_f1: 0.4430 - val_loss: 5.1903\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9912 - val_f1: 0.4430 - val_loss: 5.2204\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0247 - val_f1: 0.4430 - val_loss: 5.2009\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9971 - val_f1: 0.4430 - val_loss: 5.1187\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0043 - val_f1: 0.4430 - val_loss: 5.1499\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9953 - val_f1: 0.4430 - val_loss: 5.1964\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0032 - val_f1: 0.4430 - val_loss: 5.1892\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0027 - val_f1: 0.4430 - val_loss: 5.1692\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0176 - val_f1: 0.4430 - val_loss: 5.2189\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9969 - val_f1: 0.4430 - val_loss: 5.2768\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0225 - val_f1: 0.4430 - val_loss: 5.2737\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9985 - val_f1: 0.4430 - val_loss: 5.1821\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0121 - val_f1: 0.4430 - val_loss: 5.1926\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0058 - val_f1: 0.4430 - val_loss: 5.1903\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9904 - val_f1: 0.4430 - val_loss: 5.1918\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0224 - val_f1: 0.4430 - val_loss: 5.2428\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0164 - val_f1: 0.4430 - val_loss: 5.1987\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9929 - val_f1: 0.4430 - val_loss: 5.2010\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9753 - val_f1: 0.4430 - val_loss: 5.2725\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0244 - val_f1: 0.4430 - val_loss: 5.2092\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0194 - val_f1: 0.4430 - val_loss: 5.2372\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9878 - val_f1: 0.4430 - val_loss: 5.1573\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9731 - val_f1: 0.4430 - val_loss: 5.2749\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9869 - val_f1: 0.4430 - val_loss: 5.2305\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9749 - val_f1: 0.4430 - val_loss: 5.3267\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9914 - val_f1: 0.4430 - val_loss: 5.2393\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9989 - val_f1: 0.4430 - val_loss: 5.2247\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9959 - val_f1: 0.4430 - val_loss: 5.2681\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9805 - val_f1: 0.4430 - val_loss: 5.3526\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9859 - val_f1: 0.4430 - val_loss: 5.4620\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0215 - val_f1: 0.4430 - val_loss: 5.3867\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9994 - val_f1: 0.4430 - val_loss: 5.3708\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0078 - val_f1: 0.4430 - val_loss: 5.3802\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0320 - val_f1: 0.4430 - val_loss: 5.3713\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9980 - val_f1: 0.4430 - val_loss: 5.4550\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0076 - val_f1: 0.4430 - val_loss: 5.4031\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0044 - val_f1: 0.4430 - val_loss: 5.4179\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0086 - val_f1: 0.4430 - val_loss: 5.4412\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9910 - val_f1: 0.4430 - val_loss: 5.4893\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0025 - val_f1: 0.4430 - val_loss: 5.4989\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9973 - val_f1: 0.4430 - val_loss: 5.4270\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9889 - val_f1: 0.4430 - val_loss: 5.4776\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9891 - val_f1: 0.4430 - val_loss: 5.3841\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0234 - val_f1: 0.4430 - val_loss: 5.4590\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0025 - val_f1: 0.4430 - val_loss: 5.4825\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0102 - val_f1: 0.4430 - val_loss: 5.5038\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9922 - val_f1: 0.4430 - val_loss: 5.4715\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9999 - val_f1: 0.4430 - val_loss: 5.4680\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0217 - val_f1: 0.4430 - val_loss: 5.4558\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0158 - val_f1: 0.4430 - val_loss: 5.4742\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0195 - val_f1: 0.4430 - val_loss: 5.4401\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0012 - val_f1: 0.4430 - val_loss: 5.4167\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0421 - val_f1: 0.4430 - val_loss: 5.3724\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0169 - val_f1: 0.4430 - val_loss: 5.3544\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0124 - val_f1: 0.4430 - val_loss: 5.4079\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0052 - val_f1: 0.4430 - val_loss: 5.5056\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0270 - val_f1: 0.4430 - val_loss: 5.4322\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0260 - val_f1: 0.4430 - val_loss: 5.4482\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9985 - val_f1: 0.4430 - val_loss: 5.5010\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0142 - val_f1: 0.4430 - val_loss: 5.4700\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 16, 128, 0.4, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 3ms/step - f1: 0.4463 - loss: 6.5369 - val_f1: 0.4430 - val_loss: 4.9291\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9479 - val_f1: 0.4430 - val_loss: 4.8861\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9052 - val_f1: 0.4430 - val_loss: 4.8772\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9295 - val_f1: 0.4430 - val_loss: 4.8743\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9116 - val_f1: 0.4430 - val_loss: 4.8679\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8722 - val_f1: 0.4430 - val_loss: 4.8683\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8776 - val_f1: 0.4430 - val_loss: 4.8692\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8621 - val_f1: 0.4430 - val_loss: 4.8711\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8792 - val_f1: 0.4430 - val_loss: 4.8763\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8779 - val_f1: 0.4430 - val_loss: 4.8788\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8705 - val_f1: 0.4430 - val_loss: 4.8701\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8806 - val_f1: 0.4430 - val_loss: 4.8703\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8863 - val_f1: 0.4430 - val_loss: 4.8654\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8916 - val_f1: 0.4430 - val_loss: 4.8659\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8538 - val_f1: 0.4430 - val_loss: 4.8653\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8760 - val_f1: 0.4430 - val_loss: 4.8705\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8700 - val_f1: 0.4430 - val_loss: 4.8707\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8558 - val_f1: 0.4430 - val_loss: 4.8732\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8825 - val_f1: 0.4430 - val_loss: 4.8695\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8726 - val_f1: 0.4430 - val_loss: 4.8743\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8724 - val_f1: 0.4430 - val_loss: 4.8664\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8502 - val_f1: 0.4430 - val_loss: 4.8699\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8604 - val_f1: 0.4430 - val_loss: 4.8686\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 4.9063 - val_f1: 0.4430 - val_loss: 4.8665\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8430 - val_f1: 0.4430 - val_loss: 4.8675\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8765 - val_f1: 0.4430 - val_loss: 4.8650\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8710 - val_f1: 0.4430 - val_loss: 4.8692\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8489 - val_f1: 0.4430 - val_loss: 4.8688\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8376 - val_f1: 0.4430 - val_loss: 4.8676\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8820 - val_f1: 0.4430 - val_loss: 4.8640\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8740 - val_f1: 0.4430 - val_loss: 4.8671\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8830 - val_f1: 0.4430 - val_loss: 4.8678\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8345 - val_f1: 0.4430 - val_loss: 4.8719\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8532 - val_f1: 0.4430 - val_loss: 4.8729\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8677 - val_f1: 0.4430 - val_loss: 4.8697\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8707 - val_f1: 0.4430 - val_loss: 4.8617\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8483 - val_f1: 0.4430 - val_loss: 4.8744\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8475 - val_f1: 0.4430 - val_loss: 4.8682\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.8898 - val_f1: 0.4430 - val_loss: 4.8651\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8835 - val_f1: 0.4430 - val_loss: 4.8621\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8792 - val_f1: 0.4430 - val_loss: 4.8640\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8388 - val_f1: 0.4430 - val_loss: 4.8720\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8810 - val_f1: 0.4430 - val_loss: 4.8686\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8486 - val_f1: 0.4430 - val_loss: 4.8699\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.8879 - val_f1: 0.4430 - val_loss: 4.8651\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8933 - val_f1: 0.4430 - val_loss: 4.8642\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8781 - val_f1: 0.4430 - val_loss: 4.8635\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8742 - val_f1: 0.4430 - val_loss: 4.8665\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8505 - val_f1: 0.4430 - val_loss: 4.8701\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8762 - val_f1: 0.4430 - val_loss: 4.8685\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8627 - val_f1: 0.4430 - val_loss: 4.8715\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8437 - val_f1: 0.4430 - val_loss: 4.8696\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8607 - val_f1: 0.4430 - val_loss: 4.8734\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8690 - val_f1: 0.4430 - val_loss: 4.8633\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8764 - val_f1: 0.4430 - val_loss: 4.8722\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8556 - val_f1: 0.4430 - val_loss: 4.8715\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8675 - val_f1: 0.4430 - val_loss: 4.8742\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8719 - val_f1: 0.4430 - val_loss: 4.8677\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8708 - val_f1: 0.4430 - val_loss: 4.8717\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8767 - val_f1: 0.4430 - val_loss: 4.8765\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8736 - val_f1: 0.4430 - val_loss: 4.8645\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8449 - val_f1: 0.4430 - val_loss: 4.8808\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8686 - val_f1: 0.4430 - val_loss: 4.8806\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8541 - val_f1: 0.4430 - val_loss: 4.8735\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8403 - val_f1: 0.4430 - val_loss: 4.8726\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8581 - val_f1: 0.4430 - val_loss: 4.8762\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8352 - val_f1: 0.4430 - val_loss: 4.8774\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8327 - val_f1: 0.4430 - val_loss: 4.8703\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8545 - val_f1: 0.4430 - val_loss: 4.8708\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8604 - val_f1: 0.4430 - val_loss: 4.8771\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8714 - val_f1: 0.4430 - val_loss: 4.8701\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8487 - val_f1: 0.4430 - val_loss: 4.8745\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8513 - val_f1: 0.4430 - val_loss: 4.8748\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8489 - val_f1: 0.4430 - val_loss: 4.8936\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8667 - val_f1: 0.4430 - val_loss: 4.8754\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8559 - val_f1: 0.4430 - val_loss: 4.8715\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8469 - val_f1: 0.4430 - val_loss: 4.8740\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8675 - val_f1: 0.4430 - val_loss: 4.8737\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8685 - val_f1: 0.4430 - val_loss: 4.8754\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8544 - val_f1: 0.4430 - val_loss: 4.8691\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8605 - val_f1: 0.4430 - val_loss: 4.8719\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8809 - val_f1: 0.4430 - val_loss: 4.8722\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8635 - val_f1: 0.4430 - val_loss: 4.8766\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8407 - val_f1: 0.4430 - val_loss: 4.8768\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8598 - val_f1: 0.4430 - val_loss: 4.8646\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8571 - val_f1: 0.4430 - val_loss: 4.8626\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8777 - val_f1: 0.4430 - val_loss: 4.8667\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8530 - val_f1: 0.4430 - val_loss: 4.8742\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8770 - val_f1: 0.4430 - val_loss: 4.8743\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8350 - val_f1: 0.4430 - val_loss: 4.8774\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8513 - val_f1: 0.4430 - val_loss: 4.8747\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8750 - val_f1: 0.4430 - val_loss: 4.8711\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8653 - val_f1: 0.4430 - val_loss: 4.8724\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8508 - val_f1: 0.4430 - val_loss: 4.8760\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8598 - val_f1: 0.4430 - val_loss: 4.8892\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8728 - val_f1: 0.4430 - val_loss: 4.8766\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8680 - val_f1: 0.4430 - val_loss: 4.8786\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8462 - val_f1: 0.4430 - val_loss: 4.8748\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8435 - val_f1: 0.4430 - val_loss: 4.8707\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8554 - val_f1: 0.4430 - val_loss: 4.8625\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 16, 128, 0.5, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - f1: 0.4590 - loss: 6.0850 - val_f1: 0.4430 - val_loss: 5.0258\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0186 - val_f1: 0.4430 - val_loss: 5.0291\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0341 - val_f1: 0.4430 - val_loss: 5.0185\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0306 - val_f1: 0.4430 - val_loss: 5.0178\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0124 - val_f1: 0.4430 - val_loss: 5.0167\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0218 - val_f1: 0.4430 - val_loss: 5.0135\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0378 - val_f1: 0.4430 - val_loss: 5.0146\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0059 - val_f1: 0.4430 - val_loss: 5.0210\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9949 - val_f1: 0.4430 - val_loss: 5.0134\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9976 - val_f1: 0.4430 - val_loss: 5.0137\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0111 - val_f1: 0.4430 - val_loss: 5.0135\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0132 - val_f1: 0.4430 - val_loss: 5.0173\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0099 - val_f1: 0.4430 - val_loss: 5.0148\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 5.0036 - val_f1: 0.4430 - val_loss: 5.0309\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0284 - val_f1: 0.4430 - val_loss: 5.0209\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0235 - val_f1: 0.4430 - val_loss: 5.0135\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0300 - val_f1: 0.4430 - val_loss: 5.0163\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0245 - val_f1: 0.4430 - val_loss: 5.0145\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0156 - val_f1: 0.4430 - val_loss: 5.0156\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0028 - val_f1: 0.4430 - val_loss: 5.0397\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0385 - val_f1: 0.4430 - val_loss: 5.0206\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0301 - val_f1: 0.4430 - val_loss: 5.0216\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0274 - val_f1: 0.4430 - val_loss: 5.0167\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0348 - val_f1: 0.4430 - val_loss: 5.0139\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0135 - val_f1: 0.4430 - val_loss: 5.0283\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9930 - val_f1: 0.4430 - val_loss: 5.0195\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9964 - val_f1: 0.4430 - val_loss: 5.0223\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9996 - val_f1: 0.4430 - val_loss: 5.0154\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9980 - val_f1: 0.4430 - val_loss: 5.0166\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9988 - val_f1: 0.4430 - val_loss: 5.0143\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0201 - val_f1: 0.4430 - val_loss: 5.0006\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0224 - val_f1: 0.4430 - val_loss: 5.0136\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0187 - val_f1: 0.4430 - val_loss: 5.0031\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9788 - val_f1: 0.4430 - val_loss: 5.0003\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0054 - val_f1: 0.4430 - val_loss: 5.0142\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9520 - val_f1: 0.4430 - val_loss: 5.0369\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9988 - val_f1: 0.4430 - val_loss: 5.0344\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9899 - val_f1: 0.4430 - val_loss: 5.0461\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0009 - val_f1: 0.4430 - val_loss: 5.0589\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9757 - val_f1: 0.4430 - val_loss: 5.0537\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9885 - val_f1: 0.4430 - val_loss: 5.0365\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9968 - val_f1: 0.4430 - val_loss: 5.0584\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9987 - val_f1: 0.4430 - val_loss: 5.0606\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9817 - val_f1: 0.4430 - val_loss: 5.0665\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9960 - val_f1: 0.4430 - val_loss: 5.1034\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9677 - val_f1: 0.4430 - val_loss: 5.0180\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9343 - val_f1: 0.4430 - val_loss: 5.0623\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9550 - val_f1: 0.4430 - val_loss: 5.0825\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9346 - val_f1: 0.4430 - val_loss: 5.0685\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9523 - val_f1: 0.4430 - val_loss: 5.1654\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9336 - val_f1: 0.4430 - val_loss: 5.0899\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9299 - val_f1: 0.4430 - val_loss: 5.1659\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9482 - val_f1: 0.4430 - val_loss: 5.1501\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9549 - val_f1: 0.4430 - val_loss: 5.1570\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9035 - val_f1: 0.4430 - val_loss: 5.2614\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9094 - val_f1: 0.4430 - val_loss: 5.2352\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9199 - val_f1: 0.4430 - val_loss: 5.0435\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9079 - val_f1: 0.4430 - val_loss: 5.1101\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9046 - val_f1: 0.4430 - val_loss: 5.2866\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8904 - val_f1: 0.4430 - val_loss: 5.2476\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9055 - val_f1: 0.4430 - val_loss: 5.3095\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8859 - val_f1: 0.4430 - val_loss: 5.3616\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9070 - val_f1: 0.4430 - val_loss: 5.2996\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9013 - val_f1: 0.4430 - val_loss: 5.2746\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9296 - val_f1: 0.4430 - val_loss: 5.3023\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9156 - val_f1: 0.4430 - val_loss: 5.1546\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8776 - val_f1: 0.4430 - val_loss: 5.2012\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8789 - val_f1: 0.4430 - val_loss: 5.1477\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8992 - val_f1: 0.4430 - val_loss: 5.0599\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8702 - val_f1: 0.4430 - val_loss: 5.0408\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9104 - val_f1: 0.4430 - val_loss: 5.1301\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8955 - val_f1: 0.4430 - val_loss: 5.0825\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8969 - val_f1: 0.4430 - val_loss: 5.1922\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8682 - val_f1: 0.4430 - val_loss: 5.1448\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9002 - val_f1: 0.4430 - val_loss: 5.1191\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8903 - val_f1: 0.4430 - val_loss: 5.1605\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8808 - val_f1: 0.4430 - val_loss: 5.1731\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8725 - val_f1: 0.4430 - val_loss: 5.0953\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8792 - val_f1: 0.4430 - val_loss: 5.0956\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9114 - val_f1: 0.4430 - val_loss: 5.0616\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8687 - val_f1: 0.4430 - val_loss: 4.9869\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8944 - val_f1: 0.4430 - val_loss: 4.9784\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8844 - val_f1: 0.4430 - val_loss: 4.9526\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8906 - val_f1: 0.4430 - val_loss: 5.0178\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8920 - val_f1: 0.4430 - val_loss: 4.9929\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9099 - val_f1: 0.4430 - val_loss: 5.0093\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8969 - val_f1: 0.4430 - val_loss: 5.0383\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8694 - val_f1: 0.4430 - val_loss: 4.9769\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8958 - val_f1: 0.4430 - val_loss: 4.9411\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8925 - val_f1: 0.4430 - val_loss: 4.9413\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8588 - val_f1: 0.4430 - val_loss: 4.9739\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8770 - val_f1: 0.4430 - val_loss: 4.9327\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8966 - val_f1: 0.4430 - val_loss: 4.9639\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8605 - val_f1: 0.4430 - val_loss: 4.9653\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8613 - val_f1: 0.4430 - val_loss: 4.9211\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8715 - val_f1: 0.4430 - val_loss: 4.9917\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8805 - val_f1: 0.4430 - val_loss: 5.0293\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 4.9167 - val_f1: 0.4430 - val_loss: 5.0191\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8555 - val_f1: 0.4430 - val_loss: 4.9893\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9064 - val_f1: 0.4430 - val_loss: 4.9889\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 32, 32, 0.4, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 3ms/step - f1: 0.4487 - loss: 6.0596 - val_f1: 0.4430 - val_loss: 4.9860\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9553 - val_f1: 0.4430 - val_loss: 4.9577\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9484 - val_f1: 0.4430 - val_loss: 4.8998\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9124 - val_f1: 0.4430 - val_loss: 4.8770\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8795 - val_f1: 0.4430 - val_loss: 4.8659\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8839 - val_f1: 0.4430 - val_loss: 4.8757\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8909 - val_f1: 0.4430 - val_loss: 4.8947\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8877 - val_f1: 0.4430 - val_loss: 4.8739\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8654 - val_f1: 0.4430 - val_loss: 4.8956\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8661 - val_f1: 0.4430 - val_loss: 4.8868\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8506 - val_f1: 0.4430 - val_loss: 4.8790\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8791 - val_f1: 0.4430 - val_loss: 4.8723\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8703 - val_f1: 0.4430 - val_loss: 4.8645\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8446 - val_f1: 0.4430 - val_loss: 4.8749\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8537 - val_f1: 0.4430 - val_loss: 4.8774\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8401 - val_f1: 0.4430 - val_loss: 4.8674\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8568 - val_f1: 0.4430 - val_loss: 4.8690\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8380 - val_f1: 0.4430 - val_loss: 4.8715\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8688 - val_f1: 0.4430 - val_loss: 4.8677\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8814 - val_f1: 0.4430 - val_loss: 4.8635\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8600 - val_f1: 0.4430 - val_loss: 4.8654\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8566 - val_f1: 0.4430 - val_loss: 4.8605\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8762 - val_f1: 0.4430 - val_loss: 4.8692\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4437 - loss: 5.2357 - val_f1: 0.4990 - val_loss: 7.7159\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4716 - loss: 4.9894 - val_f1: 0.5085 - val_loss: 7.4968\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4683 - loss: 5.0199 - val_f1: 0.4980 - val_loss: 6.9267\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4660 - loss: 5.0325 - val_f1: 0.4901 - val_loss: 6.5222\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4572 - loss: 4.9937 - val_f1: 0.4430 - val_loss: 6.1313\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4486 - loss: 4.9812 - val_f1: 0.4430 - val_loss: 5.9794\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4437 - loss: 5.0296 - val_f1: 0.4430 - val_loss: 4.9212\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9112 - val_f1: 0.4430 - val_loss: 4.8648\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.1300 - val_f1: 0.4430 - val_loss: 4.8627\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8780 - val_f1: 0.4430 - val_loss: 4.8610\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8637 - val_f1: 0.4430 - val_loss: 4.8683\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8732 - val_f1: 0.4430 - val_loss: 4.8635\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8762 - val_f1: 0.4430 - val_loss: 4.8556\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8683 - val_f1: 0.4430 - val_loss: 4.8600\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8729 - val_f1: 0.4430 - val_loss: 4.8777\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8667 - val_f1: 0.4430 - val_loss: 4.8658\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8979 - val_f1: 0.4430 - val_loss: 4.8576\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8752 - val_f1: 0.4430 - val_loss: 4.8828\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8904 - val_f1: 0.4430 - val_loss: 4.8953\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8985 - val_f1: 0.4430 - val_loss: 4.8766\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9094 - val_f1: 0.4430 - val_loss: 4.9064\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8794 - val_f1: 0.4430 - val_loss: 4.8887\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9195 - val_f1: 0.4430 - val_loss: 4.8975\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9381 - val_f1: 0.4430 - val_loss: 4.9017\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8788 - val_f1: 0.4430 - val_loss: 4.8589\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8679 - val_f1: 0.4430 - val_loss: 4.8608\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8803 - val_f1: 0.4430 - val_loss: 5.0001\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9258 - val_f1: 0.4430 - val_loss: 5.0308\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8979 - val_f1: 0.4430 - val_loss: 4.9310\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8915 - val_f1: 0.4430 - val_loss: 4.8727\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8967 - val_f1: 0.4430 - val_loss: 4.8616\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8668 - val_f1: 0.4430 - val_loss: 4.8669\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8746 - val_f1: 0.4430 - val_loss: 4.8751\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9097 - val_f1: 0.4430 - val_loss: 4.8992\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8798 - val_f1: 0.4430 - val_loss: 4.8693\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8729 - val_f1: 0.4430 - val_loss: 4.8610\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8697 - val_f1: 0.4430 - val_loss: 4.8995\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8722 - val_f1: 0.4430 - val_loss: 4.9792\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8801 - val_f1: 0.4430 - val_loss: 4.9412\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8600 - val_f1: 0.4430 - val_loss: 5.0251\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8812 - val_f1: 0.4430 - val_loss: 4.8942\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9100 - val_f1: 0.4430 - val_loss: 4.9431\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.1498 - val_f1: 0.4430 - val_loss: 4.8853\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8709 - val_f1: 0.4430 - val_loss: 4.8895\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8957 - val_f1: 0.4430 - val_loss: 4.8668\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8590 - val_f1: 0.4430 - val_loss: 4.9038\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8755 - val_f1: 0.4430 - val_loss: 5.0112\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8971 - val_f1: 0.4430 - val_loss: 4.9760\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8677 - val_f1: 0.4430 - val_loss: 5.0576\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8733 - val_f1: 0.4430 - val_loss: 5.0434\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 4.9413 - val_f1: 0.4430 - val_loss: 5.1431\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9006 - val_f1: 0.4430 - val_loss: 5.3254\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9161 - val_f1: 0.4430 - val_loss: 5.1784\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8649 - val_f1: 0.4430 - val_loss: 5.4855\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9108 - val_f1: 0.4430 - val_loss: 5.6600\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9527 - val_f1: 0.4430 - val_loss: 5.6242\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9271 - val_f1: 0.4430 - val_loss: 6.0765\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9865 - val_f1: 0.4430 - val_loss: 5.6322\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9789 - val_f1: 0.4430 - val_loss: 5.6260\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9951 - val_f1: 0.4430 - val_loss: 5.7340\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9727 - val_f1: 0.4430 - val_loss: 5.5553\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9740 - val_f1: 0.4430 - val_loss: 5.5119\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9798 - val_f1: 0.4430 - val_loss: 5.4965\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9707 - val_f1: 0.4430 - val_loss: 5.5302\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0004 - val_f1: 0.4430 - val_loss: 5.5141\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9803 - val_f1: 0.4430 - val_loss: 5.3890\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9831 - val_f1: 0.4430 - val_loss: 5.8120\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9649 - val_f1: 0.4430 - val_loss: 5.7701\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9615 - val_f1: 0.4430 - val_loss: 5.9922\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9404 - val_f1: 0.4430 - val_loss: 5.7047\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9552 - val_f1: 0.4430 - val_loss: 5.7692\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9730 - val_f1: 0.4430 - val_loss: 5.5445\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9822 - val_f1: 0.4430 - val_loss: 5.8468\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9552 - val_f1: 0.4430 - val_loss: 5.9807\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9688 - val_f1: 0.4430 - val_loss: 5.7305\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9882 - val_f1: 0.4430 - val_loss: 5.7423\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9787 - val_f1: 0.4430 - val_loss: 5.6976\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 32, 32, 0.5, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4442 - loss: 6.0046 - val_f1: 0.4430 - val_loss: 5.0289\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0143 - val_f1: 0.4430 - val_loss: 5.0188\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0252 - val_f1: 0.4430 - val_loss: 5.0245\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0225 - val_f1: 0.4430 - val_loss: 5.0154\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9979 - val_f1: 0.4430 - val_loss: 5.0137\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0213 - val_f1: 0.4430 - val_loss: 5.0188\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0092 - val_f1: 0.4430 - val_loss: 5.0190\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9789 - val_f1: 0.4430 - val_loss: 5.0199\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0139 - val_f1: 0.4430 - val_loss: 5.0173\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0158 - val_f1: 0.4430 - val_loss: 5.0147\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0238 - val_f1: 0.4430 - val_loss: 5.0207\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0095 - val_f1: 0.4430 - val_loss: 5.0312\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0233 - val_f1: 0.4430 - val_loss: 5.0453\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0049 - val_f1: 0.4430 - val_loss: 5.0384\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0256 - val_f1: 0.4430 - val_loss: 5.0377\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0380 - val_f1: 0.4430 - val_loss: 5.0333\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9939 - val_f1: 0.4430 - val_loss: 5.0294\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9970 - val_f1: 0.4430 - val_loss: 5.0280\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0158 - val_f1: 0.4430 - val_loss: 5.0277\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4423 - loss: 5.0646 - val_f1: 0.4430 - val_loss: 5.0185\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0037 - val_f1: 0.4430 - val_loss: 5.0503\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0018 - val_f1: 0.4430 - val_loss: 5.0533\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0329 - val_f1: 0.4430 - val_loss: 5.0259\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0244 - val_f1: 0.4430 - val_loss: 5.0514\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0448 - val_f1: 0.4430 - val_loss: 5.0305\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0123 - val_f1: 0.4430 - val_loss: 5.0386\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0198 - val_f1: 0.4430 - val_loss: 5.0195\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9847 - val_f1: 0.4430 - val_loss: 5.0353\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0168 - val_f1: 0.4430 - val_loss: 5.0310\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0230 - val_f1: 0.4430 - val_loss: 5.0233\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9996 - val_f1: 0.4430 - val_loss: 5.0254\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9945 - val_f1: 0.4430 - val_loss: 5.0377\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9871 - val_f1: 0.4430 - val_loss: 5.0156\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0153 - val_f1: 0.4430 - val_loss: 5.0247\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0021 - val_f1: 0.4430 - val_loss: 5.0481\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9993 - val_f1: 0.4430 - val_loss: 5.0445\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0165 - val_f1: 0.4430 - val_loss: 5.0654\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0000 - val_f1: 0.4430 - val_loss: 5.0647\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0145 - val_f1: 0.4430 - val_loss: 5.0658\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0312 - val_f1: 0.4430 - val_loss: 5.0960\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0155 - val_f1: 0.4430 - val_loss: 5.1038\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9904 - val_f1: 0.4430 - val_loss: 5.1460\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0392 - val_f1: 0.4430 - val_loss: 5.1144\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0407 - val_f1: 0.4430 - val_loss: 5.0885\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9923 - val_f1: 0.4430 - val_loss: 5.1273\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9901 - val_f1: 0.4430 - val_loss: 5.0836\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9756 - val_f1: 0.4430 - val_loss: 5.0971\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0255 - val_f1: 0.4430 - val_loss: 5.0652\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0068 - val_f1: 0.4430 - val_loss: 5.0891\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0154 - val_f1: 0.4430 - val_loss: 5.0558\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0306 - val_f1: 0.4430 - val_loss: 5.0704\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0019 - val_f1: 0.4430 - val_loss: 5.0664\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0018 - val_f1: 0.4430 - val_loss: 5.0693\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0063 - val_f1: 0.4430 - val_loss: 5.0639\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0034 - val_f1: 0.4430 - val_loss: 5.0441\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0204 - val_f1: 0.4430 - val_loss: 5.0517\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0299 - val_f1: 0.4430 - val_loss: 5.0518\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0028 - val_f1: 0.4430 - val_loss: 5.0897\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0008 - val_f1: 0.4430 - val_loss: 5.0765\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9863 - val_f1: 0.4430 - val_loss: 5.0792\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0145 - val_f1: 0.4430 - val_loss: 5.0785\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0165 - val_f1: 0.4430 - val_loss: 5.0422\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0382 - val_f1: 0.4430 - val_loss: 5.0607\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0077 - val_f1: 0.4430 - val_loss: 5.0765\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0229 - val_f1: 0.4430 - val_loss: 5.0672\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0174 - val_f1: 0.4430 - val_loss: 5.0821\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9830 - val_f1: 0.4430 - val_loss: 5.0694\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0010 - val_f1: 0.4430 - val_loss: 5.0583\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0139 - val_f1: 0.4430 - val_loss: 5.0544\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0063 - val_f1: 0.4430 - val_loss: 5.0513\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0367 - val_f1: 0.4430 - val_loss: 5.0559\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0122 - val_f1: 0.4430 - val_loss: 5.0800\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0292 - val_f1: 0.4430 - val_loss: 5.0705\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0228 - val_f1: 0.4430 - val_loss: 5.0764\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0260 - val_f1: 0.4430 - val_loss: 5.0815\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0068 - val_f1: 0.4430 - val_loss: 5.0681\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9883 - val_f1: 0.4430 - val_loss: 5.0921\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9874 - val_f1: 0.4430 - val_loss: 5.0752\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9700 - val_f1: 0.4430 - val_loss: 5.0859\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9979 - val_f1: 0.4430 - val_loss: 5.0968\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0363 - val_f1: 0.4430 - val_loss: 5.0657\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0024 - val_f1: 0.4430 - val_loss: 5.0565\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9870 - val_f1: 0.4430 - val_loss: 5.0854\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9889 - val_f1: 0.4430 - val_loss: 5.0622\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9760 - val_f1: 0.4430 - val_loss: 5.0971\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0276 - val_f1: 0.4430 - val_loss: 5.0914\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0002 - val_f1: 0.4430 - val_loss: 5.0909\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9976 - val_f1: 0.4430 - val_loss: 5.0978\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9978 - val_f1: 0.4430 - val_loss: 5.0783\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0285 - val_f1: 0.4430 - val_loss: 5.0929\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0132 - val_f1: 0.4430 - val_loss: 5.1055\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0032 - val_f1: 0.4430 - val_loss: 5.1300\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0155 - val_f1: 0.4430 - val_loss: 5.0776\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0034 - val_f1: 0.4430 - val_loss: 5.1307\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0218 - val_f1: 0.4430 - val_loss: 5.1725\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0257 - val_f1: 0.4430 - val_loss: 5.1482\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0146 - val_f1: 0.4430 - val_loss: 5.1796\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9767 - val_f1: 0.4430 - val_loss: 5.1440\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0045 - val_f1: 0.4430 - val_loss: 5.1815\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9861 - val_f1: 0.4430 - val_loss: 5.2188\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 32, 64, 0.4, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4441 - loss: 5.5344 - val_f1: 0.4430 - val_loss: 5.0292\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0409 - val_f1: 0.4430 - val_loss: 5.0157\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0311 - val_f1: 0.4430 - val_loss: 5.0136\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0149 - val_f1: 0.4430 - val_loss: 5.0152\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0242 - val_f1: 0.4430 - val_loss: 5.0191\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0182 - val_f1: 0.4430 - val_loss: 5.0178\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0366 - val_f1: 0.4430 - val_loss: 5.0158\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9873 - val_f1: 0.4430 - val_loss: 5.0242\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0025 - val_f1: 0.4430 - val_loss: 5.0211\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0095 - val_f1: 0.4430 - val_loss: 5.0329\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0295 - val_f1: 0.4430 - val_loss: 5.0295\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0205 - val_f1: 0.4430 - val_loss: 5.0171\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0280 - val_f1: 0.4430 - val_loss: 5.0226\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0191 - val_f1: 0.4430 - val_loss: 5.0174\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0211 - val_f1: 0.4430 - val_loss: 5.0324\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0172 - val_f1: 0.4430 - val_loss: 5.0280\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0294 - val_f1: 0.4430 - val_loss: 5.0350\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0250 - val_f1: 0.4430 - val_loss: 5.0333\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0000 - val_f1: 0.4430 - val_loss: 5.0276\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0223 - val_f1: 0.4430 - val_loss: 5.0232\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0000 - val_f1: 0.4430 - val_loss: 5.0500\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0207 - val_f1: 0.4430 - val_loss: 5.0344\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0111 - val_f1: 0.4430 - val_loss: 5.0384\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0337 - val_f1: 0.4430 - val_loss: 5.0381\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0160 - val_f1: 0.4430 - val_loss: 5.0461\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9924 - val_f1: 0.4430 - val_loss: 5.0285\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0084 - val_f1: 0.4430 - val_loss: 5.0291\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9957 - val_f1: 0.4430 - val_loss: 5.0368\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0398 - val_f1: 0.4430 - val_loss: 5.0358\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0029 - val_f1: 0.4430 - val_loss: 5.0349\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9968 - val_f1: 0.4430 - val_loss: 5.0485\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0178 - val_f1: 0.4430 - val_loss: 5.0387\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0114 - val_f1: 0.4430 - val_loss: 5.0503\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0110 - val_f1: 0.4430 - val_loss: 5.0390\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0185 - val_f1: 0.4430 - val_loss: 5.0392\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0328 - val_f1: 0.4430 - val_loss: 5.0447\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9874 - val_f1: 0.4430 - val_loss: 5.0435\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0035 - val_f1: 0.4430 - val_loss: 5.0649\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0533 - val_f1: 0.4430 - val_loss: 5.0371\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0021 - val_f1: 0.4430 - val_loss: 5.0463\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0070 - val_f1: 0.4430 - val_loss: 5.0479\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0010 - val_f1: 0.4430 - val_loss: 5.0378\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0092 - val_f1: 0.4430 - val_loss: 5.0468\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0225 - val_f1: 0.4430 - val_loss: 5.0432\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0050 - val_f1: 0.4430 - val_loss: 5.0537\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0196 - val_f1: 0.4430 - val_loss: 5.0430\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9886 - val_f1: 0.4430 - val_loss: 5.0438\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0133 - val_f1: 0.4430 - val_loss: 5.0473\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0179 - val_f1: 0.4430 - val_loss: 5.0451\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0474 - val_f1: 0.4430 - val_loss: 5.0423\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0486 - val_f1: 0.4430 - val_loss: 5.0365\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0117 - val_f1: 0.4430 - val_loss: 5.0557\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0078 - val_f1: 0.4430 - val_loss: 5.0333\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0182 - val_f1: 0.4430 - val_loss: 5.0270\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0114 - val_f1: 0.4430 - val_loss: 5.0346\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0023 - val_f1: 0.4430 - val_loss: 5.0449\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0322 - val_f1: 0.4430 - val_loss: 5.0375\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0052 - val_f1: 0.4430 - val_loss: 5.0427\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0222 - val_f1: 0.4430 - val_loss: 5.0462\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0298 - val_f1: 0.4430 - val_loss: 5.0366\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0323 - val_f1: 0.4430 - val_loss: 5.0286\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0012 - val_f1: 0.4430 - val_loss: 5.0484\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0015 - val_f1: 0.4430 - val_loss: 5.0458\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9909 - val_f1: 0.4430 - val_loss: 5.0417\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0237 - val_f1: 0.4430 - val_loss: 5.0333\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0076 - val_f1: 0.4430 - val_loss: 5.0409\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0070 - val_f1: 0.4430 - val_loss: 5.0465\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0209 - val_f1: 0.4430 - val_loss: 5.0464\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0134 - val_f1: 0.4430 - val_loss: 5.0489\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0299 - val_f1: 0.4430 - val_loss: 5.0608\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0152 - val_f1: 0.4430 - val_loss: 5.0457\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0157 - val_f1: 0.4430 - val_loss: 5.0368\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0210 - val_f1: 0.4430 - val_loss: 5.0414\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0191 - val_f1: 0.4430 - val_loss: 5.0250\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9918 - val_f1: 0.4430 - val_loss: 4.9889\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9409 - val_f1: 0.4430 - val_loss: 4.9107\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9206 - val_f1: 0.4430 - val_loss: 4.8902\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9131 - val_f1: 0.4430 - val_loss: 4.8625\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8840 - val_f1: 0.4430 - val_loss: 4.8630\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9096 - val_f1: 0.4430 - val_loss: 4.8611\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8981 - val_f1: 0.4430 - val_loss: 4.8668\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8692 - val_f1: 0.4430 - val_loss: 4.8603\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8929 - val_f1: 0.4430 - val_loss: 4.9100\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8996 - val_f1: 0.4430 - val_loss: 4.8711\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8620 - val_f1: 0.4430 - val_loss: 4.8650\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8834 - val_f1: 0.4430 - val_loss: 4.8711\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8748 - val_f1: 0.4430 - val_loss: 4.8631\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9807 - val_f1: 0.4430 - val_loss: 4.8755\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8718 - val_f1: 0.4430 - val_loss: 4.8605\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8682 - val_f1: 0.4430 - val_loss: 4.8887\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9243 - val_f1: 0.4430 - val_loss: 4.8586\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8896 - val_f1: 0.4430 - val_loss: 4.8713\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8660 - val_f1: 0.4430 - val_loss: 4.8810\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8627 - val_f1: 0.4430 - val_loss: 4.8778\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8982 - val_f1: 0.4430 - val_loss: 4.9558\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8950 - val_f1: 0.4430 - val_loss: 4.8753\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9519 - val_f1: 0.4430 - val_loss: 4.8757\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0385 - val_f1: 0.4430 - val_loss: 5.0091\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9867 - val_f1: 0.4430 - val_loss: 4.9825\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0015 - val_f1: 0.4430 - val_loss: 5.0174\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 32, 64, 0.5, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4650 - loss: 6.6192 - val_f1: 0.4430 - val_loss: 4.8997\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8933 - val_f1: 0.4430 - val_loss: 4.8708\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8951 - val_f1: 0.4430 - val_loss: 4.8728\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8663 - val_f1: 0.4430 - val_loss: 4.8758\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8718 - val_f1: 0.4430 - val_loss: 4.8837\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9170 - val_f1: 0.4430 - val_loss: 4.8755\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8884 - val_f1: 0.4430 - val_loss: 4.8680\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8726 - val_f1: 0.4430 - val_loss: 4.8671\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8877 - val_f1: 0.4430 - val_loss: 4.8640\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8983 - val_f1: 0.4430 - val_loss: 4.8675\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8649 - val_f1: 0.4430 - val_loss: 4.8651\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 4.9023 - val_f1: 0.4430 - val_loss: 4.8654\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8754 - val_f1: 0.4430 - val_loss: 4.8646\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8860 - val_f1: 0.4430 - val_loss: 4.8681\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8663 - val_f1: 0.4430 - val_loss: 4.8656\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8655 - val_f1: 0.4430 - val_loss: 4.8699\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8567 - val_f1: 0.4430 - val_loss: 4.8649\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8782 - val_f1: 0.4430 - val_loss: 4.8753\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8761 - val_f1: 0.4430 - val_loss: 4.8684\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8698 - val_f1: 0.4430 - val_loss: 4.8742\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9390 - val_f1: 0.4430 - val_loss: 4.8719\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8744 - val_f1: 0.4430 - val_loss: 4.8842\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8733 - val_f1: 0.4430 - val_loss: 4.8779\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8652 - val_f1: 0.4430 - val_loss: 4.8813\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8987 - val_f1: 0.4430 - val_loss: 4.8758\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8712 - val_f1: 0.4430 - val_loss: 4.8806\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8769 - val_f1: 0.4430 - val_loss: 4.8659\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.8958 - val_f1: 0.4430 - val_loss: 4.8778\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8767 - val_f1: 0.4430 - val_loss: 4.8686\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8624 - val_f1: 0.4430 - val_loss: 4.8694\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8619 - val_f1: 0.4430 - val_loss: 4.8634\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8926 - val_f1: 0.4430 - val_loss: 4.8647\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8705 - val_f1: 0.4430 - val_loss: 4.8690\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9020 - val_f1: 0.4430 - val_loss: 4.8631\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8777 - val_f1: 0.4430 - val_loss: 4.8801\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8508 - val_f1: 0.4430 - val_loss: 4.8815\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8655 - val_f1: 0.4430 - val_loss: 4.8685\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8708 - val_f1: 0.4430 - val_loss: 4.8704\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8748 - val_f1: 0.4430 - val_loss: 4.8655\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8656 - val_f1: 0.4430 - val_loss: 4.8653\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8601 - val_f1: 0.4430 - val_loss: 4.8649\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8787 - val_f1: 0.4430 - val_loss: 4.8659\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8585 - val_f1: 0.4430 - val_loss: 4.8764\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8616 - val_f1: 0.4430 - val_loss: 4.8628\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9505 - val_f1: 0.4430 - val_loss: 4.9367\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9854 - val_f1: 0.4430 - val_loss: 4.8703\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8878 - val_f1: 0.4430 - val_loss: 4.8757\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9031 - val_f1: 0.4430 - val_loss: 4.8701\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8843 - val_f1: 0.4430 - val_loss: 4.8706\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8606 - val_f1: 0.4430 - val_loss: 4.9069\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8877 - val_f1: 0.4430 - val_loss: 4.8664\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8854 - val_f1: 0.4430 - val_loss: 4.8900\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8727 - val_f1: 0.4430 - val_loss: 4.8882\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8442 - val_f1: 0.4430 - val_loss: 4.8951\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8678 - val_f1: 0.4430 - val_loss: 4.9135\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8571 - val_f1: 0.4430 - val_loss: 4.8924\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8659 - val_f1: 0.4430 - val_loss: 4.8827\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8847 - val_f1: 0.4430 - val_loss: 4.9952\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8953 - val_f1: 0.4430 - val_loss: 4.9690\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9000 - val_f1: 0.4430 - val_loss: 4.9044\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8986 - val_f1: 0.4430 - val_loss: 4.8773\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8378 - val_f1: 0.4430 - val_loss: 4.8851\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8471 - val_f1: 0.4430 - val_loss: 4.8830\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8711 - val_f1: 0.4430 - val_loss: 4.9293\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8704 - val_f1: 0.4430 - val_loss: 4.9329\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8960 - val_f1: 0.4430 - val_loss: 4.8918\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8646 - val_f1: 0.4430 - val_loss: 4.8731\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8797 - val_f1: 0.4430 - val_loss: 4.8868\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8815 - val_f1: 0.4430 - val_loss: 4.8994\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8809 - val_f1: 0.4430 - val_loss: 4.9194\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8889 - val_f1: 0.4430 - val_loss: 4.8926\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8669 - val_f1: 0.4430 - val_loss: 4.8823\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8696 - val_f1: 0.4430 - val_loss: 4.9097\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8902 - val_f1: 0.4430 - val_loss: 4.8951\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8581 - val_f1: 0.4430 - val_loss: 4.9208\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8821 - val_f1: 0.4430 - val_loss: 4.8997\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8663 - val_f1: 0.4430 - val_loss: 4.9096\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8540 - val_f1: 0.4430 - val_loss: 4.9399\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8776 - val_f1: 0.4430 - val_loss: 4.9172\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8358 - val_f1: 0.4430 - val_loss: 4.9098\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8736 - val_f1: 0.4430 - val_loss: 4.8948\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8394 - val_f1: 0.4430 - val_loss: 4.9367\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8697 - val_f1: 0.4430 - val_loss: 4.9081\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8577 - val_f1: 0.4430 - val_loss: 4.9231\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8519 - val_f1: 0.4430 - val_loss: 4.9394\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8492 - val_f1: 0.4430 - val_loss: 4.9240\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8432 - val_f1: 0.4430 - val_loss: 4.9354\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8662 - val_f1: 0.4430 - val_loss: 4.8684\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8744 - val_f1: 0.4430 - val_loss: 4.9651\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8456 - val_f1: 0.4430 - val_loss: 4.9204\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8743 - val_f1: 0.4430 - val_loss: 4.9372\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8516 - val_f1: 0.4430 - val_loss: 4.9150\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8548 - val_f1: 0.4430 - val_loss: 4.8958\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8455 - val_f1: 0.4430 - val_loss: 4.8905\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4424 - loss: 4.8938 - val_f1: 0.4430 - val_loss: 4.9001\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8936 - val_f1: 0.4430 - val_loss: 4.8865\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.8902 - val_f1: 0.4430 - val_loss: 4.8871\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8392 - val_f1: 0.4430 - val_loss: 4.8995\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8561 - val_f1: 0.4430 - val_loss: 4.8828\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8477 - val_f1: 0.4430 - val_loss: 4.8806\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 32, 128, 0.4, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4520 - loss: 5.7565 - val_f1: 0.4430 - val_loss: 5.0203\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0074 - val_f1: 0.4430 - val_loss: 5.0075\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0176 - val_f1: 0.4430 - val_loss: 5.0093\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0058 - val_f1: 0.4430 - val_loss: 5.0132\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0314 - val_f1: 0.4430 - val_loss: 5.0077\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0167 - val_f1: 0.4430 - val_loss: 5.0123\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0184 - val_f1: 0.4430 - val_loss: 5.0209\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0284 - val_f1: 0.4430 - val_loss: 5.0203\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0333 - val_f1: 0.4430 - val_loss: 5.0177\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0241 - val_f1: 0.4430 - val_loss: 5.0247\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0280 - val_f1: 0.4430 - val_loss: 5.0157\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9885 - val_f1: 0.4430 - val_loss: 5.0319\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0105 - val_f1: 0.4430 - val_loss: 5.0422\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0335 - val_f1: 0.4430 - val_loss: 5.0198\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0247 - val_f1: 0.4430 - val_loss: 5.0299\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0327 - val_f1: 0.4430 - val_loss: 5.0308\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0147 - val_f1: 0.4430 - val_loss: 5.0399\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9857 - val_f1: 0.4430 - val_loss: 5.0367\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9938 - val_f1: 0.4430 - val_loss: 5.0329\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0167 - val_f1: 0.4430 - val_loss: 5.0394\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0266 - val_f1: 0.4430 - val_loss: 5.0477\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0158 - val_f1: 0.4430 - val_loss: 5.0403\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9973 - val_f1: 0.4430 - val_loss: 5.0660\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9979 - val_f1: 0.4430 - val_loss: 5.0607\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9757 - val_f1: 0.4430 - val_loss: 5.0452\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0173 - val_f1: 0.4430 - val_loss: 5.0325\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0288 - val_f1: 0.4430 - val_loss: 5.0353\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0021 - val_f1: 0.4430 - val_loss: 5.0544\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0198 - val_f1: 0.4430 - val_loss: 5.0586\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9920 - val_f1: 0.4430 - val_loss: 5.0376\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0257 - val_f1: 0.4430 - val_loss: 5.0441\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0303 - val_f1: 0.4430 - val_loss: 5.0439\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9988 - val_f1: 0.4430 - val_loss: 5.0344\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0131 - val_f1: 0.4430 - val_loss: 5.0359\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0197 - val_f1: 0.4430 - val_loss: 5.0304\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0243 - val_f1: 0.4430 - val_loss: 5.0568\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0232 - val_f1: 0.4430 - val_loss: 5.0390\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0461 - val_f1: 0.4430 - val_loss: 5.0734\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9761 - val_f1: 0.4430 - val_loss: 5.0413\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0072 - val_f1: 0.4430 - val_loss: 5.0428\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0153 - val_f1: 0.4430 - val_loss: 5.0372\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0022 - val_f1: 0.4430 - val_loss: 5.0449\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9980 - val_f1: 0.4430 - val_loss: 5.0438\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0264 - val_f1: 0.4430 - val_loss: 5.0419\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0402 - val_f1: 0.4430 - val_loss: 5.0542\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0142 - val_f1: 0.4430 - val_loss: 5.0404\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0009 - val_f1: 0.4430 - val_loss: 5.0622\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0175 - val_f1: 0.4430 - val_loss: 5.0292\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9955 - val_f1: 0.4430 - val_loss: 5.0430\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0019 - val_f1: 0.4430 - val_loss: 5.0327\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0232 - val_f1: 0.4430 - val_loss: 5.0542\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9884 - val_f1: 0.4430 - val_loss: 5.0552\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0030 - val_f1: 0.4430 - val_loss: 5.0616\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9973 - val_f1: 0.4430 - val_loss: 5.0538\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0201 - val_f1: 0.4430 - val_loss: 5.0375\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0275 - val_f1: 0.4430 - val_loss: 5.0721\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0128 - val_f1: 0.4430 - val_loss: 5.0505\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0077 - val_f1: 0.4430 - val_loss: 5.0660\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0157 - val_f1: 0.4430 - val_loss: 5.0444\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0087 - val_f1: 0.4430 - val_loss: 5.0399\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9921 - val_f1: 0.4430 - val_loss: 5.0516\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0075 - val_f1: 0.4430 - val_loss: 5.0552\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9951 - val_f1: 0.4430 - val_loss: 5.0626\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0078 - val_f1: 0.4430 - val_loss: 5.0779\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9997 - val_f1: 0.4430 - val_loss: 5.0649\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0173 - val_f1: 0.4430 - val_loss: 5.0596\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0004 - val_f1: 0.4430 - val_loss: 5.0441\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9991 - val_f1: 0.4430 - val_loss: 5.0820\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0088 - val_f1: 0.4430 - val_loss: 5.0468\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0234 - val_f1: 0.4430 - val_loss: 5.0514\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0095 - val_f1: 0.4430 - val_loss: 5.0619\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9985 - val_f1: 0.4430 - val_loss: 5.0557\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0233 - val_f1: 0.4430 - val_loss: 5.0458\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9852 - val_f1: 0.4430 - val_loss: 5.0661\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0240 - val_f1: 0.4430 - val_loss: 5.0429\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0094 - val_f1: 0.4430 - val_loss: 5.0800\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0261 - val_f1: 0.4430 - val_loss: 5.0444\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0107 - val_f1: 0.4430 - val_loss: 5.0664\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9985 - val_f1: 0.4430 - val_loss: 5.0847\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0015 - val_f1: 0.4430 - val_loss: 5.0585\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9884 - val_f1: 0.4430 - val_loss: 5.0503\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0227 - val_f1: 0.4430 - val_loss: 5.0493\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0157 - val_f1: 0.4430 - val_loss: 5.0629\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0006 - val_f1: 0.4430 - val_loss: 5.0791\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0056 - val_f1: 0.4430 - val_loss: 5.0633\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0021 - val_f1: 0.4430 - val_loss: 5.0729\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0206 - val_f1: 0.4430 - val_loss: 5.0465\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9893 - val_f1: 0.4430 - val_loss: 5.0756\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 5.0005 - val_f1: 0.4430 - val_loss: 5.0628\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9826 - val_f1: 0.4430 - val_loss: 5.0917\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0062 - val_f1: 0.4430 - val_loss: 5.0752\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0040 - val_f1: 0.4430 - val_loss: 5.0864\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9926 - val_f1: 0.4430 - val_loss: 5.0805\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0047 - val_f1: 0.4430 - val_loss: 5.0681\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0173 - val_f1: 0.4430 - val_loss: 5.0552\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9995 - val_f1: 0.4430 - val_loss: 5.0609\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0075 - val_f1: 0.4430 - val_loss: 5.0892\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0215 - val_f1: 0.4430 - val_loss: 5.0651\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0042 - val_f1: 0.4430 - val_loss: 5.1072\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9935 - val_f1: 0.4430 - val_loss: 5.0845\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 32, 128, 0.5, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 4ms/step - f1: 0.4481 - loss: 6.1529 - val_f1: 0.4430 - val_loss: 4.9265\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8917 - val_f1: 0.4430 - val_loss: 4.8932\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9024 - val_f1: 0.4430 - val_loss: 4.8698\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8790 - val_f1: 0.4430 - val_loss: 4.8807\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9063 - val_f1: 0.4430 - val_loss: 4.9763\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9005 - val_f1: 0.4430 - val_loss: 4.8735\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8863 - val_f1: 0.4430 - val_loss: 4.8864\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9113 - val_f1: 0.4430 - val_loss: 4.8726\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 4.9023 - val_f1: 0.4430 - val_loss: 4.9204\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4423 - loss: 5.5456 - val_f1: 0.4430 - val_loss: 5.3394\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0210 - val_f1: 0.4430 - val_loss: 4.9518\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9454 - val_f1: 0.4430 - val_loss: 4.9275\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9093 - val_f1: 0.4430 - val_loss: 4.8697\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8778 - val_f1: 0.4430 - val_loss: 4.8822\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8587 - val_f1: 0.4430 - val_loss: 4.8804\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9154 - val_f1: 0.4430 - val_loss: 4.8690\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8771 - val_f1: 0.4430 - val_loss: 4.8903\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8858 - val_f1: 0.4430 - val_loss: 4.8678\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9105 - val_f1: 0.4430 - val_loss: 4.8553\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8883 - val_f1: 0.4430 - val_loss: 4.8706\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8964 - val_f1: 0.4430 - val_loss: 4.8679\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8673 - val_f1: 0.4430 - val_loss: 4.8575\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8806 - val_f1: 0.4430 - val_loss: 4.8577\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8712 - val_f1: 0.4430 - val_loss: 4.8590\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8633 - val_f1: 0.4430 - val_loss: 4.8739\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8743 - val_f1: 0.4430 - val_loss: 4.8895\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8957 - val_f1: 0.4430 - val_loss: 4.8651\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8877 - val_f1: 0.4430 - val_loss: 4.8551\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8568 - val_f1: 0.4430 - val_loss: 4.8539\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8925 - val_f1: 0.4430 - val_loss: 4.8585\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8886 - val_f1: 0.4430 - val_loss: 4.8611\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8587 - val_f1: 0.4430 - val_loss: 4.8706\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8761 - val_f1: 0.4430 - val_loss: 4.8685\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8706 - val_f1: 0.4430 - val_loss: 4.8645\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8651 - val_f1: 0.4430 - val_loss: 4.8738\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8717 - val_f1: 0.4430 - val_loss: 4.8674\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8721 - val_f1: 0.4430 - val_loss: 4.8642\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8691 - val_f1: 0.4430 - val_loss: 4.8698\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8621 - val_f1: 0.4430 - val_loss: 4.8668\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8736 - val_f1: 0.4430 - val_loss: 4.8577\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8621 - val_f1: 0.4430 - val_loss: 4.8636\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8828 - val_f1: 0.4430 - val_loss: 4.8633\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8815 - val_f1: 0.4430 - val_loss: 4.8737\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8646 - val_f1: 0.4430 - val_loss: 4.8764\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8524 - val_f1: 0.4430 - val_loss: 4.8956\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8658 - val_f1: 0.4430 - val_loss: 4.8660\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8530 - val_f1: 0.4430 - val_loss: 4.8712\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8643 - val_f1: 0.4430 - val_loss: 4.8694\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8727 - val_f1: 0.4430 - val_loss: 4.8606\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8461 - val_f1: 0.4430 - val_loss: 4.8642\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8643 - val_f1: 0.4430 - val_loss: 4.8683\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8640 - val_f1: 0.4430 - val_loss: 4.8677\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8529 - val_f1: 0.4430 - val_loss: 4.8710\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8388 - val_f1: 0.4430 - val_loss: 4.8618\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8570 - val_f1: 0.4430 - val_loss: 4.8775\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8746 - val_f1: 0.4430 - val_loss: 4.8612\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8708 - val_f1: 0.4430 - val_loss: 4.8682\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8851 - val_f1: 0.4430 - val_loss: 4.8654\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8762 - val_f1: 0.4430 - val_loss: 4.8962\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8659 - val_f1: 0.4430 - val_loss: 4.9126\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9613 - val_f1: 0.4430 - val_loss: 5.7086\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4686 - loss: 5.4801 - val_f1: 0.4934 - val_loss: 9.2320\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4767 - loss: 5.0618 - val_f1: 0.4430 - val_loss: 5.0118\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9819 - val_f1: 0.4430 - val_loss: 4.8863\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.1126 - val_f1: 0.4430 - val_loss: 4.8699\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4464 - loss: 5.1096 - val_f1: 0.4430 - val_loss: 4.9547\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9074 - val_f1: 0.4430 - val_loss: 4.8665\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8887 - val_f1: 0.4430 - val_loss: 4.8591\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8548 - val_f1: 0.4430 - val_loss: 4.8590\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8638 - val_f1: 0.4430 - val_loss: 4.8644\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8612 - val_f1: 0.4430 - val_loss: 4.8622\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8720 - val_f1: 0.4430 - val_loss: 4.8608\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8622 - val_f1: 0.4430 - val_loss: 4.8690\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8713 - val_f1: 0.4430 - val_loss: 4.8677\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9004 - val_f1: 0.4430 - val_loss: 4.8597\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8777 - val_f1: 0.4430 - val_loss: 4.8639\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8456 - val_f1: 0.4430 - val_loss: 4.8731\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8510 - val_f1: 0.4430 - val_loss: 4.8679\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8642 - val_f1: 0.4430 - val_loss: 4.8741\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8662 - val_f1: 0.4430 - val_loss: 4.8672\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8674 - val_f1: 0.4430 - val_loss: 4.8718\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8530 - val_f1: 0.4430 - val_loss: 4.8655\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8494 - val_f1: 0.4430 - val_loss: 4.8672\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8814 - val_f1: 0.4430 - val_loss: 4.8567\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8924 - val_f1: 0.4430 - val_loss: 4.8699\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8661 - val_f1: 0.4430 - val_loss: 4.8652\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8483 - val_f1: 0.4430 - val_loss: 4.8793\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8652 - val_f1: 0.4430 - val_loss: 4.8848\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8365 - val_f1: 0.4430 - val_loss: 4.8749\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8395 - val_f1: 0.4430 - val_loss: 4.8728\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8541 - val_f1: 0.4430 - val_loss: 4.8739\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8793 - val_f1: 0.4430 - val_loss: 4.8678\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8440 - val_f1: 0.4430 - val_loss: 4.8729\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8596 - val_f1: 0.4430 - val_loss: 4.8718\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8483 - val_f1: 0.4430 - val_loss: 4.8721\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4423 - loss: 4.8970 - val_f1: 0.4430 - val_loss: 4.8692\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8748 - val_f1: 0.4430 - val_loss: 4.8675\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8665 - val_f1: 0.4430 - val_loss: 4.8710\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8703 - val_f1: 0.4430 - val_loss: 4.8703\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8352 - val_f1: 0.4430 - val_loss: 4.8721\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 64, 32, 0.4, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 3ms/step - f1: 0.4571 - loss: 6.3096 - val_f1: 0.4430 - val_loss: 5.0933\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0532 - val_f1: 0.4430 - val_loss: 5.0656\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0441 - val_f1: 0.4430 - val_loss: 5.0460\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0215 - val_f1: 0.4430 - val_loss: 5.0182\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0095 - val_f1: 0.4430 - val_loss: 4.9974\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0319 - val_f1: 0.4430 - val_loss: 4.9894\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9901 - val_f1: 0.4430 - val_loss: 4.9693\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9745 - val_f1: 0.4430 - val_loss: 4.9667\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9449 - val_f1: 0.4430 - val_loss: 4.9635\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9550 - val_f1: 0.4430 - val_loss: 4.9655\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9095 - val_f1: 0.4430 - val_loss: 4.9387\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9314 - val_f1: 0.4430 - val_loss: 4.9125\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9383 - val_f1: 0.4430 - val_loss: 5.3096\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0359 - val_f1: 0.4430 - val_loss: 5.0214\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0152 - val_f1: 0.4430 - val_loss: 5.0117\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0464 - val_f1: 0.4430 - val_loss: 5.0168\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9509 - val_f1: 0.4430 - val_loss: 4.9664\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9566 - val_f1: 0.4430 - val_loss: 4.9640\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9675 - val_f1: 0.4430 - val_loss: 4.9660\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9726 - val_f1: 0.4430 - val_loss: 4.9888\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9762 - val_f1: 0.4430 - val_loss: 4.9746\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9490 - val_f1: 0.4430 - val_loss: 4.9876\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9606 - val_f1: 0.4430 - val_loss: 5.0105\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4436 - loss: 4.9297 - val_f1: 0.4430 - val_loss: 5.0385\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9766 - val_f1: 0.4430 - val_loss: 5.0596\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9448 - val_f1: 0.4430 - val_loss: 5.1025\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9658 - val_f1: 0.4430 - val_loss: 5.0871\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9726 - val_f1: 0.4430 - val_loss: 5.3864\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0211 - val_f1: 0.4430 - val_loss: 5.3386\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0093 - val_f1: 0.4430 - val_loss: 5.3533\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9962 - val_f1: 0.4430 - val_loss: 5.1967\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9785 - val_f1: 0.4430 - val_loss: 5.3460\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9725 - val_f1: 0.4430 - val_loss: 5.4594\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0121 - val_f1: 0.4430 - val_loss: 5.3980\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9740 - val_f1: 0.4430 - val_loss: 5.3949\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0065 - val_f1: 0.4430 - val_loss: 5.3951\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0213 - val_f1: 0.4430 - val_loss: 5.3511\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 5.0022 - val_f1: 0.4430 - val_loss: 5.4417\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0475 - val_f1: 0.4430 - val_loss: 5.3609\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0288 - val_f1: 0.4430 - val_loss: 5.3453\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0055 - val_f1: 0.4430 - val_loss: 5.4125\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0449 - val_f1: 0.4430 - val_loss: 5.3495\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0303 - val_f1: 0.4430 - val_loss: 5.3506\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9996 - val_f1: 0.4430 - val_loss: 5.2402\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0056 - val_f1: 0.4430 - val_loss: 5.3227\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9778 - val_f1: 0.4430 - val_loss: 5.3166\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9871 - val_f1: 0.4430 - val_loss: 5.2770\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9716 - val_f1: 0.4430 - val_loss: 5.4146\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9942 - val_f1: 0.4430 - val_loss: 5.2605\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9966 - val_f1: 0.4430 - val_loss: 5.3755\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9803 - val_f1: 0.4430 - val_loss: 5.3522\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9990 - val_f1: 0.4430 - val_loss: 5.4249\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9830 - val_f1: 0.4430 - val_loss: 5.5469\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9776 - val_f1: 0.4430 - val_loss: 5.5092\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0217 - val_f1: 0.4430 - val_loss: 5.4825\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9832 - val_f1: 0.4430 - val_loss: 5.4348\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9836 - val_f1: 0.4430 - val_loss: 5.4284\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9822 - val_f1: 0.4430 - val_loss: 5.6111\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9929 - val_f1: 0.4430 - val_loss: 5.2852\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9550 - val_f1: 0.4430 - val_loss: 5.4293\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9646 - val_f1: 0.4430 - val_loss: 5.5278\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9655 - val_f1: 0.4430 - val_loss: 5.5273\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9733 - val_f1: 0.4430 - val_loss: 5.5935\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9729 - val_f1: 0.4430 - val_loss: 5.7087\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9708 - val_f1: 0.4430 - val_loss: 5.7316\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9661 - val_f1: 0.4430 - val_loss: 5.6550\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9845 - val_f1: 0.4430 - val_loss: 5.7361\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0060 - val_f1: 0.4430 - val_loss: 5.8048\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9902 - val_f1: 0.4430 - val_loss: 5.8873\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9933 - val_f1: 0.4430 - val_loss: 5.9571\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9993 - val_f1: 0.4430 - val_loss: 6.0559\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0351 - val_f1: 0.4430 - val_loss: 6.0883\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0015 - val_f1: 0.4430 - val_loss: 5.9308\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0176 - val_f1: 0.4430 - val_loss: 5.9698\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0264 - val_f1: 0.4430 - val_loss: 5.9555\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0298 - val_f1: 0.4430 - val_loss: 6.0216\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0041 - val_f1: 0.4430 - val_loss: 5.7773\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9925 - val_f1: 0.4430 - val_loss: 5.8158\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0128 - val_f1: 0.4430 - val_loss: 5.8209\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9875 - val_f1: 0.4430 - val_loss: 5.9691\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0082 - val_f1: 0.4430 - val_loss: 5.7807\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9797 - val_f1: 0.4430 - val_loss: 5.8470\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9947 - val_f1: 0.4430 - val_loss: 5.7552\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9946 - val_f1: 0.4430 - val_loss: 6.0392\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0136 - val_f1: 0.4430 - val_loss: 6.0302\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0078 - val_f1: 0.4430 - val_loss: 6.0659\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0432 - val_f1: 0.4430 - val_loss: 6.0424\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9996 - val_f1: 0.4430 - val_loss: 6.2014\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0032 - val_f1: 0.4430 - val_loss: 6.0747\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9953 - val_f1: 0.4430 - val_loss: 6.0614\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9907 - val_f1: 0.4430 - val_loss: 5.9315\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0009 - val_f1: 0.4430 - val_loss: 6.0840\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0106 - val_f1: 0.4430 - val_loss: 6.1293\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0184 - val_f1: 0.4430 - val_loss: 6.0437\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9958 - val_f1: 0.4430 - val_loss: 5.9940\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9575 - val_f1: 0.4430 - val_loss: 6.0891\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9741 - val_f1: 0.4430 - val_loss: 6.2668\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9942 - val_f1: 0.4430 - val_loss: 6.1696\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9937 - val_f1: 0.4430 - val_loss: 6.1414\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0013 - val_f1: 0.4430 - val_loss: 6.0711\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 64, 32, 0.5, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4430 - loss: 5.5335 - val_f1: 0.4430 - val_loss: 5.0156\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0126 - val_f1: 0.4430 - val_loss: 5.0186\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0314 - val_f1: 0.4430 - val_loss: 5.0147\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0083 - val_f1: 0.4430 - val_loss: 5.0190\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0319 - val_f1: 0.4430 - val_loss: 5.0173\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9860 - val_f1: 0.4430 - val_loss: 5.0181\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9996 - val_f1: 0.4430 - val_loss: 5.0248\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9915 - val_f1: 0.4430 - val_loss: 5.0193\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0398 - val_f1: 0.4430 - val_loss: 5.0340\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0174 - val_f1: 0.4430 - val_loss: 5.0201\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0322 - val_f1: 0.4430 - val_loss: 5.0268\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0295 - val_f1: 0.4430 - val_loss: 5.0224\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0165 - val_f1: 0.4430 - val_loss: 5.0262\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0116 - val_f1: 0.4430 - val_loss: 5.0286\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0007 - val_f1: 0.4430 - val_loss: 5.0234\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0071 - val_f1: 0.4430 - val_loss: 5.0301\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0159 - val_f1: 0.4430 - val_loss: 5.0303\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9957 - val_f1: 0.4430 - val_loss: 5.0417\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0309 - val_f1: 0.4430 - val_loss: 5.0284\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9943 - val_f1: 0.4430 - val_loss: 5.0452\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9931 - val_f1: 0.4430 - val_loss: 5.0211\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0058 - val_f1: 0.4430 - val_loss: 5.0504\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.9773 - val_f1: 0.4430 - val_loss: 5.0592\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0190 - val_f1: 0.4430 - val_loss: 5.0614\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9997 - val_f1: 0.4430 - val_loss: 5.0411\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0300 - val_f1: 0.4430 - val_loss: 5.0693\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0289 - val_f1: 0.4430 - val_loss: 5.0392\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9978 - val_f1: 0.4430 - val_loss: 5.0584\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 5.0412 - val_f1: 0.4430 - val_loss: 5.0472\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0174 - val_f1: 0.4430 - val_loss: 5.0631\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0078 - val_f1: 0.4430 - val_loss: 5.0515\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0312 - val_f1: 0.4430 - val_loss: 5.0536\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0085 - val_f1: 0.4430 - val_loss: 5.0677\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9793 - val_f1: 0.4430 - val_loss: 5.0502\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9856 - val_f1: 0.4430 - val_loss: 5.0742\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0053 - val_f1: 0.4430 - val_loss: 5.0599\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9863 - val_f1: 0.4430 - val_loss: 5.0801\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9951 - val_f1: 0.4430 - val_loss: 5.0780\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0367 - val_f1: 0.4430 - val_loss: 5.0469\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0181 - val_f1: 0.4430 - val_loss: 5.0672\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0207 - val_f1: 0.4430 - val_loss: 5.0352\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0308 - val_f1: 0.4430 - val_loss: 5.0640\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0275 - val_f1: 0.4430 - val_loss: 5.0509\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0094 - val_f1: 0.4430 - val_loss: 5.0586\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0171 - val_f1: 0.4430 - val_loss: 5.0634\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0224 - val_f1: 0.4430 - val_loss: 5.0538\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0081 - val_f1: 0.4430 - val_loss: 5.0549\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0136 - val_f1: 0.4430 - val_loss: 5.0677\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0331 - val_f1: 0.4430 - val_loss: 5.0917\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0006 - val_f1: 0.4430 - val_loss: 5.0674\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0001 - val_f1: 0.4430 - val_loss: 5.0386\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0023 - val_f1: 0.4430 - val_loss: 5.0642\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0186 - val_f1: 0.4430 - val_loss: 5.0776\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9992 - val_f1: 0.4430 - val_loss: 5.0513\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0070 - val_f1: 0.4430 - val_loss: 5.0540\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0181 - val_f1: 0.4430 - val_loss: 5.0282\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9806 - val_f1: 0.4430 - val_loss: 4.9840\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9532 - val_f1: 0.4430 - val_loss: 4.9826\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9881 - val_f1: 0.4430 - val_loss: 4.9807\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9778 - val_f1: 0.4430 - val_loss: 4.9932\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9819 - val_f1: 0.4430 - val_loss: 4.9794\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9673 - val_f1: 0.4430 - val_loss: 4.9792\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9536 - val_f1: 0.4430 - val_loss: 5.0091\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9651 - val_f1: 0.4430 - val_loss: 5.0085\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9183 - val_f1: 0.4430 - val_loss: 5.0166\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9578 - val_f1: 0.4430 - val_loss: 5.0093\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9482 - val_f1: 0.4430 - val_loss: 5.2128\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0029 - val_f1: 0.4430 - val_loss: 5.2035\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0122 - val_f1: 0.4430 - val_loss: 5.2006\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0133 - val_f1: 0.4430 - val_loss: 5.2615\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0181 - val_f1: 0.4430 - val_loss: 5.2641\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0091 - val_f1: 0.4430 - val_loss: 5.2007\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0278 - val_f1: 0.4430 - val_loss: 5.2412\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9890 - val_f1: 0.4430 - val_loss: 5.2656\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0488 - val_f1: 0.4430 - val_loss: 5.2237\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9885 - val_f1: 0.4430 - val_loss: 5.2986\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0418 - val_f1: 0.4430 - val_loss: 5.2771\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0273 - val_f1: 0.4430 - val_loss: 5.2470\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0297 - val_f1: 0.4430 - val_loss: 5.2774\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0175 - val_f1: 0.4430 - val_loss: 5.2100\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9999 - val_f1: 0.4430 - val_loss: 5.2914\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0141 - val_f1: 0.4430 - val_loss: 5.2739\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0260 - val_f1: 0.4430 - val_loss: 5.2634\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0171 - val_f1: 0.4430 - val_loss: 5.2254\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9907 - val_f1: 0.4430 - val_loss: 5.2592\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0036 - val_f1: 0.4430 - val_loss: 5.2591\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9961 - val_f1: 0.4430 - val_loss: 5.2776\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0067 - val_f1: 0.4430 - val_loss: 5.2872\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0232 - val_f1: 0.4430 - val_loss: 5.2320\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0153 - val_f1: 0.4430 - val_loss: 5.2634\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9942 - val_f1: 0.4430 - val_loss: 5.2480\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0137 - val_f1: 0.4430 - val_loss: 5.2534\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0251 - val_f1: 0.4430 - val_loss: 5.2612\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9973 - val_f1: 0.4430 - val_loss: 5.2298\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0219 - val_f1: 0.4430 - val_loss: 5.2667\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9817 - val_f1: 0.4430 - val_loss: 5.3061\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9791 - val_f1: 0.4430 - val_loss: 5.2656\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0204 - val_f1: 0.4430 - val_loss: 5.2955\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0125 - val_f1: 0.4430 - val_loss: 5.2509\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0136 - val_f1: 0.4430 - val_loss: 5.2822\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 64, 64, 0.4, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4460 - loss: 6.3443 - val_f1: 0.4430 - val_loss: 4.9550\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9515 - val_f1: 0.4430 - val_loss: 4.9028\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8996 - val_f1: 0.4430 - val_loss: 4.9219\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9464 - val_f1: 0.4430 - val_loss: 4.9350\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9609 - val_f1: 0.4430 - val_loss: 4.9534\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9409 - val_f1: 0.4430 - val_loss: 4.9340\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9339 - val_f1: 0.4430 - val_loss: 4.9338\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8888 - val_f1: 0.4430 - val_loss: 4.9020\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9098 - val_f1: 0.4430 - val_loss: 4.9059\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8949 - val_f1: 0.4430 - val_loss: 4.9245\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9093 - val_f1: 0.4430 - val_loss: 4.9086\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9091 - val_f1: 0.4430 - val_loss: 4.8906\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8790 - val_f1: 0.4430 - val_loss: 4.8808\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8878 - val_f1: 0.4430 - val_loss: 4.8738\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8808 - val_f1: 0.4430 - val_loss: 4.8807\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8902 - val_f1: 0.4430 - val_loss: 4.8848\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8913 - val_f1: 0.4430 - val_loss: 4.9306\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8855 - val_f1: 0.4430 - val_loss: 4.9290\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9198 - val_f1: 0.4430 - val_loss: 4.9177\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9108 - val_f1: 0.4430 - val_loss: 4.9145\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9084 - val_f1: 0.4430 - val_loss: 4.9263\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8851 - val_f1: 0.4430 - val_loss: 4.9022\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9097 - val_f1: 0.4430 - val_loss: 5.1310\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8754 - val_f1: 0.4430 - val_loss: 5.0390\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8847 - val_f1: 0.4430 - val_loss: 4.9950\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8911 - val_f1: 0.4430 - val_loss: 4.9603\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8728 - val_f1: 0.4430 - val_loss: 4.9301\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8827 - val_f1: 0.4430 - val_loss: 5.1794\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8787 - val_f1: 0.4430 - val_loss: 5.0187\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8782 - val_f1: 0.4430 - val_loss: 5.1275\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9127 - val_f1: 0.4430 - val_loss: 4.9375\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8655 - val_f1: 0.4430 - val_loss: 5.0315\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8642 - val_f1: 0.4430 - val_loss: 4.9913\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8567 - val_f1: 0.4430 - val_loss: 5.0492\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8773 - val_f1: 0.4430 - val_loss: 4.9923\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8771 - val_f1: 0.4430 - val_loss: 4.9216\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9234 - val_f1: 0.4430 - val_loss: 4.9526\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8798 - val_f1: 0.4430 - val_loss: 4.9347\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9094 - val_f1: 0.4430 - val_loss: 4.9389\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9062 - val_f1: 0.4430 - val_loss: 4.9411\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9058 - val_f1: 0.4430 - val_loss: 4.9076\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8788 - val_f1: 0.4430 - val_loss: 4.9248\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8776 - val_f1: 0.4430 - val_loss: 4.9172\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8847 - val_f1: 0.4430 - val_loss: 4.9568\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9072 - val_f1: 0.4430 - val_loss: 4.9522\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9001 - val_f1: 0.4430 - val_loss: 4.9166\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8481 - val_f1: 0.4430 - val_loss: 4.9313\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8544 - val_f1: 0.4430 - val_loss: 4.9539\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8415 - val_f1: 0.4430 - val_loss: 4.9695\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8606 - val_f1: 0.4430 - val_loss: 4.9282\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8833 - val_f1: 0.4430 - val_loss: 4.9259\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8828 - val_f1: 0.4430 - val_loss: 4.9326\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8793 - val_f1: 0.4430 - val_loss: 4.8989\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8835 - val_f1: 0.4430 - val_loss: 4.9666\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8921 - val_f1: 0.4430 - val_loss: 4.9431\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8744 - val_f1: 0.4430 - val_loss: 5.1539\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8788 - val_f1: 0.4430 - val_loss: 4.9628\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8739 - val_f1: 0.4430 - val_loss: 4.9947\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8948 - val_f1: 0.4430 - val_loss: 4.9822\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9018 - val_f1: 0.4430 - val_loss: 4.9730\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8756 - val_f1: 0.4430 - val_loss: 4.9326\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4423 - loss: 4.9045 - val_f1: 0.4430 - val_loss: 4.9166\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8572 - val_f1: 0.4430 - val_loss: 4.9444\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9072 - val_f1: 0.4430 - val_loss: 5.0521\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9468 - val_f1: 0.4430 - val_loss: 4.8838\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8993 - val_f1: 0.4430 - val_loss: 4.8921\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8929 - val_f1: 0.4430 - val_loss: 4.8706\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8936 - val_f1: 0.4430 - val_loss: 4.9261\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8570 - val_f1: 0.4430 - val_loss: 4.8718\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8504 - val_f1: 0.4430 - val_loss: 4.8729\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8962 - val_f1: 0.4430 - val_loss: 4.9188\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8979 - val_f1: 0.4430 - val_loss: 5.0147\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8956 - val_f1: 0.4430 - val_loss: 5.0000\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9036 - val_f1: 0.4430 - val_loss: 4.9564\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8990 - val_f1: 0.4430 - val_loss: 4.9006\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8937 - val_f1: 0.4430 - val_loss: 4.9366\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8432 - val_f1: 0.4430 - val_loss: 4.9673\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8758 - val_f1: 0.4430 - val_loss: 4.9616\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8939 - val_f1: 0.4430 - val_loss: 4.9591\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8828 - val_f1: 0.4430 - val_loss: 4.8682\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8790 - val_f1: 0.4430 - val_loss: 4.9111\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8964 - val_f1: 0.4430 - val_loss: 4.9102\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8466 - val_f1: 0.4430 - val_loss: 4.8659\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8698 - val_f1: 0.4430 - val_loss: 4.9714\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8732 - val_f1: 0.4430 - val_loss: 4.8887\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8745 - val_f1: 0.4430 - val_loss: 4.8990\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4436 - loss: 4.8653 - val_f1: 0.4430 - val_loss: 4.8880\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4453 - loss: 4.8996 - val_f1: 0.4430 - val_loss: 4.8645\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4443 - loss: 4.8750 - val_f1: 0.4430 - val_loss: 4.8616\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8975 - val_f1: 0.4430 - val_loss: 4.8698\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8665 - val_f1: 0.4430 - val_loss: 4.8888\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8542 - val_f1: 0.4430 - val_loss: 4.8985\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8758 - val_f1: 0.4430 - val_loss: 4.8753\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8785 - val_f1: 0.4430 - val_loss: 4.9264\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8856 - val_f1: 0.4430 - val_loss: 4.9017\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8771 - val_f1: 0.4430 - val_loss: 4.8967\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8643 - val_f1: 0.4430 - val_loss: 4.9319\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8715 - val_f1: 0.4430 - val_loss: 4.9344\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8864 - val_f1: 0.4430 - val_loss: 4.9343\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8607 - val_f1: 0.4430 - val_loss: 4.9502\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 64, 64, 0.5, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 3ms/step - f1: 0.4506 - loss: 6.2886 - val_f1: 0.4430 - val_loss: 4.9342\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9252 - val_f1: 0.4430 - val_loss: 4.9014\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9059 - val_f1: 0.4430 - val_loss: 4.8928\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8747 - val_f1: 0.4430 - val_loss: 4.8847\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8763 - val_f1: 0.4430 - val_loss: 4.8757\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9283 - val_f1: 0.4430 - val_loss: 4.8972\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4435 - loss: 4.8851 - val_f1: 0.4430 - val_loss: 4.9062\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9057 - val_f1: 0.4430 - val_loss: 4.8948\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9177 - val_f1: 0.4430 - val_loss: 4.9020\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9118 - val_f1: 0.4430 - val_loss: 4.9322\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9458 - val_f1: 0.4430 - val_loss: 4.9713\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9041 - val_f1: 0.4430 - val_loss: 4.9957\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9292 - val_f1: 0.4430 - val_loss: 4.9569\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9201 - val_f1: 0.4430 - val_loss: 4.9890\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9106 - val_f1: 0.4430 - val_loss: 4.9659\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9087 - val_f1: 0.4430 - val_loss: 4.9751\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8848 - val_f1: 0.4430 - val_loss: 5.0042\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9005 - val_f1: 0.4430 - val_loss: 4.9631\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9246 - val_f1: 0.4430 - val_loss: 4.9580\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9247 - val_f1: 0.4430 - val_loss: 4.9804\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8877 - val_f1: 0.4430 - val_loss: 5.0005\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9009 - val_f1: 0.4430 - val_loss: 5.0232\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8752 - val_f1: 0.4430 - val_loss: 4.9791\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9052 - val_f1: 0.4430 - val_loss: 5.0156\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9019 - val_f1: 0.4430 - val_loss: 4.9567\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8729 - val_f1: 0.4430 - val_loss: 4.9689\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.9009 - val_f1: 0.4430 - val_loss: 5.0698\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9299 - val_f1: 0.4430 - val_loss: 5.0607\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8897 - val_f1: 0.4430 - val_loss: 5.0218\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8916 - val_f1: 0.4430 - val_loss: 5.0107\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8838 - val_f1: 0.4430 - val_loss: 5.0363\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8916 - val_f1: 0.4430 - val_loss: 5.0113\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9048 - val_f1: 0.4430 - val_loss: 5.0913\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8828 - val_f1: 0.4430 - val_loss: 5.1129\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8886 - val_f1: 0.4430 - val_loss: 5.2411\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.9231 - val_f1: 0.4430 - val_loss: 5.0978\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8841 - val_f1: 0.4430 - val_loss: 5.0512\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8805 - val_f1: 0.4430 - val_loss: 5.0928\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8838 - val_f1: 0.4430 - val_loss: 5.0796\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8779 - val_f1: 0.4430 - val_loss: 5.0224\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8900 - val_f1: 0.4430 - val_loss: 5.1028\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9003 - val_f1: 0.4430 - val_loss: 5.0653\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9036 - val_f1: 0.4430 - val_loss: 5.0755\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8966 - val_f1: 0.4430 - val_loss: 5.0610\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8764 - val_f1: 0.4430 - val_loss: 5.0549\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8836 - val_f1: 0.4430 - val_loss: 5.1193\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8783 - val_f1: 0.4430 - val_loss: 5.0038\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4438 - loss: 4.8292 - val_f1: 0.4430 - val_loss: 5.0253\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.9059 - val_f1: 0.4430 - val_loss: 5.0989\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8790 - val_f1: 0.4430 - val_loss: 4.9900\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.9033 - val_f1: 0.4430 - val_loss: 5.0998\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8754 - val_f1: 0.4430 - val_loss: 5.0579\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9114 - val_f1: 0.4430 - val_loss: 5.0674\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8705 - val_f1: 0.4430 - val_loss: 5.0492\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8925 - val_f1: 0.4430 - val_loss: 5.0614\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8895 - val_f1: 0.4430 - val_loss: 5.0606\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 4.9133 - val_f1: 0.4430 - val_loss: 5.0590\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 4.8962 - val_f1: 0.4430 - val_loss: 5.0305\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8987 - val_f1: 0.4430 - val_loss: 5.0636\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4425 - loss: 4.9015 - val_f1: 0.4430 - val_loss: 5.0009\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8842 - val_f1: 0.4430 - val_loss: 5.0107\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8553 - val_f1: 0.4430 - val_loss: 5.0665\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8548 - val_f1: 0.4430 - val_loss: 5.0259\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.8589 - val_f1: 0.4430 - val_loss: 5.0697\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4476 - loss: 5.3346 - val_f1: 0.4430 - val_loss: 4.9726\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4805 - loss: 5.0992 - val_f1: 0.4430 - val_loss: 6.3465\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4785 - loss: 5.0512 - val_f1: 0.4430 - val_loss: 6.0296\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4730 - loss: 5.0791 - val_f1: 0.4430 - val_loss: 6.2665\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4688 - loss: 5.0591 - val_f1: 0.4430 - val_loss: 5.8377\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4641 - loss: 5.0690 - val_f1: 0.4430 - val_loss: 5.1881\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4595 - loss: 5.0628 - val_f1: 0.4430 - val_loss: 6.2753\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4556 - loss: 5.0535 - val_f1: 0.4430 - val_loss: 6.2733\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4541 - loss: 5.0747 - val_f1: 0.4430 - val_loss: 6.2728\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4533 - loss: 5.0427 - val_f1: 0.4430 - val_loss: 6.2711\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4517 - loss: 5.0549 - val_f1: 0.4430 - val_loss: 6.2527\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4500 - loss: 5.0268 - val_f1: 0.4430 - val_loss: 6.0237\n",
            "Epoch 77/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4499 - loss: 5.0214 - val_f1: 0.4430 - val_loss: 5.6376\n",
            "Epoch 78/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4478 - loss: 5.0288 - val_f1: 0.4430 - val_loss: 6.0645\n",
            "Epoch 79/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4468 - loss: 5.0508 - val_f1: 0.4430 - val_loss: 5.8743\n",
            "Epoch 80/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4459 - loss: 5.0188 - val_f1: 0.4430 - val_loss: 5.9526\n",
            "Epoch 81/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4450 - loss: 5.0556 - val_f1: 0.4430 - val_loss: 5.9583\n",
            "Epoch 82/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4450 - loss: 5.0315 - val_f1: 0.4430 - val_loss: 5.6433\n",
            "Epoch 83/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4443 - loss: 5.0445 - val_f1: 0.4430 - val_loss: 4.9474\n",
            "Epoch 84/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4442 - loss: 5.0309 - val_f1: 0.4430 - val_loss: 4.9360\n",
            "Epoch 85/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4442 - loss: 5.0448 - val_f1: 0.4430 - val_loss: 4.9304\n",
            "Epoch 86/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4438 - loss: 5.0320 - val_f1: 0.4430 - val_loss: 4.9330\n",
            "Epoch 87/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4436 - loss: 4.9799 - val_f1: 0.4430 - val_loss: 4.9506\n",
            "Epoch 88/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8922 - val_f1: 0.4430 - val_loss: 5.0139\n",
            "Epoch 89/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8791 - val_f1: 0.4430 - val_loss: 4.9733\n",
            "Epoch 90/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.8716 - val_f1: 0.4430 - val_loss: 4.9277\n",
            "Epoch 91/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8686 - val_f1: 0.4430 - val_loss: 4.9043\n",
            "Epoch 92/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8511 - val_f1: 0.4430 - val_loss: 4.9061\n",
            "Epoch 93/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.8558 - val_f1: 0.4430 - val_loss: 4.8834\n",
            "Epoch 94/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8800 - val_f1: 0.4430 - val_loss: 4.9211\n",
            "Epoch 95/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 4.8746 - val_f1: 0.4430 - val_loss: 4.9623\n",
            "Epoch 96/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 4.8810 - val_f1: 0.4430 - val_loss: 4.9254\n",
            "Epoch 97/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8623 - val_f1: 0.4430 - val_loss: 4.9893\n",
            "Epoch 98/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.8617 - val_f1: 0.4430 - val_loss: 4.9925\n",
            "Epoch 99/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.8836 - val_f1: 0.4430 - val_loss: 5.1641\n",
            "Epoch 100/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 4.8846 - val_f1: 0.4430 - val_loss: 4.9948\n",
            "\u001b[1m1225/1225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "[[31162.     0.]\n",
            " [ 8021.     0.]]\n",
            "[[0.79529388 0.        ]\n",
            " [0.20470612 0.        ]]\n",
            "-------------------------------new high f1 score: feature=AEC, balance=None, f1=0.0 -------------------------------\n",
            "[2, 2, 64, 128, 0.4, None]\n",
            "{'MESOTHELIALEPICARDIUM': 49001, 'SPLEEN': 19861, 'STOMACH': 29039, 'HEPATOCYTE': 38539, 'NEURALCREST': 63538, 'NEPHRONPROGENITOR': 108920, 'OSTEOCYTE': 52642, 'PANCREAS': 13408, 'MESENCHYMAL': 16669, 'PERIPHERALBLOOD': 211}\n",
            "0.2779791132844003\n",
            "{'BACKGROUND': 311621, 'OFC': 80207}\n",
            "0.7953004889900671\n",
            "Epoch 1/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - f1: 0.4643 - loss: 6.3400 - val_f1: 0.4430 - val_loss: 5.0563\n",
            "Epoch 2/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0364 - val_f1: 0.4430 - val_loss: 5.0490\n",
            "Epoch 3/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0158 - val_f1: 0.4430 - val_loss: 5.0148\n",
            "Epoch 4/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0099 - val_f1: 0.4430 - val_loss: 5.0233\n",
            "Epoch 5/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0450 - val_f1: 0.4430 - val_loss: 5.0213\n",
            "Epoch 6/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0076 - val_f1: 0.4430 - val_loss: 5.0279\n",
            "Epoch 7/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0149 - val_f1: 0.4430 - val_loss: 5.0213\n",
            "Epoch 8/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0257 - val_f1: 0.4430 - val_loss: 5.0144\n",
            "Epoch 9/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9911 - val_f1: 0.4430 - val_loss: 5.0154\n",
            "Epoch 10/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0197 - val_f1: 0.4430 - val_loss: 5.0152\n",
            "Epoch 11/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9877 - val_f1: 0.4430 - val_loss: 5.0265\n",
            "Epoch 12/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9934 - val_f1: 0.4430 - val_loss: 5.0301\n",
            "Epoch 13/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9863 - val_f1: 0.4430 - val_loss: 5.0163\n",
            "Epoch 14/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0219 - val_f1: 0.4430 - val_loss: 5.0153\n",
            "Epoch 15/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9972 - val_f1: 0.4430 - val_loss: 5.0229\n",
            "Epoch 16/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9836 - val_f1: 0.4430 - val_loss: 5.0185\n",
            "Epoch 17/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0086 - val_f1: 0.4430 - val_loss: 5.0195\n",
            "Epoch 18/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9971 - val_f1: 0.4430 - val_loss: 5.0147\n",
            "Epoch 19/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0084 - val_f1: 0.4430 - val_loss: 5.0459\n",
            "Epoch 20/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0275 - val_f1: 0.4430 - val_loss: 5.0213\n",
            "Epoch 21/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9918 - val_f1: 0.4430 - val_loss: 5.0243\n",
            "Epoch 22/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0217 - val_f1: 0.4430 - val_loss: 5.0272\n",
            "Epoch 23/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9948 - val_f1: 0.4430 - val_loss: 5.0302\n",
            "Epoch 24/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0107 - val_f1: 0.4430 - val_loss: 5.0325\n",
            "Epoch 25/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0061 - val_f1: 0.4430 - val_loss: 5.0506\n",
            "Epoch 26/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0103 - val_f1: 0.4430 - val_loss: 5.0680\n",
            "Epoch 27/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0325 - val_f1: 0.4430 - val_loss: 5.0344\n",
            "Epoch 28/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0183 - val_f1: 0.4430 - val_loss: 5.0711\n",
            "Epoch 29/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 4.9992 - val_f1: 0.4430 - val_loss: 5.0629\n",
            "Epoch 30/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0127 - val_f1: 0.4430 - val_loss: 5.0637\n",
            "Epoch 31/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0249 - val_f1: 0.4430 - val_loss: 5.0476\n",
            "Epoch 32/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0035 - val_f1: 0.4430 - val_loss: 5.0805\n",
            "Epoch 33/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0141 - val_f1: 0.4430 - val_loss: 5.0876\n",
            "Epoch 34/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0033 - val_f1: 0.4430 - val_loss: 5.0499\n",
            "Epoch 35/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9909 - val_f1: 0.4430 - val_loss: 5.0655\n",
            "Epoch 36/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9977 - val_f1: 0.4430 - val_loss: 5.1305\n",
            "Epoch 37/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0536 - val_f1: 0.4430 - val_loss: 5.0707\n",
            "Epoch 38/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0392 - val_f1: 0.4430 - val_loss: 5.0812\n",
            "Epoch 39/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0042 - val_f1: 0.4430 - val_loss: 5.0669\n",
            "Epoch 40/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0432 - val_f1: 0.4430 - val_loss: 5.0634\n",
            "Epoch 41/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9970 - val_f1: 0.4430 - val_loss: 5.0814\n",
            "Epoch 42/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0104 - val_f1: 0.4430 - val_loss: 5.0629\n",
            "Epoch 43/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0258 - val_f1: 0.4430 - val_loss: 5.0720\n",
            "Epoch 44/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9902 - val_f1: 0.4430 - val_loss: 5.0560\n",
            "Epoch 45/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0298 - val_f1: 0.4430 - val_loss: 5.0779\n",
            "Epoch 46/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0158 - val_f1: 0.4430 - val_loss: 5.0567\n",
            "Epoch 47/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0212 - val_f1: 0.4430 - val_loss: 5.0687\n",
            "Epoch 48/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0242 - val_f1: 0.4430 - val_loss: 5.0567\n",
            "Epoch 49/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0274 - val_f1: 0.4430 - val_loss: 5.0627\n",
            "Epoch 50/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0162 - val_f1: 0.4430 - val_loss: 5.0607\n",
            "Epoch 51/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9900 - val_f1: 0.4430 - val_loss: 5.1045\n",
            "Epoch 52/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4427 - loss: 5.0287 - val_f1: 0.4430 - val_loss: 5.0543\n",
            "Epoch 53/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0188 - val_f1: 0.4430 - val_loss: 5.0635\n",
            "Epoch 54/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0286 - val_f1: 0.4430 - val_loss: 5.1046\n",
            "Epoch 55/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 4.9965 - val_f1: 0.4430 - val_loss: 5.0698\n",
            "Epoch 56/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0262 - val_f1: 0.4430 - val_loss: 5.0748\n",
            "Epoch 57/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9821 - val_f1: 0.4430 - val_loss: 5.0796\n",
            "Epoch 58/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0042 - val_f1: 0.4430 - val_loss: 5.0865\n",
            "Epoch 59/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0186 - val_f1: 0.4430 - val_loss: 5.0686\n",
            "Epoch 60/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0173 - val_f1: 0.4430 - val_loss: 5.0648\n",
            "Epoch 61/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0283 - val_f1: 0.4430 - val_loss: 5.0429\n",
            "Epoch 62/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0261 - val_f1: 0.4430 - val_loss: 5.0677\n",
            "Epoch 63/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4434 - loss: 4.9875 - val_f1: 0.4430 - val_loss: 5.0917\n",
            "Epoch 64/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9863 - val_f1: 0.4430 - val_loss: 5.0535\n",
            "Epoch 65/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0141 - val_f1: 0.4430 - val_loss: 5.0510\n",
            "Epoch 66/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0052 - val_f1: 0.4430 - val_loss: 5.0648\n",
            "Epoch 67/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4426 - loss: 5.0342 - val_f1: 0.4430 - val_loss: 5.0886\n",
            "Epoch 68/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0135 - val_f1: 0.4430 - val_loss: 5.0755\n",
            "Epoch 69/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 4.9986 - val_f1: 0.4430 - val_loss: 5.0663\n",
            "Epoch 70/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0175 - val_f1: 0.4430 - val_loss: 5.0780\n",
            "Epoch 71/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4433 - loss: 4.9982 - val_f1: 0.4430 - val_loss: 5.0904\n",
            "Epoch 72/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4432 - loss: 5.0009 - val_f1: 0.4430 - val_loss: 5.1244\n",
            "Epoch 73/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4430 - loss: 5.0144 - val_f1: 0.4430 - val_loss: 5.0623\n",
            "Epoch 74/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4428 - loss: 5.0262 - val_f1: 0.4430 - val_loss: 5.0643\n",
            "Epoch 75/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4429 - loss: 5.0306 - val_f1: 0.4430 - val_loss: 5.0915\n",
            "Epoch 76/100\n",
            "\u001b[1m8572/8572\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - f1: 0.4431 - loss: 5.0107 - val_f1: 0.4430 - val_loss: 5.0539\n",
            "Epoch 77/100\n",
            "\u001b[1m4413/8572\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - f1: 0.4424 - loss: 5.0640"
          ]
        }
      ],
      "source": [
        "cell_idx = get_cell_idx(C)\n",
        "cell_label_str = '_'.join([k+'-%s'%cell_idx[k] for k in sorted(cell_idx)])\n",
        "json_score = '/'.join(in_path.split('/')[:-1])+'/%s.%s.%s.score.json'%('_'.join(sorted(features)),cell_label_str,balance_w)\n",
        "if os.path.exists(json_score):\n",
        "    with open(json_score,'r') as f: score = json.load(f)\n",
        "else: score = {feature: [hyper_params[0],[], 0.0] for feature in C}\n",
        "\n",
        "models = {}\n",
        "for feature in C:\n",
        "    for hyper in hyper_params:\n",
        "        embed_dim, num_head, ff_dim, batch, drop, bl = hyper\n",
        "        with tf.device('/device:GPU:%s'%gpu_num):\n",
        "            # -----------------------------------------------------------------------\n",
        "            inputs = layers.Input(shape=(maxlen,))\n",
        "            embedding_layer = TokenAndPositionEmbedding(maxlen, max_vocab, embed_dim)\n",
        "            x = embedding_layer(inputs)\n",
        "            transformer_block = TransformerBlock(embed_dim, num_head, ff_dim)\n",
        "            x = transformer_block(x)\n",
        "            x = layers.GlobalAveragePooling1D()(x)\n",
        "            x = layers.Dropout(0.2)(x)\n",
        "            x = layers.Dense(class_num * 64, activation=\"relu\")(x)\n",
        "            x = layers.Dropout(drop)(x)\n",
        "            outputs = layers.Dense(class_num, activation=\"softmax\")(x)\n",
        "            models[feature] = keras.Model(inputs=inputs, outputs=outputs)\n",
        "            models[feature].compile(optimizer=keras.optimizers.Adam(5e-5),\n",
        "                                    loss=c2_f1_loss,\n",
        "                                    metrics=[F1()])\n",
        "            models[feature].name = feature\n",
        "\n",
        "            # training-----------------------------------------------------------------------\n",
        "            callbacks = [\n",
        "                keras.callbacks.EarlyStopping(monitor=\"val_f1\",\n",
        "                                                min_delta=1e-2,patience=5,mode='max',verbose=1,\n",
        "                                                restore_best_weights=True)\n",
        "            ]\n",
        "            history = models[feature].fit(\n",
        "                x=train[feature][0], y=train[feature][1], epochs=100,\n",
        "                validation_data=(test[feature][0],test[feature][1])\n",
        "            )\n",
        "\n",
        "            # validation score-----------------------------------------------------------------------\n",
        "            true = valid[feature][1]\n",
        "            pred = np.argmax(models[feature].predict(valid[feature][0]), axis=1)\n",
        "            cm = confusion_matrix(true, pred, c=class_num)\n",
        "            cm0 = (cm if np.sum(cm) == 0.0 else cm / np.sum(cm))\n",
        "            print(cm)\n",
        "            print(cm0)\n",
        "            f1 = f1_score(cm)\n",
        "            if f1 >= score[feature][-1]:\n",
        "                print(\n",
        "                    '-------------------------------new high f1 score: feature=%s, balance=%s, f1=%s -------------------------------\\n%s'\\\n",
        "                    %(feature,balance_w,f1,hyper))\n",
        "                score[feature] = [hyper, [list(l) for l in list(cm)], f1]\n",
        "                weight_path    = '/'.join(in_path.split('/')[:-1])+'/%s.%s.%s.weights.h5'%(feature,cell_label_str,balance_w)\n",
        "                if os.path.exists(json_score):\n",
        "                    with open(json_score,'r') as f:  old_score          = json.load(f)\n",
        "                    if feature in old_score:         old_score[feature] = score[feature]\n",
        "                    with open(json_score,'w') as f:\n",
        "                        json.dump(score,f)\n",
        "                        models[feature].save_weights(weight_path)\n",
        "                else:\n",
        "                    with open(json_score,'w') as f:\n",
        "                        json.dump(score,f)\n",
        "                        models[feature].save_weights(weight_path)\n",
        "            else:\n",
        "                print('f1 score: feature=%s, balance=%s, f1=%s'%(feature,balance_w, f1))\n",
        "\n",
        "            print({cell: len(F[feature][cell]) for cell in F[feature]})\n",
        "            min_score = max([len(F[feature][cell]) for cell in F[feature]]) / sum(\n",
        "                [len(F[feature][cell]) for cell in F[feature]])\n",
        "            print(min_score)\n",
        "            print({cell: len(C[feature][cell]) for cell in C[feature]})\n",
        "            min_score = max([len(C[feature][cell]) for cell in C[feature]]) / sum(\n",
        "                [len(C[feature][cell]) for cell in C[feature]])\n",
        "            print(min_score)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "130r0o1OABt7BqiCKFKPVwKS9cfZf0aKZ",
      "authorship_tag": "ABX9TyO7ZkFgAyxOGKIERmuwMq2E"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}